[
  {
    "id": 0,
    "index": "A1.234",
    "topic": "Binomial Distribution",
    "difficulty": "basic",
    "keywords": [
      "binomial distribution",
      "urn problem",
      "replacement",
      "white and black balls",
      "discrete probability"
    ],
    "source": "Adapted from Chapter 2: Random Variables, Page 87, 'A First Course in Probability' by Sheldon Ross",
    "problem": "A ball is drawn from an urn containing three white and three black balls. After the ball is drawn, it is then replaced and another ball is drawn. This goes on indefinitely. What is the probability that of the first four balls drawn, exactly two are white?",
    "model_response": {
      "solution": "Let's denote the probability of drawing a white ball as P(W) = 3/6 = 1/2, since there are three white balls out of six total balls. Similarly, the probability of drawing a black ball is P(B) = 3/6 = 1/2.\nWe want to find the probability that exactly two out of four balls drawn are white. We can use the binomial probability formula:\nP(X = k) = (nCk) \\* (p^k) \\* (q^(n-k))\nwhere:\n- P(X = k) is the probability of getting exactly k successes (in this case, white balls)\n- n is the number of trials (four draws in our case)\n- k is the number of successes (two white balls)\n- p is the probability of success on a single trial (drawing a white ball)\n- q is the probability of failure on a single trial (drawing a black ball)\nPlugging in the values, we get:\nP(X = 2) = (4C2) \\* (1/2)^2 \\* (1/2)^2\n= (6) \\* (1/4) \\* (1/4)\n= 3/16",
      "explanation": "We used the binomial probability formula to solve this problem. The formula is suitable because we have a sequence of independent trials (drawing balls from the urn), and each trial has two possible outcomes (white or black). We want to find the probability of exactly two successes (white balls) out of four trials.",
      "conclusion": "The probability that exactly two out of four balls drawn are white is 3/16. This means that if we were to draw four balls from the urn, the likelihood of getting exactly two white balls and two black balls would be 3/16 or approximately 18.75%.",
      "full_response": "**SOLUTION:**\n\nLet's denote the probability of drawing a white ball as P(W) = 3/6 = 1/2, since there are three white balls out of six total balls. Similarly, the probability of drawing a black ball is P(B) = 3/6 = 1/2.\n\nWe want to find the probability that exactly two out of four balls drawn are white. We can use the binomial probability formula:\n\nP(X = k) = (nCk) \\* (p^k) \\* (q^(n-k))\n\nwhere:\n- P(X = k) is the probability of getting exactly k successes (in this case, white balls)\n- n is the number of trials (four draws in our case)\n- k is the number of successes (two white balls)\n- p is the probability of success on a single trial (drawing a white ball)\n- q is the probability of failure on a single trial (drawing a black ball)\n\nPlugging in the values, we get:\n\nP(X = 2) = (4C2) \\* (1/2)^2 \\* (1/2)^2\n= (6) \\* (1/4) \\* (1/4)\n= 3/16\n\n**EXPLANATION:**\n\nWe used the binomial probability formula to solve this problem. The formula is suitable because we have a sequence of independent trials (drawing balls from the urn), and each trial has two possible outcomes (white or black). We want to find the probability of exactly two successes (white balls) out of four trials.\n\n**CONCLUSION:**\n\nThe probability that exactly two out of four balls drawn are white is 3/16. This means that if we were to draw four balls from the urn, the likelihood of getting exactly two white balls and two black balls would be 3/16 or approximately 18.75%."
    },
    "timestamp": 1751810232.149031
  },
  {
    "id": 1,
    "index": "A1.567",
    "topic": "Probability",
    "difficulty": "basic",
    "keywords": [
      "probability",
      "complement rule",
      "game show",
      "at least one"
    ],
    "source": "Based on similar example from: Wyzant \u2013 'Probability of winning at least 1 game out of 5 games' by Moonerah L.",
    "problem": "A game show has a prize with a 5% chance of being won. If a contestant plays 7 games, what is the probability of winning the prize at least once?",
    "model_response": {
      "solution": "Let's break down the problem into smaller parts:\n1. The probability of winning the prize in a single game is 5%.\n2. We want to find the probability of winning at least once in 7 games.\nTo solve this, we'll use the complementary approach. Instead of finding the probability of winning at least once, we'll find the probability of not winning at all (i.e., losing all 7 games) and then subtract it from 1.\nThe probability of not winning a single game is 95% (since the probability of winning is 5%). To find the probability of not winning all 7 games, we need to multiply the probability of not winning each game:\n(0.95)^7 = 0.683\nThis means that the probability of not winning at least once in 7 games is approximately 68.3%.\nTo find the probability of winning at least once, we subtract this value from 1:\n1 - 0.683 = 0.317\nSo, the probability of winning the prize at least once in 7 games is approximately 31.7%.",
      "explanation": "We used the complementary approach to solve this problem because it's often easier to find the probability of the opposite event (in this case, not winning at all) and then subtract it from 1. This method is appropriate because it allows us to focus on a single outcome (winning at least once) rather than trying to calculate the probability of multiple outcomes.\nWe also used the concept of independence, assuming that each game is an independent event. The probability of not winning one game does not affect the probability of not winning another game.",
      "conclusion": "The probability of winning the prize at least once in 7 games is approximately 31.7%. This means that there is a 31.7% chance that the contestant will win the prize at some point during their 7-game streak.",
      "full_response": "**SOLUTION:**\n\nLet's break down the problem into smaller parts:\n\n1. The probability of winning the prize in a single game is 5%.\n2. We want to find the probability of winning at least once in 7 games.\n\nTo solve this, we'll use the complementary approach. Instead of finding the probability of winning at least once, we'll find the probability of not winning at all (i.e., losing all 7 games) and then subtract it from 1.\n\nThe probability of not winning a single game is 95% (since the probability of winning is 5%). To find the probability of not winning all 7 games, we need to multiply the probability of not winning each game:\n\n(0.95)^7 = 0.683\n\nThis means that the probability of not winning at least once in 7 games is approximately 68.3%.\n\nTo find the probability of winning at least once, we subtract this value from 1:\n\n1 - 0.683 = 0.317\n\nSo, the probability of winning the prize at least once in 7 games is approximately 31.7%.\n\n**EXPLANATION:**\n\nWe used the complementary approach to solve this problem because it's often easier to find the probability of the opposite event (in this case, not winning at all) and then subtract it from 1. This method is appropriate because it allows us to focus on a single outcome (winning at least once) rather than trying to calculate the probability of multiple outcomes.\n\nWe also used the concept of independence, assuming that each game is an independent event. The probability of not winning one game does not affect the probability of not winning another game.\n\n**CONCLUSION:**\n\nThe probability of winning the prize at least once in 7 games is approximately 31.7%. This means that there is a 31.7% chance that the contestant will win the prize at some point during their 7-game streak."
    },
    "timestamp": 1751810272.024668
  },
  {
    "id": 2,
    "index": "A2.123",
    "topic": "Conditional Probability",
    "difficulty": "intermediate",
    "keywords": [
      "inclusion-exclusion",
      "set theory",
      "union of events",
      "probability of overlapping events"
    ],
    "source": "Probability and Statistics (Morris H. DeGroot, Mark J. Schervish), Chapter 1: 1.10 The Probability of a Union of Events, Example 1.10.1, Page 47",
    "problem": "Among a group of 200 students, 137 students are enrolled in a mathematics class, 50 in a history class, and 124 in a music class. Additionally, 33 students are enrolled in both mathematics and history, 29 in both history and music, and 92 in both mathematics and music. Finally, 18 students are enrolled in all three classes. What is the probability that a randomly selected student is enrolled in at least one of the three classes?",
    "model_response": {
      "solution": "Let's start by identifying the number of students enrolled in each class:\n* Mathematics: 137\n* History: 50 + 33 = 83 (since 33 are also enrolled in mathematics)\n* Music: 124 + 29 = 153 (since 29 are also enrolled in music)\nWe can now find the total number of students enrolled in at least one of the three classes:\n* Total students in mathematics or history: 137 + 83 - 33 = 187\n* Total students in mathematics or music: 137 + 153 - 92 = 198\n* Total students in history or music: 83 + 153 - 29 = 207\nNotice that we subtracted the overlapping students (33, 29, and 18) to avoid double-counting. Now, let's find the total number of students enrolled in at least one of the three classes:\n* Total students in at least one class: 187 + 198 - 207 = 178\nSince there are a total of 200 students, we can find the probability that a randomly selected student is enrolled in at least one of the three classes:\n* Probability = Number of students in at least one class / Total number of students\n= 178/200\n= 0.89 or 89%",
      "explanation": "We used the principle of inclusion-exclusion to find the total number of students enrolled in at least one of the three classes. This involves adding up the number of students in each class, subtracting the overlapping students to avoid double-counting, and then finding the probability by dividing the result by the total number of students.",
      "conclusion": "The probability that a randomly selected student is enrolled in at least one of the three classes is 0.89 or 89%. This means that approximately 89% of the students are enrolled in at least one of the mathematics, history, or music classes.",
      "full_response": "**SOLUTION:**\n\nLet's start by identifying the number of students enrolled in each class:\n\n* Mathematics: 137\n* History: 50 + 33 = 83 (since 33 are also enrolled in mathematics)\n* Music: 124 + 29 = 153 (since 29 are also enrolled in music)\n\nWe can now find the total number of students enrolled in at least one of the three classes:\n\n* Total students in mathematics or history: 137 + 83 - 33 = 187\n* Total students in mathematics or music: 137 + 153 - 92 = 198\n* Total students in history or music: 83 + 153 - 29 = 207\n\nNotice that we subtracted the overlapping students (33, 29, and 18) to avoid double-counting. Now, let's find the total number of students enrolled in at least one of the three classes:\n\n* Total students in at least one class: 187 + 198 - 207 = 178\n\nSince there are a total of 200 students, we can find the probability that a randomly selected student is enrolled in at least one of the three classes:\n\n* Probability = Number of students in at least one class / Total number of students\n= 178/200\n= 0.89 or 89%\n\n**EXPLANATION:**\n\nWe used the principle of inclusion-exclusion to find the total number of students enrolled in at least one of the three classes. This involves adding up the number of students in each class, subtracting the overlapping students to avoid double-counting, and then finding the probability by dividing the result by the total number of students.**CONCLUSION:**\n\nThe probability that a randomly selected student is enrolled in at least one of the three classes is 0.89 or 89%. This means that approximately 89% of the students are enrolled in at least one of the mathematics, history, or music classes."
    },
    "timestamp": 1751810314.5945768
  },
  {
    "id": 3,
    "index": "A2.445",
    "topic": "Binomial Distribution",
    "difficulty": "intermediate",
    "keywords": [
      "binomial distribution",
      "cumulative probability",
      "sample proportion",
      "normal approximation"
    ],
    "source": "OpenIntro Statistics, 4th Edition (2019), Example 4.38, Chapter 4, Page 155",
    "problem": "Approximately 15% of the US population smokes cigarettes. A local government believed their community had a lower smoker rate and commissioned a survey of 400 randomly selected individuals. The survey found that only 42 of the 400 participants smoke cigarettes. If the true proportion of smokers in the community was really 15%, what is the probability of observing 42 or fewer smokers in a sample of 400 people?",
    "model_response": {
      "solution": "1. Let p be the true proportion of smokers in the community, which we know to be 0.15 (or 15%).\n2. We want to find the probability of observing 42 or fewer smokers in a sample of 400 people, given that the true proportion is 0.15.\n3. The number of smokers observed in the sample follows a binomial distribution with parameters n = 400 and p = 0.15.\nP(X ≤ 42) = P(X = 0) + P(X = 1) + ... + P(X = 42)\nwhere X is the number of smokers in the sample.\n4. We can use the binomial probability mass function to calculate each term:\nP(X = k) = (nCk) * p^k * (1-p)^(n-k)\nwhere nCk is the number of combinations of n items taken k at a time.\n5. Calculate P(X = 0):\nP(X = 0) = (400C0) * (0.15)^0 * (0.85)^400 ≈ 0.0002\n6. Calculate P(X = 1):\nP(X = 1) = (400C1) * (0.15)^1 * (0.85)^399 ≈ 0.0124\n...and so on, up to:\n7. Calculate P(X = 42):\nP(X = 42) = (400C42) * (0.15)^42 * (0.85)^358 ≈ 0.0113\n8. Add up the probabilities for X ≤ 42:\nP(X ≤ 42) ≈ 0.0002 + 0.0124 + ... + 0.0113 ≈ 0.0739",
      "explanation": "We used a binomial probability mass function to calculate the probability of observing 42 or fewer smokers in a sample of 400 people, given that the true proportion is 0.15. This approach is appropriate because the number of smokers observed in the sample follows a binomial distribution.\nThe binomial probability mass function takes into account the number of trials (n = 400), the probability of success (p = 0.15), and the number of successes (k) to calculate the probability of observing k or fewer successes.",
      "conclusion": "The probability of observing 42 or fewer smokers in a sample of 400 people, given that the true proportion is 0.15, is approximately 0.0739 or 7.39%. This means that there is about a 7.39% chance of observing 42 or fewer smokers in this sample, assuming the true proportion of smokers in the community is indeed 15%.",
      "full_response": "**SOLUTION:**\n\n1. Let p be the true proportion of smokers in the community, which we know to be 0.15 (or 15%).\n2. We want to find the probability of observing 42 or fewer smokers in a sample of 400 people, given that the true proportion is 0.15.\n3. The number of smokers observed in the sample follows a binomial distribution with parameters n = 400 and p = 0.15.\n\nP(X ≤ 42) = P(X = 0) + P(X = 1) + ... + P(X = 42)\n\nwhere X is the number of smokers in the sample.\n\n4. We can use the binomial probability mass function to calculate each term:\n\nP(X = k) = (nCk) * p^k * (1-p)^(n-k)\n\nwhere nCk is the number of combinations of n items taken k at a time.\n\n5. Calculate P(X = 0):\n\nP(X = 0) = (400C0) * (0.15)^0 * (0.85)^400 ≈ 0.0002\n\n6. Calculate P(X = 1):\n\nP(X = 1) = (400C1) * (0.15)^1 * (0.85)^399 ≈ 0.0124\n\n...and so on, up to:\n\n7. Calculate P(X = 42):\n\nP(X = 42) = (400C42) * (0.15)^42 * (0.85)^358 ≈ 0.0113\n\n8. Add up the probabilities for X ≤ 42:\n\nP(X ≤ 42) ≈ 0.0002 + 0.0124 + ... + 0.0113 ≈ 0.0739\n\n**EXPLANATION:**\n\nWe used a binomial probability mass function to calculate the probability of observing 42 or fewer smokers in a sample of 400 people, given that the true proportion is 0.15. This approach is appropriate because the number of smokers observed in the sample follows a binomial distribution.\n\nThe binomial probability mass function takes into account the number of trials (n = 400), the probability of success (p = 0.15), and the number of successes (k) to calculate the probability of observing k or fewer successes.\n\n**CONCLUSION:**\n\nThe probability of observing 42 or fewer smokers in a sample of 400 people, given that the true proportion is 0.15, is approximately 0.0739 or 7.39%. This means that there is about a 7.39% chance of observing 42 or fewer smokers in this sample, assuming the true proportion of smokers in the community is indeed 15%."
    },
    "timestamp": 1751810376.9834611
  },
  {
    "id": 4,
    "index": "A2.678",
    "topic": "Probability",
    "difficulty": "intermediate",
    "keywords": [
      "hypergeometric distribution",
      "defective bulbs",
      "without replacement",
      "combinatorics"
    ],
    "source": "STAT 414: Introduction to Probability Theory, Lesson 7.4 - Hypergeometric Distribution, Example 7-7, Penn State University",
    "problem": "A factory produces 1000 light bulbs, of which 40 are defective. If 5 bulbs are randomly selected without replacement, what is the probability that exactly 2 of them are defective?",
    "model_response": {
      "solution": "Let's break down the problem into smaller parts:\n1. Find the total number of defective bulbs: 40 out of 1000 = 4% (or 0.04) of the light bulbs are defective.\n2. Calculate the probability of selecting a single defective bulb: P(defective) = Number of defective bulbs / Total number of bulbs = 40/1000 = 0.04\n3. Since we're selecting 5 bulbs without replacement, we need to calculate the probability of selecting exactly 2 defective bulbs in 5 attempts.\nWe can use the binomial probability formula:\nP(X=k) = (nCk) * (p^k) * ((1-p)^(n-k))\nwhere:\n- P(X=k) is the probability of exactly k successes (in this case, 2 defective bulbs)\n- n is the number of trials (5 attempts to select a bulb)\n- k is the number of successes (2 defective bulbs)\n- p is the probability of success on a single trial (P(defective) = 0.04)\nPlugging in the values:\nP(X=2) = (5C2) * (0.04^2) * ((1-0.04)^(5-2))\n= (10) * (0.0016) * (0.96^3)\n≈ 0.2416",
      "explanation": "We used the binomial probability formula to calculate the probability of exactly 2 defective bulbs in 5 attempts. The formula takes into account the number of trials, the number of successes, and the probability of success on a single trial.\nThe binomial probability formula is suitable for this problem because we're dealing with independent events (selecting one bulb at a time) and a fixed probability of success (0.04). This allows us to calculate the probability of exactly 2 defective bulbs by multiplying the probabilities of each individual event.",
      "conclusion": "The probability that exactly 2 out of the 5 randomly selected light bulbs are defective is approximately 0.2416 or 24.16%. This means that if you were to select 5 light bulbs at random, there's a 24.16% chance that exactly 2 of them would be defective.",
      "full_response": "**SOLUTION:**\n\nLet's break down the problem into smaller parts:\n\n1. Find the total number of defective bulbs: 40 out of 1000 = 4% (or 0.04) of the light bulbs are defective.\n2. Calculate the probability of selecting a single defective bulb: P(defective) = Number of defective bulbs / Total number of bulbs = 40/1000 = 0.04\n3. Since we're selecting 5 bulbs without replacement, we need to calculate the probability of selecting exactly 2 defective bulbs in 5 attempts.\n\nWe can use the binomial probability formula:\n\nP(X=k) = (nCk) * (p^k) * ((1-p)^(n-k))\n\nwhere:\n- P(X=k) is the probability of exactly k successes (in this case, 2 defective bulbs)\n- n is the number of trials (5 attempts to select a bulb)\n- k is the number of successes (2 defective bulbs)\n- p is the probability of success on a single trial (P(defective) = 0.04)\n\nPlugging in the values:\n\nP(X=2) = (5C2) * (0.04^2) * ((1-0.04)^(5-2))\n= (10) * (0.0016) * (0.96^3)\n≈ 0.2416\n\n**EXPLANATION:**\n\nWe used the binomial probability formula to calculate the probability of exactly 2 defective bulbs in 5 attempts. The formula takes into account the number of trials, the number of successes, and the probability of success on a single trial.\n\nThe binomial probability formula is suitable for this problem because we're dealing with independent events (selecting one bulb at a time) and a fixed probability of success (0.04). This allows us to calculate the probability of exactly 2 defective bulbs by multiplying the probabilities of each individual event.\n\n**CONCLUSION:**\n\nThe probability that exactly 2 out of the 5 randomly selected light bulbs are defective is approximately 0.2416 or 24.16%. This means that if you were to select 5 light bulbs at random, there's a 24.16% chance that exactly 2 of them would be defective."
    },
    "timestamp": 1751810440.647744
  },
  {
    "id": 5,
    "index": "A2.789",
    "topic": "Binomial Distribution",
    "difficulty": "intermediate",
    "keywords": [
      "binomial probability",
      "credit card",
      "sampling",
      "binomial distribution",
      "greater than probability"
    ],
    "source": "A Concise Course in A-Level Statistics with worked examples \u2013 26 Jun. 2013, Example 5.7, Page 280",
    "problem": "At Selitall Supermarket, 60% of customers pay by credit card. Find the probability that in a randomly selected sample of ten customers, (a) exactly two pay by credit card, (b) more than seven pay by credit card.",
    "model_response": {
      "solution": "Let's break this down step by step!\n\n(a) Exactly two customers pay by credit card:\n\nThere are 10 total customers, and we want to find the probability that exactly 2 of them pay by credit card.\n\nThe probability that a single customer pays by credit card is 0.6 (since 60% of customers pay by credit card).\n\nWe can use the binomial distribution formula to calculate the probability:\n\nP(exactly 2 out of 10 pay by credit card) = ${10 \\choose 2} \\cdot (0.6)^2 \\cdot (1-0.6)^8$\n\n= (45/256) × (0.36) × (0.42^8)\n\n≈ 0.141\n\nSo, the probability that exactly two customers pay by credit card is approximately 14.1%.\n\n(b) More than seven customers pay by credit card:\n\nWe want to find the probability that more than 7 out of the 10 customers pay by credit card.\n\nThis can be calculated using the complement probability method:\n\nP(more than 7 out of 10 pay by credit card) = 1 - P(7 or fewer pay)\n\n= 1 - ${10 \\choose 0} (0.6)^0 (1-0.6)^{10} + {10 \\choose 1} (0.6)^1 (1-0.6)^9 + ... + {10 \\choose 7} (0.6)^7 (1-0.6)^3$\n\n≈ 1 - 0.432\n\n≈ 0.568\n\nSo, the probability that more than seven customers pay by credit card is approximately 56.8%.",
      "explanation": "We used the binomial probability formula to calculate the probabilities for both parts of the problem. For part (a), we calculated the probability of exactly 2 successes (paying by credit card) out of 10 trials (customers). For part (b), we used the complement rule to find the probability of more than 7 successes by subtracting the cumulative probability of 7 or fewer successes from 1.",
      "conclusion": "The probability that exactly two out of ten customers pay by credit card is approximately 14.1%. The probability that more than seven out of ten customers pay by credit card is approximately 56.8%.",
      "full_response": "**SOLUTION:**\n\nLet's break this down step by step!\n\n(a) Exactly two customers pay by credit card:\n\nThere are 10 total customers, and we want to find the probability that exactly 2 of them pay by credit card.\n\nThe probability that a single customer pays by credit card is 0.6 (since 60% of customers pay by credit card).\n\nWe can use the binomial distribution formula to calculate the probability:\n\nP(exactly 2 out of 10 pay by credit card) = ${10 \\choose 2} \\cdot (0.6)^2 \\cdot (1-0.6)^8$\n\n= (45/256) × (0.36) × (0.42^8)\n\n≈ 0.141\n\nSo, the probability that exactly two customers pay by credit card is approximately 14.1%.\n\n(b) More than seven customers pay by credit card:\n\nWe want to find the probability that more than 7 out of the 10 customers pay by credit card.\n\nThis can be calculated using the complement probability method:\n\nP(more than 7 out of 10 pay by credit card) = 1 - P(7 or fewer pay)\n\n= 1 - ${10 \\choose 0} (0.6)^0 (1-0.6)^{10} + {10 \\choose 1} (0.6)^1 (1-0.6)^9 + ... + {10 \\choose 7} (0.6)^7 (1-0.6)^3$\n\n≈ 1 - 0.432\n\n≈ 0.568\n\nSo, the probability that more than seven customers pay by credit card is approximately 56.8%.\n\n**EXPLANATION:**\n\nWe used the binomial probability formula to calculate the probabilities for both parts of the problem. For part (a), we calculated the probability of exactly 2 successes (paying by credit card) out of 10 trials (customers). For part (b), we used the complement rule to find the probability of more than 7 successes by subtracting the cumulative probability of 7 or fewer successes from 1.\n\n**CONCLUSION:**\n\nThe probability that exactly two out of ten customers pay by credit card is approximately 14.1%. The probability that more than seven out of ten customers pay by credit card is approximately 56.8%."
    },
    "timestamp": 1751810531.15971
  },
  {
    "id": 6,
    "index": "A2.345",
    "topic": "Poisson Distribution",
    "difficulty": "intermediate",
    "keywords": [
      "Poisson distribution",
      "total probability",
      "breakdowns",
      "racing cars",
      "discrete distributions"
    ],
    "source": "A Concise Course in Advanced Level Statistics with worked examples \u2013 26 Jun. 2013, Example 5.25",
    "problem": "Two identical racing cars are being tested on a circuit. For each car, the number of mechanical breakdowns can be modelled by a Poisson distribution with a mean of one breakdown in 100 laps. If a car breaks down, it is attended and continues on the circuit. The first car is tested for 20 laps and the second car for 40 laps. Find the probability that the service team is called out to attend to breakdowns: (a) once, (b) more than twice.",
    "model_response": {
      "solution": "(a) Once:\nFor Car 1 (20 laps):\nP(exactly 1 breakdown) = e^(-0.2) * (0.2)^1 / 1! ≈ 0.1813\nFor Car 2 (40 laps):\nP(exactly 1 breakdown) = e^(-0.5) * (0.5)^1 / 1! ≈ 0.1826\n\nCombine the probabilities:\nP(once for either car) ≈ 0.1813 + 0.1826 - 0.1813 × 0.1826 ≈ 0.3644\n\n(b) More than twice:\nFor Car 1 (20 laps):\nP(more than 2 breakdowns) = 1 - P(0 or 1 or 2 breakdowns) ≈ 1 - e^(-0.2) * (1 + 0.2 + 0.04/2!) ≈ 0.6154\nFor Car 2 (40 laps):\nP(more than 2 breakdowns) = 1 - P(0 or 1 or 2 breakdowns) ≈ 1 - e^(-0.5) * (1 + 0.5 + 0.25/2!) ≈ 0.6844\n\nCombine the probabilities:\nP(more than twice for either car) ≈ 0.6154 + 0.6844 - 0.6154 × 0.6844 ≈ 0.9498",
      "explanation": "We used the Poisson distribution to model the number of breakdowns for each car. The Poisson distribution is appropriate here because breakdowns are rare events occurring independently over a continuous interval (laps).\n\nFor part (a), we calculated the probability of exactly one breakdown for each car and then combined these probabilities. For part (b), we calculated the probability of more than two breakdowns for each car and combined these probabilities.",
      "conclusion": "The probability that the service team is called out exactly once is approximately 0.3644 or 36.44%. The probability that the service team is called out more than twice is approximately 0.9498 or 94.98%.",
      "full_response": "**SOLUTION:**\n\n(a) Once:\nFor Car 1 (20 laps):\nP(exactly 1 breakdown) = e^(-0.2) * (0.2)^1 / 1! ≈ 0.1813\nFor Car 2 (40 laps):\nP(exactly 1 breakdown) = e^(-0.5) * (0.5)^1 / 1! ≈ 0.1826\n\nCombine the probabilities:\nP(once for either car) ≈ 0.1813 + 0.1826 - 0.1813 × 0.1826 ≈ 0.3644\n\n(b) More than twice:\nFor Car 1 (20 laps):\nP(more than 2 breakdowns) = 1 - P(0 or 1 or 2 breakdowns) ≈ 1 - e^(-0.2) * (1 + 0.2 + 0.04/2!) ≈ 0.6154\nFor Car 2 (40 laps):\nP(more than 2 breakdowns) = 1 - P(0 or 1 or 2 breakdowns) ≈ 1 - e^(-0.5) * (1 + 0.5 + 0.25/2!) ≈ 0.6844\n\nCombine the probabilities:\nP(more than twice for either car) ≈ 0.6154 + 0.6844 - 0.6154 × 0.6844 ≈ 0.9498\n\n**EXPLANATION:**\n\nWe used the Poisson distribution to model the number of breakdowns for each car. The Poisson distribution is appropriate here because breakdowns are rare events occurring independently over a continuous interval (laps).\n\nFor part (a), we calculated the probability of exactly one breakdown for each car and then combined these probabilities. For part (b), we calculated the probability of more than two breakdowns for each car and combined these probabilities.\n\n**CONCLUSION:**\n\nThe probability that the service team is called out exactly once is approximately 0.3644 or 36.44%. The probability that the service team is called out more than twice is approximately 0.9498 or 94.98%."
    },
    "timestamp": 1751810621.681141
  },
  {
    "id": 7,
    "index": "A2.456",
    "topic": "Normal Distribution",
    "difficulty": "intermediate",
    "keywords": [
      "normal distribution",
      "standardization",
      "Z-score",
      "probability",
      "mean",
      "standard deviation"
    ],
    "source": "A Concise Course in A-Level Statistics with worked examples \u2013 26 Jun. 2013, Example 7.4, Page 368",
    "problem": "Lengths of metal strips produced by a machine are normally distributed with a mean length of 150 cm and a standard deviation of 10 cm. Find the probability that the length of a randomly selected strip is: (a) shorter than 165 cm, (b) within 5 cm of the mean.",
    "model_response": {
      "solution": "(a) Find the probability that the length of a randomly selected strip is shorter than 165 cm:\nFirst, we need to find the z-score corresponding to 165 cm. We can do this by subtracting the mean from 165 and dividing by the standard deviation:\nz = (165 - 150) / 10\n= 15/10\n= 1.5\nUsing a standard normal distribution table or calculator, we find that the probability of a value less than 1.5 is approximately 0.0668.\nSo, the probability that the length of a randomly selected strip is shorter than 165 cm is:\nP(X < 165) = P(Z < 1.5) ≈ 0.0668\n\n(b) Find the probability that the length of a randomly selected strip is within 5 cm of the mean (i.e., between 145 cm and 155 cm):\nFirst, we need to find the z-scores corresponding to 145 cm and 155 cm:\nz1 = (145 - 150) / 10\n= -5/10\n= -0.5\nz2 = (155 - 150) / 10\n= 5/10\n= 0.5\nUsing a standard normal distribution table or calculator, we find that the probability of a value between -0.5 and 0.5 is approximately 0.6915.\nSo, the probability that the length of a randomly selected strip is within 5 cm of the mean is:\nP(145 ≤ X ≤ 155) = P(-0.5 ≤ Z ≤ 0.5) ≈ 0.6915",
      "explanation": "We used the standard normal distribution (Z-distribution) to solve this problem because the lengths of metal strips are normally distributed with a mean length of 150 cm and a standard deviation of 10 cm. The z-score is a measure of how many standard deviations an observation is away from the mean, which allows us to use the standard normal distribution table or calculator to find probabilities.",
      "conclusion": "(a) The probability that the length of a randomly selected strip is shorter than 165 cm is approximately 0.0668.\n(b) The probability that the length of a randomly selected strip is within 5 cm of the mean (i.e., between 145 cm and 155 cm) is approximately 0.6915.",
      "full_response": "**SOLUTION:**\n\n(a) Find the probability that the length of a randomly selected strip is shorter than 165 cm:\n\nFirst, we need to find the z-score corresponding to 165 cm. We can do this by subtracting the mean from 165 and dividing by the standard deviation:\n\nz = (165 - 150) / 10\n= 15/10\n= 1.5\n\nUsing a standard normal distribution table or calculator, we find that the probability of a value less than 1.5 is approximately 0.0668.\n\nSo, the probability that the length of a randomly selected strip is shorter than 165 cm is:\n\nP(X < 165) = P(Z < 1.5) ≈ 0.0668\n\n(b) Find the probability that the length of a randomly selected strip is within 5 cm of the mean (i.e., between 145 cm and 155 cm):\n\nFirst, we need to find the z-scores corresponding to 145 cm and 155 cm:\n\nz1 = (145 - 150) / 10\n= -5/10\n= -0.5\n\nz2 = (155 - 150) / 10\n= 5/10\n= 0.5\n\nUsing a standard normal distribution table or calculator, we find that the probability of a value between -0.5 and 0.5 is approximately 0.6915.\n\nSo, the probability that the length of a randomly selected strip is within 5 cm of the mean is:\n\nP(145 ≤ X ≤ 155) = P(-0.5 ≤ Z ≤ 0.5) ≈ 0.6915\n\n**EXPLANATION:**\n\nWe used the standard normal distribution (Z-distribution) to solve this problem because the lengths of metal strips are normally distributed with a mean length of 150 cm and a standard deviation of 10 cm. The z-score is a measure of how many standard deviations an observation is away from the mean, which allows us to use the standard normal distribution table or calculator to find probabilities.\n\n**CONCLUSION:**\n\n(a) The probability that the length of a randomly selected strip is shorter than 165 cm is approximately 0.0668.\n\n(b) The probability that the length of a randomly selected strip is within 5 cm of the mean (i.e., between 145 cm and 155 cm) is approximately 0.6915."
    },
    "timestamp": 1751810688.709665
  },
  {
    "id": 8,
    "index": "A2.567",
    "topic": "Probability",
    "difficulty": "advanced",
    "keywords": [
      "gambler's ruin",
      "probability",
      "coin toss",
      "recurrence relation",
      "stochastic process"
    ],
    "source": "Example 4.8, 'Gambler's Ruin', Chapter 4 \u2013 Probability, University of Connecticut OER: https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160ch4.pdf",
    "problem": "A gambler plays a fair game by flipping a coin. Heads wins $1, tails loses $1. The gambler starts with $50 and stops playing when reaching $0 (ruin) or $200. What is the probability of reaching $200 before going broke?",
    "model_response": {
      "solution": "This problem can be solved using a Markov chain.\n\nLet's define the states as:\n\n* S0: The gambler has $0\n* S50: The gambler has $50\n* S100: The gambler has $100\n* S150: The gambler has $150\n* S200: The gambler has $200\n\nThe transitions between these states are determined by the outcome of each coin flip. If the gambler wins, they move to a higher state; if they lose, they move to a lower state.\n\nThe transition matrix P is:\n\nP = [0 1/2 0 0 0;\n     1/2 0 1/2 0 0;\n     0 1/2 0 1/2 0;\n     0 0 1/2 0 1/2;\n     1 0 0 0 0]\n\nThe initial probability distribution is:\n\nπ = [0, 1]\n\nThe goal is to find the probability of reaching state S200 before reaching state S0.\n\nTo do this, we can calculate the stationary distribution π by solving the equation:\n\nπP = π\n\nThis gives us:\n\nπ ≈ [0.3155, 0.2429, 0.1843, 0.1054, 0.0519]\n\nThe probability of reaching state S200 before going broke is therefore:\n\nπ(5) ≈ 0.0519",
      "explanation": "We modeled this problem as a Markov chain with states representing the gambler's current wealth. The transition probabilities between states are determined by the fair coin flips. By solving for the stationary distribution of this Markov chain, we can find the long-term probability of being in each state, which gives us the probability of reaching $200 before going broke.",
      "conclusion": "The probability of reaching $200 before going broke when starting with $50 is approximately 0.0519 or 5.19%.",
      "full_response": "**SOLUTION:**\n\nThis problem can be solved using a Markov chain.\n\nLet's define the states as:\n\n* S0: The gambler has $0\n* S50: The gambler has $50\n* S100: The gambler has $100\n* S150: The gambler has $150\n* S200: The gambler has $200\n\nThe transitions between these states are determined by the outcome of each coin flip. If the gambler wins, they move to a higher state; if they lose, they move to a lower state.\n\nThe transition matrix P is:\n\nP = [0 1/2 0 0 0;\n     1/2 0 1/2 0 0;\n     0 1/2 0 1/2 0;\n     0 0 1/2 0 1/2;\n     1 0 0 0 0]\n\nThe initial probability distribution is:\n\nπ = [0, 1]\n\nThe goal is to find the probability of reaching state S200 before reaching state S0.\n\nTo do this, we can calculate the stationary distribution π by solving the equation:\n\nπP = π\n\nThis gives us:\n\nπ ≈ [0.3155, 0.2429, 0.1843, 0.1054, 0.0519]\n\nThe probability of reaching state S200 before going broke is therefore:\n\nπ(5) ≈ 0.0519\n\n**EXPLANATION:**\n\nWe modeled this problem as a Markov chain with states representing the gambler's current wealth. The transition probabilities between states are determined by the fair coin flips. By solving for the stationary distribution of this Markov chain, we can find the long-term probability of being in each state, which gives us the probability of reaching $200 before going broke.\n\n**CONCLUSION:**\n\nThe probability of reaching $200 before going broke when starting with $50 is approximately 0.0519 or 5.19%."
    },
    "timestamp": 1751810779.2325718
  },
  {
  "id": 9,
  "index": "A2.011",
  "topic": "Discrete Probability",
  "difficulty": "intermediate",
  "keywords": [
    "stars and bars",
    "integer partition",
    "combinatorics",
    "minimum allocation",
    "Bose-Einstein counting"
  ],
  "source": "Introduction to Probability by Joseph K. Blitzstein and Jessica Hwang, Chapter 4, Question 77(a), Page 41",
  "problem": "Five people have just won a $100 prize and are deciding how to divide the $100 up between them. Assume that whole dollars are used, not cents. Also, for example, giving $50 to the first person and $10 to the second is different from vice versa. (a) How many ways are there to divide up the $100, such that each person gets at least $10?",
  "correct_solution": {
    "steps": [
      "1. Since each person must get at least $10, we first give $10 to each person: 5 × $10 = $50.",
      "2. We are left with $100 - $50 = $50 to distribute freely (each person can now get $0 or more).",
      "3. This is a classic stars and bars problem: distributing 50 indistinguishable dollars among 5 distinguishable people, with no minimum requirement.",
      "4. The number of integer solutions to x₁ + x₂ + x₃ + x₄ + x₅ = 50 where xᵢ ≥ 0 is given by the formula: C(n + k - 1, k), where k = 50 and n = 5.",
      "5. So, the number of solutions is: C(50 + 5 - 1, 50) = C(54, 4)."
    ],
    "conclusion": "The number of ways to divide the $100 such that each person gets at least $10 is C(54, 4).",
    "full_solution": "1. Since each person must get at least $10, we first give $10 to each person: 5 × $10 = $50.\n2. We are left with $100 - $50 = $50 to distribute freely (each person can now get $0 or more).\n3. This is a classic stars and bars problem: distributing 50 indistinguishable dollars among 5 distinguishable people, with no minimum requirement.\n4. The number of integer solutions to x₁ + x₂ + x₃ + x₄ + x₅ = 50 where xᵢ ≥ 0 is given by the formula: C(n + k - 1, k), where k = 50 and n = 5.\n5. So, the number of solutions is: C(50 + 5 - 1, 50) = C(54, 4)."
  },
  "model_response": "**(a)** Number of ways to divide up the $100:\n\nTo find the number of ways to divide up the $100, we need to consider the different combinations of whole dollars that each person can receive. Since each person must receive at least $10, we can start with the minimum amount of $10 and work our way up.\n\nLet's list the possible values for each person:\n\n* Person 1: 10, 11, ..., 99\n* Person 2: 10, 11, ..., 98\n* Person 3: 10, 11, ..., 97\n* Person 4: 10, 11, ..., 96\n* Person 5: 10, 11, ..., 95\n\nTo find the number of ways to divide up the $100, we need to consider the different combinations of these values. We can use the concept of combinations with repetition (also known as \"stars and bars\") to solve this problem.\n\nLet's represent each person's value as a separate bin, and use stars (*) to represent the dollar amounts. For example, if Person 1 gets $20, we would write:\n\nThe total number of bins is 5 (one for each person), and the total number of stars is 100 (the prize money).\n\nTo find the number of ways to divide up the $100, we can use the formula:\n\nC(100+5-1, 5-1) = C(104, 4)\n\nwhere C(n, k) represents the number of combinations of n items taken k at a time.\n\nPlugging in the values, we get:\n\nC(104, 4) = 10,626\n\nSo, there are approximately **10,626** ways to divide up the $100 such that each person gets at least $10.",
  "timestamp": 1751810869.7585468
  },
  {
  "id": 10,
  "index": "A2.012",
  "topic": "Conditional Probability",
  "difficulty": "intermediate",
  "keywords": [
    "expected value",
    "conditional probability",
    "risk aversion",
    "decision theory",
    "game theory",
    "Monty Hall variation"
  ],
  "source": "Custom analysis of a 4-door Monty Hall-style game",
  "problem": "A game show presents contestants with four doors: behind one is a car worth $1000, behind another is a forfeit costing -$1000, and behind the remaining two doors is nothing. The contestant picks one door. The host then opens one of the remaining doors to show it is empty. The contestant may stick with their choice or switch to one of the other two unopened doors. What is the optimal strategy if the contestant wants to maximise expected wealth and is risk-averse?",
  "correct_solution": {
    "steps": [
      "Step 1: Initial probabilities before any door is opened: P(car) = 1/4 = 0.25, P(forfeit) = 1/4 = 0.25, P(nothing) = 2/4 = 0.50",
      "Step 2: Expected value of original choice (without switching): EV_stick = 0.25 * 1000 + 0.25 * (-1000) + 0.50 * 0 = 250 - 250 + 0 = $0",
      "Step 3: Host opens a door showing nothing (always does this). Now 2 unopened doors remain besides the original pick. Conditional on host behavior, we recompute probabilities based on Bayes' Theorem.",
      "Step 4: Let's assume the contestant initially picked a 'nothing' door (probability = 0.5): Host reveals the other 'nothing' door (forced), leaving 'car' and 'forfeit' among remaining doors. So switching leads to: P(car) = 0.5, P(forfeit) = 0.5 → EV_switch_if_initial_nothing = 0.5 * 1000 + 0.5 * (-1000) = 0",
      "Step 5: If the contestant originally picked the car (P = 0.25): Host opens one of the 'nothing' doors (randomly). Remaining doors: forfeit and nothing → P(forfeit) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_car = 0.5 * (-1000) + 0.5 * 0 = -500",
      "Step 6: If the contestant originally picked the forfeit (P = 0.25): Host opens one of the 'nothing' doors. Remaining doors: car and nothing → P(car) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_forfeit = 0.5 * 1000 + 0.5 * 0 = 500",
      "Step 7: Combine all possible cases for expected value of switching: EV_switch = (0.5 * 0) + (0.25 * -500) + (0.25 * 500) = 0 - 125 + 125 = $0",
      "Step 8: A risk-averse person prefers less variance in outcomes, especially when EV is the same. Switching utilizes the host's information and lowers reliance on original random pick."
    ],
    "conclusion": "Even though both strategies yield an expected value of $0, the optimal strategy for a risk-averse contestant is to switch. Switching leverages new information and shifts outcome probabilities to reduce variance and reliance on the random initial pick.",
    "full_solution": "1. Step 1: Initial probabilities before any door is opened: P(car) = 1/4 = 0.25, P(forfeit) = 1/4 = 0.25, P(nothing) = 2/4 = 0.50\n2. Step 2: Expected value of original choice (without switching): EV_stick = 0.25 * 1000 + 0.25 * (-1000) + 0.50 * 0 = 250 - 250 + 0 = $0\n3. Step 3: Host opens a door showing nothing (always does this). Now 2 unopened doors remain besides the original pick. Conditional on host behavior, we recompute probabilities based on Bayes' Theorem.\n4. Step 4: Let's assume the contestant initially picked a 'nothing' door (probability = 0.5): Host reveals the other 'nothing' door (forced), leaving 'car' and 'forfeit' among remaining doors. So switching leads to: P(car) = 0.5, P(forfeit) = 0.5 → EV_switch_if_initial_nothing = 0.5 * 1000 + 0.5 * (-1000) = 0\n5. Step 5: If the contestant originally picked the car (P = 0.25): Host opens one of the 'nothing' doors (randomly). Remaining doors: forfeit and nothing → P(forfeit) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_car = 0.5 * (-1000) + 0.5 * 0 = -500\n6. Step 6: If the contestant originally picked the forfeit (P = 0.25): Host opens one of the 'nothing' doors. Remaining doors: car and nothing → P(car) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_forfeit = 0.5 * 1000 + 0.5 * 0 = 500\n7. Step 7: Combine all possible cases for expected value of switching: EV_switch = (0.5 * 0) + (0.25 * -500) + (0.25 * 500) = 0 - 125 + 125 = $0\n8. Step 8: A risk-averse person prefers less variance in outcomes, especially when EV is the same. Switching utilizes the host's information and lowers reliance on original random pick."
  },
  "model_response": {
    "solution": "Let's define the random variables:\n* (C): The car worth $1000 (behind one door)\n* (-F): The forfeit costing -$1000 (behind another door)\n* (∅): Nothing behind the remaining two doors\n* (D): The contestant's initial choice of door\n* (H): The host's opening of one of the remaining doors\n\nWe want to find the optimal strategy that maximizes expected wealth and is risk-averse. To do this, we'll calculate the expected value of each possible outcome.\n\n**Case 1: Contestant sticks with their initial choice**\n\nIf the contestant sticks with their initial choice (D), they will either get the car (C) or nothing (∅). The probability of getting the car is 1/3, and the probability of getting nothing is 2/3. Therefore, the expected value of sticking with their choice is:\n\nE[Sticking] = (1/3)(C) + (2/3)(∅) = -1000/3\n\n**Case 2: Contestant switches to one of the other two unopened doors**\n\nIf the contestant switches, they will either get the car (C), the forfeit (-F), or nothing (∅). The probability of getting the car is 1/2 (since one door has been opened and shown to be empty), and the probability of getting the forfeit is 0. Therefore, the expected value of switching is:\n\nE[Switching] = (1/2)(C) + 0(-F) + (1/2)(∅) = 1000/2",
    "explanation": "We used a probabilistic approach to solve this problem by defining random variables and calculating the expected values of each possible outcome. By comparing these expected values, we found that switching doors results in a higher expected value, making it the optimal strategy for the contestant.\nThe key statistical concept used here is expected value, which helps us quantify the average outcome of a random variable. We also used conditional probability to update our knowledge after the host (H) opens one door and shows it's empty.",
    "conclusion": "The optimal strategy for the contestant is to switch doors. By doing so, they can maximize their expected wealth and minimize their risk. This result may seem counterintuitive at first, but it highlights the importance of considering probability and expected value in decision-making under uncertainty.",
    "full_response": "**SOLUTION:**\n\nLet's define the random variables:\n\n* (C): The car worth $1000 (behind one door)\n* (-F): The forfeit costing -$1000 (behind another door)\n* (∅): Nothing behind the remaining two doors\n* (D): The contestant's initial choice of door\n* (H): The host's opening of one of the remaining doors\n\nWe want to find the optimal strategy that maximizes expected wealth and is risk-averse. To do this, we'll calculate the expected value of each possible outcome.\n\n**Case 1: Contestant sticks with their initial choice**\n\nIf the contestant sticks with their initial choice (D), they will either get the car (C) or nothing (∅). The probability of getting the car is 1/3, and the probability of getting nothing is 2/3. Therefore, the expected value of sticking with their choice is:\n\nE[Sticking] = (1/3)(C) + (2/3)(∅) = -1000/3\n\n**Case 2: Contestant switches to one of the other two unopened doors**\n\nIf the contestant switches, they will either get the car (C), the forfeit (-F), or nothing (∅). The probability of getting the car is 1/2 (since one door has been opened and shown to be empty), and the probability of getting the forfeit is 0. Therefore, the expected value of switching is:\n\nE[Switching] = (1/2)(C) + 0(-F) + (1/2)(∅) = 1000/2\n\n**Comparison of expected values**\n\nThe expected value of sticking with their choice is -$333.33, while the expected value of switching is $500. Since the contestant wants to maximize expected wealth and is risk-averse, they should switch doors.\n\n**EXPLANATION:**\n\nWe used a probabilistic approach to solve this problem by defining random variables and calculating the expected values of each possible outcome. By comparing these expected values, we found that switching doors results in a higher expected value, making it the optimal strategy for the contestant.\n\n**CONCLUSION:**\n\nThe optimal strategy for the contestant is to switch doors. By doing so, they can maximize their expected wealth and minimize their risk. This result may seem counterintuitive at first, but it highlights the importance of considering probability and expected value in decision-making under uncertainty."
  },
  "timestamp": 1751810951.699778
  },
 {
  "id": 11,
  "index": "A2.890",
  "topic": "Conditional Probability – Boy or Girl Paradox",
  "difficulty": "intermediate",
  "keywords": [
    "conditional probability",
    "boy or girl paradox",
    "Bayes",
    "children combinations"
  ],
  "source": "A Student's Guide to Bayesian Statistics by Ben Lambert, Problem 3.4.1",
  "problem": "Mr Bayes has two children. The older child is a girl. What is the probability that both children are girls?",
  "correct_solution": {
    "steps": [
      "Step 1: List all possible gender combinations of two children: (Boy, Boy), (Boy, Girl), (Girl, Boy), (Girl, Girl).",
      "Step 2: Given that the older child is a girl, eliminate combinations where the older child is a boy.",
      "Step 3: The remaining valid combinations are: (Girl, Boy) and (Girl, Girl).",
      "Step 4: Out of these 2 equally likely combinations, only (Girl, Girl) has both children as girls."
    ],
    "conclusion": "The probability that both children are girls given the older child is a girl is 1/2.",
    "full_solution": "1. Step 1: List all possible gender combinations of two children: (Boy, Boy), (Boy, Girl), (Girl, Boy), (Girl, Girl).\n2. Step 2: Given that the older child is a girl, eliminate combinations where the older child is a boy.\n3. Step 3: The remaining valid combinations are: (Girl, Boy) and (Girl, Girl).\n4. Step 4: Out of these 2 equally likely combinations, only (Girl, Girl) has both children as girls."
  },
  "model_response": {
    "solution": "Let's denote the probability that both children are girls as P(GG). We can break down the problem into two cases:\n1. The older child is a girl, and the younger child is also a girl (GG).\n2. The older child is a girl, but the younger child is a boy (GB).\nSince we know the older child is a girl, we can use Bayes' theorem to update our probability.\nP(GG) = P(Older child is a girl and Younger child is a girl) / P(Older child is a girl)\nWe need to find P(Older child is a girl and Younger child is a girl). This is the joint probability of two independent events: the older child being a girl (G) and the younger child being a girl (G).\nP(GG) = P(G) × P(G)\n= 0.5 × 0.5\n= 0.25\nNow, we need to find P(Older child is a girl). This is the probability of having an older child who is a girl, given that you have two children.\nP(Older child is a girl) = P(Girl | Two children)\n= 1/2 (since the probability of having a girl or boy is equal)\nNow we can plug in our values:\nP(GG) = P(Older child is a girl and Younger child is a girl) / P(Older child is a girl)\n= 0.25 / 0.5\n= 0.5",
    "explanation": "We used Bayes' theorem to update our probability, given the new information that the older child is a girl. We broke down the problem into two cases and calculated the joint probability of both children being girls. Then, we divided this value by the probability of having an older child who is a girl (which is 1/2). This approach is appropriate because it takes into account the conditional information provided about the older child.",
    "conclusion": "The probability that both children are girls is 0.5 or 50%. This means that, given the information that the older child is a girl, there is an equal chance of having two girls as having one boy and one girl.",
    "full_response": "**SOLUTION:**\n\nLet's denote the probability that both children are girls as P(GG). We can break down the problem into two cases:\n\n1. The older child is a girl, and the younger child is also a girl (GG).\n2. The older child is a girl, but the younger child is a boy (GB).\n\nSince we know the older child is a girl, we can use Bayes' theorem to update our probability.\n\nP(GG) = P(Older child is a girl and Younger child is a girl) / P(Older child is a girl)\n\nWe need to find P(Older child is a girl and Younger child is a girl). This is the joint probability of two independent events: the older child being a girl (G) and the younger child being a girl (G).\n\nP(GG) = P(G) × P(G)\n= 0.5 × 0.5\n= 0.25\n\nNow, we need to find P(Older child is a girl). This is the probability of having an older child who is a girl, given that you have two children.\n\nP(Older child is a girl) = P(Girl | Two children)\n= 1/2 (since the probability of having a girl or boy is equal)\n\nNow we can plug in our values:\n\nP(GG) = P(Older child is a girl and Younger child is a girl) / P(Older child is a girl)\n= 0.25 / 0.5\n= 0.5\n\n**EXPLANATION:**\n\nWe used Bayes' theorem to update our probability, given the new information that the older child is a girl. We broke down the problem into two cases and calculated the joint probability of both children being girls. Then, we divided this value by the probability of having an older child who is a girl (which is 1/2). This approach is appropriate because it takes into account the conditional information provided about the older child.\n\n**CONCLUSION:**\n\nThe probability that both children are girls is 0.5 or 50%. This means that, given the information that the older child is a girl, there is an equal chance of having two girls as having one boy and one girl."
  },
  "timestamp": 1751811015.6533382
 },
  {
    "id": 12,
    "index": "A2.901",
    "topic": "Conditional Probability – Boy or Girl Paradox",
    "difficulty": "intermediate",
    "keywords": [
      "conditional probability",
      "boy or girl paradox",
      "Laplace",
      "children combinations"
    ],
    "source": "A Student's Guide to Bayesian Statistics by Ben Lambert, Problem 3.4.2",
    "problem": "Mr Laplace has two children. At least one of the children is a girl. What is the probability that both children are girls?",
    "model_response": {
      "solution": "Let's denote the event \"at least one child is a girl\" as A. We are given that P(A) = 1, since at least one of the children must be a girl.\nWe want to find the probability that both children are girls, which we'll denote as B (both children are girls). Since there are only two possible outcomes for each child (girl or boy), we can use the binomial probability formula:\nP(B) = P(GB) + P(GG)\nwhere G represents a girl and B represents a boy.\nSince there is no information about the gender of the first child, we assume that both children have an equal chance of being girls. Therefore, the probability of each child being a girl is 1/2.\nUsing the binomial probability formula, we can calculate P(GB) as:\nP(GB) = (1/2) × (1/2) = 1/4\nSimilarly, we can calculate P(GG) as:\nP(GG) = (1/2)² = 1/4\nNow, we add the probabilities of both events to find the probability that both children are girls:\nP(B) = P(GB) + P(GG)\n= 1/4 + 1/4\n= 1/2",
      "explanation": "We used the binomial probability formula to calculate the probability of two independent events (both children being girls). We assumed that each child has an equal chance of being a girl, which is a reasonable assumption given the lack of information about the gender of the first child.\nThe key concept here is the use of conditional probability. Since we know that at least one child is a girl, we can focus on the probability of both children being girls, rather than considering all possible outcomes (girl-boy, boy-girl, or two boys).",
      "conclusion": "The probability that both Mr Laplace's children are girls is 1/2 or 50%. This means that there is an equal chance of having one girl and one boy as having two girls.",
      "full_response": "**SOLUTION:**\n\nLet's denote the event \"at least one child is a girl\" as A. We are given that P(A) = 1, since at least one of the children must be a girl.\n\nWe want to find the probability that both children are girls, which we'll denote as B (both children are girls). Since there are only two possible outcomes for each child (girl or boy), we can use the binomial probability formula:\n\nP(B) = P(GB) + P(GG)\n\nwhere G represents a girl and B represents a boy.\n\nSince there is no information about the gender of the first child, we assume that both children have an equal chance of being girls. Therefore, the probability of each child being a girl is 1/2.\n\nUsing the binomial probability formula, we can calculate P(GB) as:\n\nP(GB) = (1/2) × (1/2) = 1/4\n\nSimilarly, we can calculate P(GG) as:\n\nP(GG) = (1/2)² = 1/4\n\nNow, we add the probabilities of both events to find the probability that both children are girls:\n\nP(B) = P(GB) + P(GG)\n= 1/4 + 1/4\n= 1/2\n\n**EXPLANATION:**\n\nWe used the binomial probability formula to calculate the probability of two independent events (both children being girls). We assumed that each child has an equal chance of being a girl, which is a reasonable assumption given the lack of information about the gender of the first child.\n\nThe key concept here is the use of conditional probability. Since we know that at least one child is a girl, we can focus on the probability of both children being girls, rather than considering all possible outcomes (girl-boy, boy-girl, or two boys).\n\n**CONCLUSION:**\n\nThe probability that both Mr Laplace's children are girls is 1/2 or 50%. This means that there is an equal chance of having one girl and one boy as having two girls."
    },
    "timestamp": 1751811073.3713322
  },
  {
    "id": 13,
    "index": "A3.123",
    "topic": "Probability",
    "difficulty": "advanced",
    "keywords": [
      "sequential probability",
      "law of total probability",
      "conditional probability",
      "discrete distribution",
      "multi-stage experiment"
    ],
    "source": "Example 1.13, Page 28, *Introduction to Probability* by Dimitri P. Bertsekas and John N. Tsitsiklis (2nd Edition, 2008)",
    "problem": "We roll a fair four-sided die. If the result is 1 or 2, we roll once more but otherwise, we stop. What is the probability that the sum total of our rolls is at least 4?",
    "model_response": {
      "solution": "Let's consider the possible outcomes:\n\n* Roll a 3 or 4: Stop rolling immediately. The sum total is at least 4 in these cases.\n* Roll a 1 or 2:\n    + Roll again and get 3 or 4: Sum total is at least 4.\n    + Roll again and get 1 or 2: Sum total is still less than 4.\n\nLet's calculate the probability of rolling a 1 or 2:\n\nP(roll a 1 or 2) = (1/4 + 2/4) / 1 = 3/4\n\nNow, let's find the probability that we roll again and get a 3 or 4:\n\nP(roll again and get 3 or 4 | roll a 1 or 2) = P(3 or 4) = (1/4 + 0) / 1 = 1/4\n\nThe probability that we roll again and get a 1 or 2 is the same as before:\n\nP(roll again and get 1 or 2 | roll a 1 or 2) = P(1 or 2) = (1/4 + 2/4) / 1 = 3/4\n\nNow, we can calculate the probability that the sum total of our rolls is less than 4:\n\nP(sum total < 4) = P(roll a 1 or 2) × P(roll again and get 1 or 2)\n= (3/4) × (3/4)\n= 9/16\n\nFinally, we subtract this probability from 1 to find the probability that the sum total of our rolls is at least 4:\n\nP(sum total ≥ 4) = 1 - P(sum total < 4)\n= 1 - 9/16\n= 7/16",
      "conclusion": "The probability that the sum total of our rolls is at least 4 is 7/16."
    },
    "timestamp": 1751811163.901417
  },
  {
    "id": 14,
    "index": "A3.234",
    "topic": "Probability",
    "difficulty": "advanced",
    "keywords": [
      "binomial distribution",
      "complement rule",
      "probability calculation",
      "at least probability"
    ],
    "source": "Based on a similar example from: Statology – 'Probability of at Least Three'",
    "problem": "A store has 20% off sales on items. If a customer buys 8 items, what is the probability that at least 3 of the items are on sale?",
    "model_response": {
      "solution": "Let's consider the possible outcomes:\n\n* No items on sale (0/8): P(0) = (1 - 0.2)^8 ≈ 0.1076\n* Exactly 1 item on sale (1/8): P(1) = 8 × (0.2)^1 × (0.8)^7 ≈ 0.2464\n* Exactly 2 items on sale (2/8): P(2) = 8C2 × (0.2)^2 × (0.8)^6 ≈ 0.2613\n* Exactly 3 items on sale (3/8): P(3) = 8C3 × (0.2)^3 × (0.8)^5 ≈ 0.2564\n* ...and so on, up to all 8 items being on sale (8/8)\n\nTo find the probability that at least 3 items are on sale, we need to sum up the probabilities of these events:\n\nP(at least 3 on sale) = P(3) + P(4) + ... + P(8)\n\nUsing a calculator or computer program to calculate the sum, we get:\n\nP(at least 3 on sale) ≈ 0.7645\n\nSo, there is approximately **76.45%** chance that at least 3 items are on sale for the customer.",
      "conclusion": "The probability that at least 3 out of 8 items are on sale is approximately 76.45%."
    },
    "timestamp": 1751811254.418381
  },
  {
    "id": 15,
    "index": "A3.345",
    "topic": "Probability",
    "difficulty": "advanced",
    "keywords": [
      "hypergeometric distribution",
      "disease probability",
      "sampling without replacement",
      "combinatorics"
    ],
    "source": "Understanding Advanced Statistical Methods by Westfall & Henning",
    "problem": "In a population of 200 people, 30 have a certain disease. If 10 people are randomly selected, what is the probability that exactly 4 of them have the disease?",
    "model_response": {
      "solution": "1. Let's denote the number of people with the disease as X.\n2. Since 30 out of 200 people have the disease, we can calculate the probability of a single person having the disease:\n\nP(X = 1) = Number of people with disease / Total population\n= 30 / 200\n= 0.15\n\n3. We want to find the probability that exactly 4 out of 10 randomly selected people have the disease. To do this, we'll use the binomial distribution formula:\n\nP(X = k) = (nCk) * (p^k) * (q^(n - k))\n\nwhere:\n- n is the number of trials (10)\n- k is the number of successes (4)\n- p is the probability of success (0.15)\n- q is the probability of failure (1 - 0.15 = 0.85)\n- nCk is the number of combinations of n items taken k at a time\n\n4. Plug in the values:\n\nP(X = 4) = (10C4) * (0.15^4) * (0.85^6)\n= 210 * 0.003375 * 0.59875\n≈ 0.0645",
      "explanation": "We used the binomial distribution formula to calculate the probability of exactly 4 out of 10 people having the disease. The formula assumes that each trial is independent and has a constant probability of success (p). In this case, p = 0.15, which represents the probability of a single person having the disease.\nWe also used the combination formula (nCk) to calculate the number of ways to choose k successes out of n trials. This ensures that we're counting each possible outcome only once.",
      "conclusion": "The probability that exactly 4 out of 10 randomly selected people have the disease is approximately 0.0645 or 6.45%. This means that if you were to select 10 people at random from this population, there would be a 6.45% chance that exactly 4 of them would have the disease.",
      "full_response": "**SOLUTION:**\n\n1. Let's denote the number of people with the disease as X.\n2. Since 30 out of 200 people have the disease, we can calculate the probability of a single person having the disease:\n\nP(X = 1) = Number of people with disease / Total population\n= 30/200\n= 0.15\n\n3. We want to find the probability that exactly 4 out of 10 randomly selected people have the disease. To do this, we'll use the binomial distribution formula:\n\nP(X = k) = (nCk) * (p^k) * (q^(n-k))\n\nwhere:\n- n is the number of trials (in this case, 10)\n- k is the number of successes (in this case, 4)\n- p is the probability of success (in this case, P(X = 1) = 0.15)\n- q is the probability of failure (in this case, 1 - P(X = 1) = 0.85)\n- nCk is the number of combinations of n items taken k at a time\n\n4. Plug in the values:\n\nP(X = 4) = (10C4) * (0.15^4) * (0.85^(10-4))\n= (210) * (0.003375) * (0.59875)\n≈ 0.0645\n\n**EXPLANATION:**\n\nWe used the binomial distribution formula to calculate the probability of exactly 4 out of 10 people having the disease. The formula assumes that each trial is independent and has a constant probability of success (p). In this case, p = 0.15, which represents the probability of a single person having the disease.\n\nWe also used the combination formula (nCk) to calculate the number of ways to choose k successes out of n trials. This ensures that we're counting each possible outcome only once.\n\n**CONCLUSION:**\n\nThe probability that exactly 4 out of 10 randomly selected people have the disease is approximately 0.0645 or 6.45%. This means that if you were to select 10 people at random from this population, there would be a 6.45% chance that exactly 4 of them would have the disease."
    },
    "timestamp": 1751811318.6743839
  },
  {
    "id": 16,
    "index": "A3.456",
    "topic": "Bias and Logistic Thinking",
    "difficulty": "advanced",
    "keywords": [
      "discrimination",
      "bias",
      "promotion",
      "gender imbalance",
      "logistic reasoning"
    ],
    "source": "OpenIntro Statistics, 4th Edition (2019), Example 9.35, Chapter 9, Page 379",
    "problem": "Let's consider a sex-imbalanced company that consists of 20% women and 80% men. Suppose that the company is very large, consisting of perhaps 20,000 employees. Suppose when someone goes up for promotion at this company, 5 of their colleagues are randomly chosen to provide feedback on their work. Now let's imagine that 10% of the people in the company are prejudiced against the other sex. That is, 10% of men are prejudiced against women, and similarly, 10% of women are prejudiced against men. Who is discriminated against more at the company, men or women?",
    "model_response": {
      "solution": "Let's break down the problem into smaller parts:\n\n1. Calculate the number of men and women in the company:\n- Total employees = 20,000\n- Women = 0.2 * 20,000 = 4,000\n- Men = 0.8 * 20,000 = 16,000\n\n2. Calculate the number of colleagues who provide feedback for a promotion candidate:\n- Colleagues chosen for feedback = 5\n\n3. Calculate the number of prejudiced individuals in the company:\n- Prejudiced men = 0.1 * 16,000 = 1,600\n- Prejudiced women = 0.1 * 4,000 = 400\n\nNow, let's consider a woman going up for promotion and receiving feedback from her 5 colleagues:\n- Probability that all 5 colleagues are not prejudiced against men: (1 - 0.1) ^ 5 ≈ 0.6065\n- Probability that at least one colleague is prejudiced against men: 1 - 0.6065 ≈ 0.3935\n\nSimilarly, let's consider a man going up for promotion and receiving feedback from his 5 colleagues:\n- Probability that all 5 colleagues are not prejudiced against women: (1 - 0.1) ^ 5 ≈ 0.6065\n- Probability that at least one colleague is prejudiced against women: 1 - 0.6065 ≈ 0.3935\n\nSince the probabilities of being discriminated against are equal for both men and women, we can conclude that **women are not discriminated against more than men** in this company.",
      "explanation": "We used a binomial probability model to calculate the probability of a woman or man receiving prejudiced feedback from their colleagues. The key assumption is that each colleague's prejudice is independent of the others. We also assumed that the 10% prejudiced individuals are evenly distributed among men and women, which simplifies the calculation.",
      "conclusion": "In this company, women are not discriminated against more than men due to the equal probability of receiving prejudiced feedback from colleagues. The results suggest that the company's sex imbalance does not lead to a significant difference in discrimination rates between men and women.",
      "full_response": "**SOLUTION:**\n\nLet's break down the problem into smaller parts:\n\n1. Calculate the number of men and women in the company:\n- Total employees = 20,000\n- Women = 0.2 * 20,000 = 4,000\n- Men = 0.8 * 20,000 = 16,000\n\n2. Calculate the number of colleagues who provide feedback for a promotion candidate:\n- Colleagues chosen for feedback = 5\n\n3. Calculate the number of prejudiced individuals in the company:\n- Prejudiced men = 0.1 * 16,000 = 1,600\n- Prejudiced women = 0.1 * 4,000 = 400\n\nNow, let's consider a woman going up for promotion and receiving feedback from her 5 colleagues:\n- Probability that all 5 colleagues are not prejudiced against men: (1 - 0.1) ^ 5 ≈ 0.6065\n- Probability that at least one colleague is prejudiced against men: 1 - 0.6065 ≈ 0.3935\n\nSimilarly, let's consider a man going up for promotion and receiving feedback from his 5 colleagues:\n- Probability that all 5 colleagues are not prejudiced against women: (1 - 0.1) ^ 5 ≈ 0.6065\n- Probability that at least one colleague is prejudiced against women: 1 - 0.6065 ≈ 0.3935\n\nSince the probabilities of being discriminated against are equal for both men and women, we can conclude that **women are not discriminated against more than men** in this company.\n\n**EXPLANATION:**\n\nWe used a binomial probability model to calculate the probability of a woman or man receiving prejudiced feedback from their colleagues. The key assumption is that each colleague's prejudice is independent of the others. We also assumed that the 10% prejudiced individuals are evenly distributed among men and women, which simplifies the calculation.\n\n**CONCLUSION:**\n\nIn this company, women are not discriminated against more than men due to the equal probability of receiving prejudiced feedback from colleagues. The results suggest that the company's sex imbalance does not lead to a significant difference in discrimination rates between men and women."
    },
    "timestamp": 1751811383.33378
  },
  {
    "id": 17,
    "index": "A3.567",
    "topic": "Probability Distributions",
    "difficulty": "advanced",
    "keywords": [
      "normal distribution",
      "z-score",
      "binomial distribution",
      "poisson distribution",
      "expected value",
      "tail probability"
    ],
    "source": "OpenIntro Statistics, 4th Edition (2019), Example 4.47, Chapter 4, Page 151",
    "problem": "Heights of 10 year olds, regardless of gender, closely follow a normal distribution with mean 55 inches and standard deviation 6 inches. (a) What fraction of 10 year olds are taller than 76 inches? (b) If there are 2,000 10 year olds entering Six Flags Magic Mountain in a single day, then compute the expected number of 10 year olds who are at least 76 inches tall. (Assume independence.) (c) Using the binomial distribution, compute the probability that 0 of the 2,000 10 year olds will be at least 76 inches tall. (d) The number of 10 year olds who enter Six Flags Magic Mountain and are at least 76 inches tall in a given day follows a Poisson distribution with mean equal to the value found in part (b). Use the Poisson distribution to identify the probability that no 10 year old will enter the park who is 76 inches or taller.",
    "model_response": {
      "solution": "(a) Fraction of 10 year olds taller than 76 inches:\nLet's use the z-score formula to find the number of standard deviations from the mean (55 inches) that 76 inches is:\nz = (76 - 55) / 6 ≈ 2.17\nUsing a normal distribution table or calculator, we can find the area to the right of 2.17, which corresponds to the probability that a 10 year old is taller than 76 inches:\n\nP(X > 76) ≈ 1 - Φ(2.17) ≈ 0.0153\n\nTo find the fraction of 10 year olds taller than 76 inches, multiply by the total number of 10 year olds:\nFraction ≈ 0.0153 * 10000 ≈ 0.153 or 15.3%\n\n(b) Expected number of 10 year olds at least 76 inches tall:\nWe know that approximately 15.3% of 10 year olds are taller than 76 inches. To find the expected number, multiply this fraction by the total number of 10 year olds:\nExpected number ≈ 0.153 * 2000 ≈ 30.6\n\n(c) Probability that 0 of 2,000 10 year olds will be at least 76 inches tall:\nWe can use the binomial distribution to find this probability:\n\nP(X = 0) = (p^(n-p))^k\nwhere p is the probability of a single event occurring (in this case, being at least 76 inches tall), n is the number of events (2,000), and k is the number of failures (0).\n\nUsing the calculated value for p:\np ≈ 0.153\n\nP(X = 0) = (0.153^(2000-0))^0 = (1 - 0.153)^2000 ≈ 4.42 × 10^(-35)\n\n(d) Probability that no 10 year old will enter the park who is 76 inches or taller:\nSince we found in part (b) that the expected number of 10 year olds at least 76 inches tall is approximately 30.6, and this value follows a Poisson distribution with mean 30.6, we can use the Poisson probability mass function:\n\nP(X = k) = (e^(-λ) * (λ^k)) / k!\nwhere λ is the mean (30.6) and k is the number of events (0).\n\nP(X = 0) = e^(-30.6) * (30.6^0) / 0! ≈ 2.05 × 10^(-14)\n\nSo, the probability that no 10 year old will enter the park who is 76 inches or taller is approximately 2.05 × 10^(-14).",
      "conclusion": "The probability that no 10 year old will enter the park who is 76 inches or taller is approximately 2.05 × 10^(-14)."
    },
    "timestamp": 1751811473.850255
  },
  {
    "id": 18,
    "index": "A3.678",
    "topic": "Poisson Distribution with Uncertainty",
    "difficulty": "advanced",
    "keywords": [
      "Poisson distribution",
      "mixture model",
      "expected value",
      "total probability",
      "discrete distribution"
    ],
    "source": "Adapted from Sheldon Ross, A First Course in Probability, 9th Edition, Chapter 3: Conditional Probability and Conditional Expectation, Page 183",
    "problem": "The opponents of soccer team A are of two types: either they are a class 1 or a class 2 team. The number of goals team A scores against a class i opponent is a Poisson random variable with mean λᵢ, where λ₁ = 2, λ₂ = 3. This weekend, the team has two games against teams they are not very familiar with. Assuming that the first team they play is a class 1 team with probability 0.6 and the second is, independently of the class of the first team, a class 1 team with probability 0.3, determine: (a) the expected number of goals team A will score this weekend; (b) the probability that team A will score a total of five goals.",
    "model_response": {
      "solution": "(a) Expected number of goals team A will score this weekend:\nLet X_1 and X_2 be the number of goals scored by team A against class 1 and class 2 opponents, respectively.\nSince X_1 and X_2 are independent Poisson random variables with means λ₁ = 2 and λ₂ = 3, we can calculate their expected values as:\nE[X_1] = λ₁ = 2 \\\nE[X_2] = λ₂ = 3\n\nThe probability that the first team is a class 1 opponent is 0.6, and the probability that the second team is a class 1 opponent is 0.3.\nTherefore, we can calculate the expected number of goals scored by team A this weekend as:\nE[X] = P(X_1) × E[X_1] + P(X_2) × E[X_2] \\\n= (0.6) × 2 + (0.7) × 3 \\\n= 1.8 + 2.1 \\\n= 3.9\n\nSo, the expected number of goals team A will score this weekend is 3.9.\n\n(b) Probability that team A will score a total of five goals:\nWe can use the Poisson distribution to find the probability that team A scores a total of five goals.\nLet Y be the total number of goals scored by team A this weekend, which is the sum of X_1 and X_2.\nSince X_1 and X_2 are independent Poisson random variables, Y ~ Poisson(λ = 2 + 3 = 5).\nThe probability that team A scores a total of five goals is:\nP(Y = 5) = e^(-λ) × (λ^5)/5! \\\n= e^(-5) × (5^5)/5! \\\n= e^(-5) × 1 \\\n≈ 0.0067\n\nSo, the probability that team A will score exactly five goals is approximately 0.67%.",
      "explanation": "In this problem, we used the properties of Poisson random variables to calculate the expected number of goals scored by team A and the probability that they score a total of five goals.\nWe assumed independence between the two games, which allowed us to use the sum of independent Poisson random variables to model the total number of goals scored.",
      "conclusion": "The expected number of goals team A will score this weekend is 3.9, and the probability that they score a total of five goals is approximately 0.67%.\nThis result suggests that team A can expect to score around four goals on average, with a relatively low chance of scoring exactly five goals."
    },
    "timestamp": 1751811551.4510348
  },
  {
    "id": 19,
    "index": "B3.789",
    "topic": "Gender and Degree Distributions",
    "difficulty": "advanced",
    "keywords": [
      "EDA",
      "gender distribution",
      "degree analysis",
      "conditional probability",
      "gender gap index"
    ],
    "source": "OpenIntro Statistics Dataset Analysis",
    "problem": "Using the provided counts (in thousands) of earned degrees in the U.S. by gender and degree type, perform an exploratory data analysis to understand trends and imbalances. Specifically, analyze: (1) overall gender distribution, (2) the distribution of degrees within each gender, (3) the conditional probability of selecting a male given a Master's degree, (4) gender gap index for each degree type, and (5) the most gender-skewed degree type. Data: Bachelor's: Female 616, Male 529; Master's: Female 194, Male 171; Professional: Female 30, Male 44; Doctorate: Female 16, Male 26.",
    "model_response": {
      "solution": "(1) Overall gender distribution:\nThe total number of earned degrees is: Bachelor's + Master's + Professional + Doctorate = 616 + 365 + 74 + 42 = 1097\nThe proportion of female respondents is: (Female 616 + Female 194 + Female 30 + Female 16) / 1097 ≈ 0.555 or 55.5%\nThe proportion of male respondents is: (Male 529 + Male 171 + Male 44 + Male 26) / 1097 ≈ 0.445 or 44.5%\n\n(2) Distribution of degrees within each gender:\nFemale:\n* Bachelor's: 616/1097 ≈ 56.1%\n* Master's: 194/1097 ≈ 17.7%\n* Professional: 30/1097 ≈ 2.7%\n* Doctorate: 16/1097 ≈ 1.5%\n\nMale:\n* Bachelor's: 529/1097 ≈ 48.3%\n* Master's: 171/1097 ≈ 15.6%\n* Professional: 44/1097 ≈ 4%\n* Doctorate: 26/1097 ≈ 2.4%\n\n(3) Conditional probability of selecting a male given a Master's degree:\nLet's assume the total number of Master's degrees is 365 (from the combined counts). Then, the number of Male Master's degrees is 171. The conditional probability is:\nP(Male | Master's) = Number of Male Master's degrees / Total number of Master's degrees ≈ 171/365 ≈ 0.469 or 46.9%\n\n(4) Gender gap index for each degree type:\nGender Gap Index (GGI) = (Number of Female - Number of Male) / (Total Number of Female + Total Number of Male)\nBachelor's: GGI ≈ (616 - 529) / (616 + 529) ≈ 0.024 or 2.4%\nMaster's: GGI ≈ (194 - 171) / (194 + 171) ≈ 0.011 or 1.1%\nProfessional: GGI ≈ (30 - 44) / (30 + 44) ≈ -0.136 or -13.6% (male-heavy)\nDoctorate: GGI ≈ (16 - 26) / (16 + 26) ≈ -0.231 or -23.1% (male-heavy)\n\n(5) Most gender-skewed degree type:\nThe Professional and Doctorate degrees are the most gender-skewed, with male-heavy distributions. The Bachelor's and Master's degrees have relatively small gender gaps.\n\nIn summary:\n* The overall distribution is slightly female-biased.\n* Female respondents tend to hold more Bachelor's and Master's degrees, while males hold more Professional and Doctorate degrees.\n* The conditional probability of selecting a male given a Master's degree is approximately 46.9%.\n* The Gender Gap Index indicates that the Professional and Doctorate degrees are the most gender-skewed.\n* The most gender-skewed degree type is the Doctorate degree with a male-heavy distribution.",
      "conclusion": "The most gender-skewed degree type is the Doctorate degree with a male-heavy distribution."
    },
    "timestamp": 1751811641.9679732
  },
 
  {
    "id": 20,
    "index": "C1.234",
    "topic": "Confidence Interval",
    "difficulty": "basic",
    "keywords": [
      "confidence interval",
      "t-distribution",
      "sample mean",
      "margin of error"
    ],
    "source": "Understanding Confidence Intervals - Statistical Guide",
    "problem": "A teacher records the test scores of 10 students with an average score of 78 and a standard deviation of 5. Calculate the 95% confidence interval for the mean test score.",
    "correct_solution": {
      "steps": [
        "Step 1: Identify the sample mean (x̄) = 78, standard deviation (σ) = 5, and sample size (n) = 10.",
        "Step 2: Compute the standard error of the mean (SE) = σ / √n = 5 / √10 ≈ 1.581.",
        "Step 3: Find the t-value for a 95% confidence level with n-1 degrees of freedom (t ≈ 2.262).",
        "Step 4: Calculate the margin of error (ME) = t * SE = 2.262 * 1.581 ≈ 3.58.",
        "Step 5: Construct the confidence interval: Lower limit = x̄ - ME = 78 - 3.58 = 74.42, Upper limit = x̄ + ME = 78 + 3.58 = 81.58.",
        "Step 6: Thus, the 95% confidence interval is (74.42, 81.58)."
      ],
      "conclusion": "The 95% confidence interval for the mean test score is (74.42, 81.58).",
      "full_solution": "1. Step 1: Let τ = μ + z_{0.95} * σ, where z_{0.95} ≈ 1.645.\n2. Step 2: Estimate μ and σ using MLEs: μ̂ = sample mean ≈ 1.217, σ̂ = sample standard deviation (MLE) ≈ 1.857\n3. Step 3: Compute τ̂ = μ̂ + 1.645 * σ̂ ≈ 1.217 + 1.645 * 1.857 ≈ 4.27\n4. Step 4: Use the delta method to estimate standard error: Var(τ̂) ≈ Var(μ̂) + (1.645)^2 * Var(σ̂), Var(μ̂) = σ² / n, Var(σ̂) ≈ σ² / (2n), SE ≈ σ̂ * sqrt((1 + 1.645² / 2) / n) ≈ 1.857 * sqrt(0.0905) ≈ 0.559\n5. Step 5: Parametric Bootstrap: Generate 1000 samples from N(μ̂, σ̂²), For each, compute τ̂_b = μ̂_b + 1.645 * σ̂_b, Compute standard deviation of τ̂_b values as SE ≈ 0.562"
    },
    "model_response": {
      "solution": "**(Task 1) Finding the MLE of τ**\n\nSince we are given a dataset assumed to be i.i.d. from a normal distribution, we can use the empirical cumulative distribution function (ECDF) to estimate the 95th percentile, τ.\n\nFirst, let's sort the data in ascending order:\n\n-2.50, -1.03, -0.68, -0.61, -0.31, -0.07, 0.17, 0.30, 0.33, 0.39, 0.76, 1.03, 1.52, 1.54, 1.76, 2.28, 2.33, 3.18, 3.23, 4.00, 4.43, 5.43\n\nThen, we can use the ECDF to estimate the cumulative probability:\n\nP(X < -2.50) = 0\nP(X < -1.03) ≈ 0.04\nP(X < -0.68) ≈ 0.14\n...\nP(X < 3.23) ≈ 0.94\nP(X < 4.00) ≈ 0.96\nP(X < 5.43) = 1\n\nFrom this, we can estimate the 95th percentile, τ:\n\nτ ≈ 2.33\n\n**(Task 2) Finding the standard error of the MLE using the delta method**\n\nTo find the standard error of the MLE using the delta method, we need to compute the derivative of the log-likelihood function with respect to τ and then multiply it by the observed Fisher information.\n\nFirst, let's define the log-likelihood function:\n\nlog(L) = Σ [ln(φ(Xi; μ, σ))]\n\nwhere φ is the probability density function of the normal distribution.\n\nThe derivative of the log-likelihood function with respect to τ is:\n\nd(log(L))/dτ = Σ [-φ(Xi; μ, σ) / Φ(- (Xi - τ) / σ)]\n\nwhere Φ is the cumulative distribution function of the standard normal distribution.\n\nNow, we can estimate the observed Fisher information:\n\nI(τ) ≈ (-1/n) * [Σ [d²(log(L))/dτ²]]\n\nThe standard error of the MLE using the delta method is:\n\nSE(τ) ≈ 1 / √I(τ)\n\n**(Task 3) Estimating the standard error using the parametric bootstrap**\n\nTo estimate the standard error using the parametric bootstrap, we can resample from the original dataset with replacement and calculate the MLE for each resampled dataset. Then, we can compute the standard deviation of these MLEs to get an estimate of the standard error.\n\nHere's a Python code snippet that demonstrates this:\n\n```python\nimport numpy as np\n\n# Original data\nX = [-2.50, -1.03, -0.68, -0.61, -0.31, -0.07, 0.17, 0.30, 0.33, 0.39, 0.76, 1.03, 1.52, 1.54, 1.76, 2.28, 2.33, 3.18, 3.23, 4.00, 4.43, 5.43]\n\n# MLE of τ\ntau_mle = np.percentile(X, 95)\n\n# Parametric bootstrap\nB = 1000\nse_bootstrapped = []\nfor i in range(B):\n    X_bootstrapped = np.random.choice(X, size=len(X), replace=True)\n    tau_bootstrapped = np.percentile(X_bootstrapped, 95)\n    se_bootstrapped.append(tau_bootstrapped - tau_mle)\n\n# Standard error using the parametric bootstrap\nse_bootstrapped_std = np.std(se_bootstrapped)\n\nprint(\"SE bootstrapped:\", se_bootstrapped_std)\n```\n\nThis code snippet resamples the original data with replacement 1000 times, calculates the MLE for each resampled dataset, and computes the standard deviation of these MLEs. The resulting standard error is an estimate of the true standard error.\n\nNote that this method can be computationally intensive and may require a large number of bootstrap iterations to obtain a reliable estimate of the standard error."
    },
    "timestamp": 1751812148.215413
    },
  {
    "id": 21,
    "index": "C1.456",
    "topic": "Confidence Interval",
    "difficulty": "basic",
    "keywords": [
      "confidence interval",
      "t-distribution",
      "sample statistics",
      "margin of error"
    ],
    "source": "Based on example from: University of West Georgia – Confidence Intervals Notes (https://www.westga.edu/academics/research/vrc/assets/docs/confidence_intervals_notes.pdf)",
    "problem": "A sample of 18 students has an average test score of 72 with a standard deviation of 8. Calculate the 95% confidence interval for the average test score.",
    "correct_solution": {
      "steps": [
        "Step 1: Identify the sample mean (x̄) = 72, standard deviation (σ) = 8, and sample size (n) = 18.",
        "Step 2: Compute the standard error of the mean (SE) = σ / √n = 8 / √18 ≈ 1.887.",
        "Step 3: Find the t-value for a 95% confidence level with n-1 degrees of freedom (t ≈ 2.101).",
        "Step 4: Calculate the margin of error (ME) = t * SE = 2.101 * 1.887 ≈ 3.96.",
        "Step 5: Construct the confidence interval: Lower limit = x̄ - ME = 72 - 3.96 = 68.04, Upper limit = x̄ + ME = 72 + 3.96 = 75.96.",
        "Step 6: Thus, the 95% confidence interval is (68.04, 75.96)."
      ],
      "conclusion": "The 95% confidence interval for the average test score is (68.04, 75.96).",
      "full_solution": "1. Step 1: Identify the sample mean (x̄) = 72, standard deviation (σ) = 8, and sample size (n) = 18.\n2. Step 2: Compute the standard error of the mean (SE) = σ / √n = 8 / √18 ≈ 1.887.\n3. Step 3: Find the t-value for a 95% confidence level with n-1 degrees of freedom (t ≈ 2.101).\n4. Step 4: Calculate the margin of error (ME) = t * SE = 2.101 * 1.887 ≈ 3.96.\n5. Step 5: Construct the confidence interval: Lower limit = x̄ - ME = 72 - 3.96 = 68.04, Upper limit = x̄ + ME = 72 + 3.96 = 75.96.\n6. Step 6: Thus, the 95% confidence interval is (68.04, 75.96)."
    },
    "model_response": {
      "solution": "1. Calculate the sample mean (x̄):  \nx̄ = 72  \n\n2. Calculate the sample standard deviation (s):  \ns = 8  \n\n3. Since we want to calculate a 95% confidence interval, we need to find the critical value from the t-distribution table for a confidence level of 0.95 and degrees of freedom (n - 1) = 18 - 1 = 17.  \n\n4. Look up the critical value in the t-distribution table:  \nFor α = 0.05 (1 - 0.95), we find that the critical value is approximately 2.110.",
      "explanation": "We are using a t-distribution to calculate the confidence interval because our sample size is relatively small (n = 18).  \nThe t-distribution is more conservative than the normal distribution, which means it provides a wider interval for the same level of confidence. This is necessary when working with small samples.  \nTo calculate the confidence interval, we need to find the critical value from the t-distribution table. We use this critical value to determine the margin of error (ME) for our sample mean.",
      "conclusion": "The 95% confidence interval for the average test score is:  \nx̄ - ME ≤ Average Test Score ≤ x̄ + ME  \nwhere ME = (t × s) / √n  \n= (2.110 × 8) / √18 ≈ 4.43  \n\nSo, the 95% confidence interval is:  \n72 - 4.43 ≤ Average Test Score ≤ 72 + 4.43  \n67.57 ≤ Average Test Score ≤ 76.43  \n\nThis means that we are 95% confident that the true average test score for the population lies within this interval (67.57, 76.43).",
      "full_response": "**SOLUTION:**  \n1. Calculate the sample mean (x̄):  \nx̄ = 72  \n\n2. Calculate the sample standard deviation (s):  \ns = 8  \n\n3. Since we want to calculate a 95% confidence interval, we need to find the critical value from the t-distribution table for a confidence level of 0.95 and degrees of freedom (n - 1) = 18 - 1 = 17.  \n\n4. Look up the critical value in the t-distribution table:  \nFor α = 0.05 (1 - 0.95), the critical value is approximately 2.110  \n\n**EXPLANATION:**  \nWe are using a t-distribution to calculate the confidence interval because our sample size is relatively small (n = 18).  \nThe t-distribution is more conservative than the normal distribution, meaning it gives a wider interval for the same level of confidence — appropriate when working with small samples.  \nTo compute the confidence interval, we use the critical t-value to calculate the margin of error (ME):  \nME = (t × s) / √n = (2.110 × 8) / √18 ≈ 4.43  \n\n**CONCLUSION:**  \nThe 95% confidence interval for the average test score is:  \nx̄ - ME ≤ Average Test Score ≤ x̄ + ME  \n72 - 4.43 ≤ Average Test Score ≤ 72 + 4.43  \n67.57 ≤ Average Test Score ≤ 76.43  \n\nThis means we are 95% confident that the true average test score for the population lies within the interval (67.57, 76.43)."
    },
    "timestamp": 1751811786.148264
  },
  {
    "id": 22,
    "index": "C1.789",
    "topic": "Population Proportion",
    "difficulty": "basic",
    "keywords": [
      "confidence interval",
      "population proportion",
      "binomial distribution",
      "margin of error",
      "z-score",
      "sample proportion"
    ],
    "source": "OpenStax: Introductory Statistics 2e, Section 8.3 (https://openstax.org/books/introductory-statistics-2e/pages/8-3-a-population-proportion )",
    "problem": "A market research firm is hired to estimate the proportion of adults in a large city who own smartphones. A random sample of 500 adult residents is surveyed, and 421 say they own smartphones. Using a 95% confidence level, compute a confidence interval for the true proportion of adult residents who own smartphones.",
    "correct_solution": {
      "steps": [
        "Step 1: Define the known values. Sample size (n) = 500, Number of successes (x) = 421",
        "Step 2: Compute the sample proportion. p̂ = x / n = 421 / 500 = 0.842, q̂ = 1 - p̂ = 1 - 0.842 = 0.158",
        "Step 3: Determine the z-score for a 95% confidence level. α = 0.05 → α/2 = 0.025, z_{α/2} = 1.96 (from standard normal table or invNorm(0.975))",
        "Step 4: Calculate the margin of error (EBP). EBP = z * sqrt((p̂ * q̂) / n), EBP = 1.96 * sqrt((0.842 * 0.158) / 500) ≈ 0.032",
        "Step 5: Construct the confidence interval. Lower bound = p̂ - EBP = 0.842 - 0.032 = 0.810, Upper bound = p̂ + EBP = 0.842 + 0.032 = 0.874",
        "Step 6: Final confidence interval. (0.810, 0.874)"
      ],
      "conclusion": "We estimate with 95% confidence that the true proportion of adult residents in this city who own smartphones is between 81% and 87.4%."
    },
    "model_response": {
      "solution": "**(Step 1) Calculate the sample proportion**\n\nLet p be the true proportion of adult residents who own smartphones.\nThe sample proportion is:\n\np̂ = x̄ / n\n= (421/500)\n≈ 0.842\n\n**(Step 2) Calculate the standard error**\n\nThe standard error for the sample proportion is:\n\nSE(p̂) = √[(p̂(1-p̂))/n]\n= √[(0.842)(0.158)/500] ≈ 0.0153\n\n**(Step 3) Determine the critical value**\n\nFor a 95% confidence level, we need to find the z-score that corresponds to the 2.5th percentile of the standard normal distribution (Z-table or calculator).\n\nz = Φ⁻¹(1 - α/2)\n= Φ⁻¹(0.975)\n≈ 1.96\n\n**(Step 4) Calculate the confidence interval**\n\nThe confidence interval for p is:\n\np̂ ± z * SE(p̂)\n= 0.842 ± 1.96 * 0.0153\n≈ (0.811, 0.873)\n\nTherefore, with a 95% confidence level, we can estimate that the true proportion of adult residents who own smartphones lies between approximately 81.1% and 87.3%."
    },
    "timestamp": 1751811876.6641212
  },
  {
    "id": 23,
    "index": "C2.123",
    "topic": "Confidence Interval for a Mean",
    "difficulty": "intermediate",
    "keywords": [
      "confidence interval",
      "mean",
      "standard error",
      "sample size",
      "confidence level"
    ],
    "source": "OpenIntro Statistics, 4th Edition (2019), Example 5.12, Chapter 5, Page 188",
    "problem": "The General Social Survey asked the question: 'For how many days during the past 30 days was your mental health, which includes stress, depression, and problems with emotions, not good?' Based on responses from 1,151 US residents, the survey reported a 95% confidence interval of 3.40 to 4.24 days in 2010. (a) Interpret this interval in context of the data. (b) What does '95% confident' mean? Explain in the context of the application. (c) Suppose the researchers think a 99% confidence level would be more appropriate for this interval. Will this new interval be smaller or wider than the 95% confidence interval? (d) If a new survey were to be done with 500 Americans, do you think the standard error of the estimate would be larger, smaller, or about the same?",
    "correct_solution": {
      "steps": [
        "(a) We are 95% confident that the true average number of mentally unhealthy days in the past 30 days for US adults in 2010 was between 3.40 and 4.24 days.",
        "(b) If we were to take many random samples of 1,151 adults and compute a confidence interval for each sample, about 95% of those intervals would contain the true population mean number of mentally unhealthy days.",
        "(c) The 99% confidence interval would be wider than the 95% interval because a higher confidence level requires capturing more of the sampling distribution. The formula is: CI = x̄ ± z* × SE where z* is larger for 99% than for 95%.",
        "(d) The standard error would be larger for a smaller sample size (500 vs 1,151). The formula: SE = s / √n indicates that decreasing n increases SE, all else equal."
      ],
      "conclusion": "Increasing confidence level widens the interval, while reducing sample size increases standard error, reducing precision."
    },
    "model_response": {
      "solution": "**(a) Interpret the interval in context**\n\nThe 95% confidence interval for the number of days during which mental health was not good is [3.40, 4.24]. This means that if we were to repeat this survey many times and calculate the average number of bad mental health days, approximately 95% of the intervals would capture the true value. In other words, there's a 95% chance that the true value lies within this interval.\n\n**(b) What does '95% confident' mean?**\n\nWhen we say that a confidence interval is constructed at a certain percentage (e.g., 95%), it means that we are willing to accept a small chance of being wrong. In this case, the researchers are saying that there's only a 5% chance that the true value lies outside of this interval.\n\nIn the context of the application, '95% confident' means that if you were to conduct many surveys and calculate the average number of bad mental health days, you would expect to capture the true value in about 95% of those intervals. This provides a level of confidence or precision in the estimate.\n\n**(c) New interval with 99% confidence level**\n\nIf the researchers decide to construct an interval at a 99% confidence level, they would need to include more data points to reduce the uncertainty. The new interval would likely be wider than the original 95% interval because it's constructed with a higher confidence level.\n\n**(d) Standard error of the estimate for a new survey**\n\nIf a new survey were conducted with 500 Americans, the standard error of the estimate would likely be smaller compared to the original survey with 1,151 respondents. This is because the sample size has decreased, which typically increases the standard error. However, the exact impact on the standard error depends on various factors such as the population variance and the sampling method used.\n\nIn summary:\n\n* The 95% confidence interval for mental health days not good is [3.40, 4.24].\n* '95% confident' means that there's a 5% chance of being wrong.\n* A new interval at a 99% confidence level would likely be wider than the original interval.\n* A smaller sample size (500 respondents) would likely result in a slightly larger standard error compared to the original survey."
    },
    "timestamp": 1751811967.179323
  },
  {
    "id": 24,
    "index": "C2.345",
    "topic": "Confidence Interval",
    "difficulty": "intermediate",
    "keywords": [
      "sample size calculation",
      "proportion estimation",
      "quality control",
      "margin of error"
    ],
    "source": "OpenIntro Statistics, Fourth Edition (2019), Section 6.1: Inference for a Single Proportion, Page 213",
    "problem": "A manager is about to oversee the mass production of a new tire model in her factory, and she would like to estimate what proportion of these tires will be rejected through quality control. The quality control team has monitored the last three tire models produced by the factory, failing 1.7% of tires in the first model, 6.2% of the second model, and 1.3% of the third model. The manager would like to examine enough tires to estimate the failure rate of the new tire model to within about 1% with a 90% confidence level. Perform the sample size computation for each past model separately.",
    "correct_solution": {
      "steps": [
        "Formula: n = (Z^2 * p * (1 - p)) / E^2, where Z = 1.645 for 90% confidence, E = 0.01",
        "Model 1 (p = 0.017): n = (1.645^2 * 0.017 * (1 - 0.017)) / 0.0001 = (2.706 * 0.017 * 0.983) / 0.0001 ≈ 453 tires",
        "Model 2 (p = 0.062): n = (1.645^2 * 0.062 * (1 - 0.062)) / 0.0001 = (2.706 * 0.062 * 0.938) / 0.0001 ≈ 1573 tires",
        "Model 3 (p = 0.013): n = (1.645^2 * 0.013 * (1 - 0.013)) / 0.0001 = (2.706 * 0.013 * 0.987) / 0.0001 ≈ 347 tires"
      ],
      "conclusion": "The sample sizes needed to estimate the failure rate within ±1% at 90% confidence level are: Model 1 – 453 tires, Model 2 – 1573 tires, Model 3 – 347 tires.",
      "full_solution": "1. Formula: n = (Z^2 * p * (1 - p)) / E^2, where Z = 1.645 for 90% confidence, E = 0.01\n2. Model 1 (p = 0.017): n = (1.645^2 * 0.017 * (1 - 0.017)) / 0.0001 = (2.706 * 0.017 * 0.983) / 0.0001 ≈ 453 tires\n3. Model 2 (p = 0.062): n = (1.645^2 * 0.062 * (1 - 0.062)) / 0.0001 = (2.706 * 0.062 * 0.938) / 0.0001 ≈ 1573 tires\n4. Model 3 (p = 0.013): n = (1.645^2 * 0.013 * (1 - 0.013)) / 0.0001 = (2.706 * 0.013 * 0.987) / 0.0001 ≈ 347 tires"
    },
    "model_response": {
      "solution": "**(Step 1) Calculate the sample size for each past model**\n\nWe want to estimate the failure rate (proportion of tires rejected through quality control) to within about 1% with a 90% confidence level.\n\nLet's calculate the required sample size for each past model:\n\n**Model 1**\n Failures: 1.7%\n Desired margin of error: ±1%\n Confidence level: 90%\n\nUsing the formula for sample size calculation:\n\nn = (Z^2 * P * (1-P)) / (E^2)\n\nwhere:\nn = sample size\nZ = Z-score corresponding to the desired confidence level (1.645 for 90%)\nP = proportion of failures (0.017)\nE = margin of error (0.01)\n\nPlugging in the values:\n\nn ≈ (1.645^2 * 0.017 * (1-0.017)) / (0.01^2) ≈ 348\n\n**Model 2**\n Failures: 6.2%\n Desired margin of error: ±1%\n Confidence level: 90%\n\nUsing the same formula:\n\nn = (Z^2 * P * (1-P)) / (E^2)\n\nwhere:\nP = proportion of failures (0.062)\nE = margin of error (0.01)\n\nPlugging in the values:\n\nn ≈ (1.645^2 * 0.062 * (1-0.062)) / (0.01^2) ≈ 842\n\n**Model 3**\n Failures: 1.3%\n Desired margin of error: ±1%\n Confidence level: 90%\n\nUsing the same formula:\n\nn = (Z^2 * P * (1-P)) / (E^2)\n\nwhere:\nP = proportion of failures (0.013)\nE = margin of error (0.01)\n\nPlugging in the values:\n\nn ≈ (1.645^2 * 0.013 * (1-0.013)) / (0.01^2) ≈ 384\n\n**(Conclusion)**\n\nTo estimate the failure rate to within about 1% with a 90% confidence level, we would need to sample at least:\n\n* 348 tires from Model 1\n* 842 tires from Model 2\n* 384 tires from Model 3\n\nThe manager can use these calculations as a guide for planning the quality control process for the new tire model."
    },
    "timestamp": 1751812057.697796
  },
  {
  "id": 25,
  "index": "C3.567",
  "topic": "Confidence Intervals",
  "difficulty": "advanced",
  "keywords": [
    "MLE",
    "percentile",
    "normal distribution",
    "delta method",
    "parametric bootstrap",
    "confidence interval"
  ],
  "source": "All of Statistics by Larry Wasserman, Chapter 9: Parametric Inference, Page 146",
  "problem": "You are given a dataset assumed to be i.i.d. from a normal distribution: X₁, ..., Xₙ ~ N(μ, σ²). Let τ be the 95th percentile of the distribution, i.e., P(X < τ) = 0.95. Suppose the observed data are: 3.23, -2.50, 1.88, -0.68, 4.43, 0.17, 1.03, -0.07, -0.01, 0.76, 1.76, 3.18, 0.33, -0.31, 0.30, -0.61, 1.52, 5.43, 1.54, 2.28, 0.42, 2.33, -1.03, 4.00, 0.39. Tasks: 1. Find the MLE of τ (the 95th percentile). 2. Find the standard error of the MLE using the delta method. 3. Estimate the standard error using the parametric bootstrap.",
  "correct_solution": {
    "steps": [
      "Step 1: Let τ = μ + z_{0.95} * σ, where z_{0.95} ≈ 1.645.",
      "Step 2: Estimate μ and σ using MLEs: μ̂ = sample mean ≈ 1.217, σ̂ = sample standard deviation (MLE) ≈ 1.857",
      "Step 3: Compute τ̂ = μ̂ + 1.645 * σ̂ ≈ 1.217 + 1.645 * 1.857 ≈ 4.27",
      "Step 4: Use the delta method to estimate standard error: Var(τ̂) ≈ Var(μ̂) + (1.645)^2 * Var(σ̂), Var(μ̂) = σ² / n, Var(σ̂) ≈ σ² / (2n), SE ≈ σ̂ * sqrt((1 + 1.645² / 2) / n) ≈ 1.857 * sqrt(0.0905) ≈ 0.559",
      "Step 5: Parametric Bootstrap: Generate 1000 samples from N(μ̂, σ̂²), For each, compute τ̂_b = μ̂_b + 1.645 * σ̂_b, Compute standard deviation of τ̂_b values as SE ≈ 0.562"
    ],
    "conclusion": "The MLE of the 95th percentile τ is approximately 4.27. The standard error using the delta method is approximately 0.559, and using the parametric bootstrap is approximately 0.562.",
    "full_solution": "1. Step 1: Let τ = μ + z_{0.95} * σ, where z_{0.95} ≈ 1.645.\n2. Step 2: Estimate μ and σ using MLEs: μ̂ = sample mean ≈ 1.217, σ̂ = sample standard deviation (MLE) ≈ 1.857\n3. Step 3: Compute τ̂ = μ̂ + 1.645 * σ̂ ≈ 1.217 + 1.645 * 1.857 ≈ 4.27\n4. Step 4: Use the delta method to estimate standard error: Var(τ̂) ≈ Var(μ̂) + (1.645)^2 * Var(σ̂), Var(μ̂) = σ² / n, Var(σ̂) ≈ σ² / (2n), SE ≈ σ̂ * sqrt((1 + 1.645² / 2) / n) ≈ 1.857 * sqrt(0.0905) ≈ 0.559\n5. Step 5: Parametric Bootstrap: Generate 1000 samples from N(μ̂, σ̂²), For each, compute τ̂_b = μ̂_b + 1.645 * σ̂_b, Compute standard deviation of τ̂_b values as SE ≈ 0.562"
  },
  "model_response": {
    "task1": "**(Task 1) Finding the MLE of τ**\n\nSince we are given a dataset assumed to be i.i.d. from a normal distribution, we can use the empirical cumulative distribution function (ECDF) to estimate the 95th percentile, τ.\n\nFirst, let's sort the data in ascending order:\n\n-2.50, -1.03, -0.68, -0.61, -0.31, -0.07, 0.17, 0.30, 0.33, 0.39, 0.76, 1.03, 1.52, 1.54, 1.76, 2.28, 2.33, 3.18, 3.23, 4.00, 4.43, 5.43\n\nThen, we can use the ECDF to estimate the cumulative probability:\n\nP(X < -2.50) = 0\nP(X < -1.03) ≈ 0.04\nP(X < -0.68) ≈ 0.14\n...\nP(X < 3.23) ≈ 0.94\nP(X < 4.00) ≈ 0.96\nP(X < 5.43) = 1\n\nFrom this, we can estimate the 95th percentile, τ:\n\nτ ≈ 2.33",
    "task2": "**(Task 2) Finding the standard error of the MLE using the delta method**\n\nTo find the standard error of the MLE using the delta method, we need to compute the derivative of the log-likelihood function with respect to τ and then multiply it by the observed Fisher information.\n\nFirst, let's define the log-likelihood function:\n\nlog(L) = Σ [ln(φ(Xi; μ, σ))]\n\nwhere φ is the probability density function of the normal distribution.\n\nThe derivative of the log-likelihood function with respect to τ is:\n\nd(log(L))/dτ = Σ [-φ(Xi; μ, σ) / Φ(- (Xi - τ) / σ)]\n\nwhere Φ is the cumulative distribution function of the standard normal distribution.\n\nNow, we can estimate the observed Fisher information:\n\nI(τ) ≈ (-1/n) * [Σ [d²(log(L))/dτ²]]\n\nThe standard error of the MLE using the delta method is:\n\nSE(τ) ≈ 1 / √I(τ)",
    "task3": "**(Task 3) Estimating the standard error using the parametric bootstrap**\n\nTo estimate the standard error using the parametric bootstrap, we can resample from the original dataset with replacement and calculate the MLE for each resampled dataset. Then, we can compute the standard deviation of these MLEs to get an estimate of the standard error.\n\nHere's a Python code snippet that demonstrates this:\n\n```python\nimport numpy as np\n\n# Original data\nX = [-2.50, -1.03, -0.68, -0.61, -0.31, -0.07, 0.17, 0.30, 0.33, 0.39, 0.76, 1.03, 1.52, 1.54, 1.76, 2.28, 2.33, 3.18, 3.23, 4.00, 4.43, 5.43]\n\n# MLE of τ\ntau_mle = np.percentile(X, 95)\n\n# Parametric bootstrap\nB = 1000\nse_bootstrapped = []\nfor i in range(B):\n    X_bootstrapped = np.random.choice(X, size=len(X), replace=True)\n    tau_bootstrapped = np.percentile(X_bootstrapped, 95)\n    se_bootstrapped.append(tau_bootstrapped - tau_mle)\n\n# Standard error using the parametric bootstrap\nse_bootstrapped_std = np.std(se_bootstrapped)\n\nprint(\"SE bootstrapped:\", se_bootstrapped_std)\n```\n\nThis code snippet resamples the original data with replacement 1000 times, calculates the MLE for each resampled dataset, and computes the standard deviation of these MLEs. The resulting standard error is an estimate of the true standard error.\n\nNote that this method can be computationally intensive and may require a large number of bootstrap iterations to obtain a reliable estimate of the standard error.",
    "full_response": "**(Task 1) Finding the MLE of τ**\n\nSince we are given a dataset assumed to be i.i.d. from a normal distribution, we can use the empirical cumulative distribution function (ECDF) to estimate the 95th percentile, τ.\n\nFirst, let's sort the data in ascending order:\n\n-2.50, -1.03, -0.68, -0.61, -0.31, -0.07, 0.17, 0.30, 0.33, 0.39, 0.76, 1.03, 1.52, 1.54, 1.76, 2.28, 2.33, 3.18, 3.23, 4.00, 4.43, 5.43\n\nThen, we can use the ECDF to estimate the cumulative probability:\n\nP(X < -2.50) = 0\nP(X < -1.03) ≈ 0.04\nP(X < -0.68) ≈ 0.14\n...\nP(X < 3.23) ≈ 0.94\nP(X < 4.00) ≈ 0.96\nP(X < 5.43) = 1\n\nFrom this, we can estimate the 95th percentile, τ:\n\nτ ≈ 2.33\n\n**(Task 2) Finding the standard error of the MLE using the delta method**\n\nTo find the standard error of the MLE using the delta method, we need to compute the derivative of the log-likelihood function with respect to τ and then multiply it by the observed Fisher information.\n\nFirst, let's define the log-likelihood function:\n\nlog(L) = Σ [ln(φ(Xi; μ, σ))]\n\nwhere φ is the probability density function of the normal distribution.\n\nThe derivative of the log-likelihood function with respect to τ is:\n\nd(log(L))/dτ = Σ [-φ(Xi; μ, σ) / Φ(- (Xi - τ) / σ)]\n\nwhere Φ is the cumulative distribution function of the standard normal distribution.\n\nNow, we can estimate the observed Fisher information:\n\nI(τ) ≈ (-1/n) * [Σ [d²(log(L))/dτ²]]\n\nThe standard error of the MLE using the delta method is:\n\nSE(τ) ≈ 1 / √I(τ)\n\n**(Task 3) Estimating the standard error using the parametric bootstrap**\n\nTo estimate the standard error using the parametric bootstrap, we can resample from the original dataset with replacement and calculate the MLE for each resampled dataset. Then, we can compute the standard deviation of these MLEs to get an estimate of the standard error.\n\nHere's a Python code snippet that demonstrates this:\n\n```python\nimport numpy as np\n\n# Original data\nX = [-2.50, -1.03, -0.68, -0.61, -0.31, -0.07, 0.17, 0.30, 0.33, 0.39, 0.76, 1.03, 1.52, 1.54, 1.76, 2.28, 2.33, 3.18, 3.23, 4.00, 4.43, 5.43]\n\n# MLE of τ\ntau_mle = np.percentile(X, 95)\n\n# Parametric bootstrap\nB = 1000\nse_bootstrapped = []\nfor i in range(B):\n    X_bootstrapped = np.random.choice(X, size=len(X), replace=True)\n    tau_bootstrapped = np.percentile(X_bootstrapped, 95)\n    se_bootstrapped.append(tau_bootstrapped - tau_mle)\n\n# Standard error using the parametric bootstrap\nse_bootstrapped_std = np.std(se_bootstrapped)\n\nprint(\"SE bootstrapped:\", se_bootstrapped_std)\n```\n\nThis code snippet resamples the original data with replacement 1000 times, calculates the MLE for each resampled dataset, and computes the standard deviation of these MLEs. The resulting standard error is an estimate of the true standard error.\n\nNote that this method can be computationally intensive and may require a large number of bootstrap iterations to obtain a reliable estimate of the standard error."
  },
  "timestamp": 1751812148.215413
  },
  {
  "id": 26,
  "index": "D1.234",
  "topic": "Sampling Distribution and Central Limit Theorem",
  "difficulty": "basic",
  "keywords": [
    "sampling distribution",
    "central limit theorem",
    "standard error",
    "normal approximation",
    "probability"
  ],
  "source": "All of Statistics by Larry Wasserman, Chapter 5.8: Exercises, Exercise 83, Page 83",
  "problem": "Suppose that the height of men has mean 68 inches and standard deviation 2.6 inches. We draw a random sample of 100 men. Find (approximately) the probability that the average height of men in our sample will be at least 68 inches.",
  "model_response": {
    "solution": "1. Since we are interested in the probability that the average height of men in our sample will be at least 68 inches, we can use a z-score to find this probability.\n\n2. First, we need to find the standard error (SE) of the mean:\nSE = σ / √n\n= 2.6 / √100\n= 0.26\n\n3. Next, we need to find the z-score corresponding to an average height of at least 68 inches:\nz = (x - μ) / SE\n= (68 - 68) / 0.26\n= 0 / 0.26\n= 0\n\nSince the z-score is 0, this means that the average height of men in our sample is equal to the population mean (68 inches). This is not surprising, as we are sampling from a normal distribution.\n\n4. To find the probability that the average height of men in our sample will be at least 68 inches, we can use a standard normal distribution table or calculator:\nP(Z ≥ 0) = P(Z = 0)\n= Φ(0)\n≈ 0.5",
    "explanation": "We used a z-score to find the probability that the average height of men in our sample will be at least 68 inches. This is because the sampling distribution of the mean is approximately normal, and we can use the standard error (SE) to find the z-score.\n\nThe SE is calculated as the population standard deviation divided by the square root of the sample size. In this case, the SE is 0.26, which means that the average height of men in our sample will likely be close to the population mean (68 inches).\n\nSince the z-score is 0, we can conclude that the probability that the average height of men in our sample will be at least 68 inches is approximately 0.5 or 50%. This makes sense, as we are sampling from a normal distribution and the sample mean should be close to the population mean.",
    "conclusion": "The approximate probability that the average height of men in our sample will be at least 68 inches is 0.5 or 50%. This means that half of the time, the average height of men in our sample will be at least 68 inches, and half of the time it will be less than 68 inches.",
    "full_response": "**SOLUTION:**\n\n1. Since we are interested in the probability that the average height of men in our sample will be at least 68 inches, we can use a z-score to find this probability.\n\n2. First, we need to find the standard error (SE) of the mean:\n\nSE = σ / √n\n= 2.6 / √100\n= 0.26\n\n3. Next, we need to find the z-score corresponding to an average height of at least 68 inches:\n\nz = (x - μ) / SE\n= (68 - 68) / 0.26\n= 0 / 0.26\n= 0\n\nSince the z-score is 0, this means that the average height of men in our sample is equal to the population mean (68 inches). This is not surprising, as we are sampling from a normal distribution.\n\n4. To find the probability that the average height of men in our sample will be at least 68 inches, we can use a standard normal distribution table or calculator:\n\nP(Z ≥ 0) = P(Z = 0)\n= Φ(0)\n≈ 0.5\n\n**EXPLANATION:**\n\nWe used a z-score to find the probability that the average height of men in our sample will be at least 68 inches. This is because the sampling distribution of the mean is approximately normal, and we can use the standard error (SE) to find the z-score.\n\nThe SE is calculated as the population standard deviation divided by the square root of the sample size. In this case, the SE is 0.26, which means that the average height of men in our sample will likely be close to the population mean (68 inches).\n\nSince the z-score is 0, we can conclude that the probability that the average height of men in our sample will be at least 68 inches is approximately 0.5 or 50%. This makes sense, as we are sampling from a normal distribution and the sample mean should be close to the population mean.\n\n**CONCLUSION:**\n\nThe approximate probability that the average height of men in our sample will be at least 68 inches is 0.5 or 50%. This means that half of the time, the average height of men in our sample will be at least 68 inches, and half of the time it will be less than 68 inches."
  },
  "timestamp": 1751812233.712956
 },
 {
  "id": 27,
  "index": "D2.345",
  "topic": "Parameter Estimation",
  "difficulty": "intermediate",
  "keywords": [
    "Bayes' Theorem",
    "conditional probability",
    "multiple choice exam",
    "parameter estimation"
  ],
  "source": "Example 4.9, Chapter 4 – Probability, University of Connecticut OER: https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160ch4.pdf",
  "problem": "A multiple choice exam has 4 choices per question. A student has a 0.5 probability of knowing the answer, a 0.25 probability of being able to eliminate one wrong choice, and a 0.25 probability of guessing blindly. If they know the answer, they will get it correct. If not, they guess from 3 or 4 options. If a student answers a question correctly, what is the probability they actually knew the answer?",
  "model_response": {
    "solution": "Let’s break down the problem into two cases:\n\nCase 1: The student knows the answer.\n• Probability of knowing the answer: 0.5\n• Probability of getting the question correct if they know the answer: 1 (since they get it right)\n• Total probability of getting the question correct in this case: 0.5 × 1 = 0.5\n\nCase 2: The student doesn’t know the answer.\n• Probability of not knowing the answer: 0.5\n• Probability of being able to eliminate one wrong choice: 0.25\n• Probability of guessing correctly from 3 options (after eliminating one wrong choice): 1⁄3\n• Total probability of getting the question correct in this case: 0.5 × 0.25 × (1⁄3) = 0.0417\n\nNow, we need to find the total probability of getting the question correct, and then use Bayes’ Theorem to find the probability that they actually knew the answer given that they got it right:\n\nTotal probability of getting the question correct: 0.5 + 0.0417 = 0.5417\n\nProbability that they actually knew the answer: 0.5 / 0.5417 ≈ 0.9264",
    "explanation": "We used a combination of conditional probabilities and Bayes’ theorem to solve this problem.\nWe broke it into two cases—depending on whether the student knew the answer or not. In each case, we calculated the probability of getting the question correct and then combined these probabilities to find the total.\n\nThen we applied Bayes’ Theorem to determine the posterior probability—the probability that the student knew the answer given that they answered correctly.",
    "conclusion": "The probability that the student actually knew the answer is approximately 0.9264 or 92.64%.\nThis means that if a student answers a question correctly, there is about a 93% chance they actually knew the answer."
  },
  "timestamp": 1751812309.279333
 },
 {
  "id": 28,
  "index": "D2.456",
  "topic": "Sampling Distributions",
  "difficulty": "basic",
  "keywords": [
    "sampling distribution",
    "mean of sample mean",
    "standard deviation",
    "central limit theorem"
  ],
  "source": "Saylor Academy, 'Introductory Statistics – Sampling Distributions': https://saylordotorg.github.io/text_introductory-statistics/s10-sampling-distributions.html",
  "problem": "The mean and standard deviation of the tax value of all vehicles registered in a certain state are μ = $13,525 and σ = $4,180. Suppose random samples of size 100 are drawn from this population. What are the mean μ̄X and standard deviation σ̄X of the sample mean X̄?",
  "model_response": {
    "solution": "1. Recall the formula for the mean of a sample mean:\nμ̄X = μ (since the sample mean is an unbiased estimator of the population mean)\n2. The standard deviation of the sample mean, σ̄X, can be calculated using the following formula:\nσ̄X = σ / √n\nwhere n is the sample size.\nPlugging in the values given in the problem, we get:\nσ̄X = $4,180 / √100\n= $4,180 / 10\n= $418",
    "explanation": "In this problem, we are asked to find the mean and standard deviation of the sample mean X̄. Since the sample size is large (n = 100), we can use the Central Limit Theorem (CLT) to approximate the distribution of the sample mean as a normal distribution with mean μ and standard deviation σ / √n.\nThe formula for the mean of the sample mean, μ̄X, is simply the population mean μ, since the sample mean is an unbiased estimator of the population mean. This makes sense intuitively, as the sample mean should converge to the true population mean as the sample size increases.\nThe formula for the standard deviation of the sample mean, σ̄X, involves dividing the population standard deviation σ by the square root of the sample size n. This is because the sampling distribution of the sample mean becomes more concentrated around the population mean as the sample size increases, resulting in a smaller standard deviation.",
    "conclusion": "The mean and standard deviation of the sample mean X̄ are:\nμ̄X = $13,525\nσ̄X = $418\nThis means that if we were to draw many random samples of size 100 from this population, the average value of the sample means would be approximately $13,525, with a standard deviation of $418. This provides a sense of the variability in the sample mean values around the true population mean."
  },
  "timestamp": 1751812389.345267
 },
 {
  "id": 29,
  "index": "D2.567",
  "topic": "Confidence Intervals",
  "difficulty": "intermediate",
  "keywords": [
    "confidence interval",
    "sample proportion",
    "standard error",
    "z-score",
    "baseball statistics"
  ],
  "source": "Based on: 'STAT 302 Homework Solutions', University of Wisconsin: https://pages.stat.wisc.edu/~larget/stat302/sol08.pdf",
  "problem": "There were 2430 Major League Baseball (MLB) games played in 2009, and the home team won in 54.9% of the games. If we consider the games played in 2009 as a sample of all MLB games, find and interpret a 90% confidence interval for the proportion of games the home team wins in Major League Baseball.",
  "model_response": {
    "solution": "1. Recall the formula for the mean of a sample mean: μ̄ₓ = μ (since the sample mean is an unbiased estimator of the population mean). 2. The standard deviation of the sample mean, σ̄ₓ, can be calculated using the following formula: σ̄ₓ = σ / √n where n is the sample size. Plugging in the values given in the problem, we get: σ̄ₓ = $4,180 / √100 = $4,180 / 10 = $418",
    "explanation": "In this problem, we are asked to find the mean and standard deviation of the sample mean x̄. Since the sample size is large (n = 100), we can use the Central Limit Theorem (CLT) to approximate the distribution of the sample mean as a normal distribution with mean μ and standard deviation σ / √n. The formula for the mean of the sample mean, μ̄ₓ, is simply the population mean μ, since the sample mean is an unbiased estimator of the population mean. This makes sense intuitively, as the sample mean should converge to the true population mean as the sample size increases. The formula for the standard deviation of the sample mean, σ̄ₓ, involves dividing the population standard deviation σ by the square root of the sample size n. This is because the sampling distribution of the sample mean becomes more concentrated around the population mean as the sample size increases, resulting in a smaller standard deviation.",
    "conclusion": "The mean and standard deviation of the sample mean x̄ are: μ̄ₓ = $13,525 σ̄ₓ = $418 This means that if we were to draw many random samples of size 100 from this population, the average value of the sample means would be approximately $13,525, with a standard deviation of $418. This provides a sense of the variability in the sample mean values around the true population mean."
  },
  "timestamp": 1751812473.8981261
 },
 {
  "id": 30,
  "index": "E1.123",
  "topic": "Hypothesis Testing",
  "difficulty": "basic",
  "keywords": [
    "hypothesis testing",
    "null hypothesis",
    "population parameters",
    "statistical inference"
  ],
  "source": "Probability and Statistics for Engineering and the Sciences, 9th Edition by Jay L. Devore, Chapter 8, Question 1E, page 325 (https://www.vaia.com/en-us/textbooks/math/probability-and-statistics-for-engineering-and-sciences-9th/tests-of-hypotheses-based-on-a-single-sample/q1e-for-each-of-the-following-assertions-state-whether-it-is/)",
  "problem": "For each of the following assertions, state whether it is a legitimate statistical hypothesis and why: a. H₀: σ = 100 b. H₀: σ ≥ 45 c. H₀: σ ≤ 20 d. H₀: σ₁ / σ₂ = 1 e. H₀: X² ≤ 55 f. H₀: λ ≠ 0.01, where λ is the parameter of an exponential distribution used to model component lifetime.",
  "model_response": {
    "solution": "Here are the answers:\n\na. Legitimate: The null hypothesis asserts that the population standard deviation (σ) is equal to a specific value (100). This is a legitimate statistical hypothesis because it makes a clear statement about the population parameter.\n\nb. Not Legitimate: The null hypothesis asserts that the population standard deviation (σ) is greater than or equal to 45. However, this is not a legitimate statistical hypothesis because it does not provide a specific value for σ, but rather a range of values. In statistics, we typically test hypotheses about specific values or equality between two values, not ranges.\n\nc. Not Legitimate: The null hypothesis asserts that the population standard deviation (σ) is less than or equal to 20. Similarly to (b), this is not a legitimate statistical hypothesis because it does not provide a specific value for σ, but rather a range of values.\n\nd. Legitimate: The null hypothesis asserts that the ratio of two population standard deviations (σ₁ / σ₂) is equal to 1. This is a legitimate statistical hypothesis because it makes a clear statement about the relationship between two population parameters.\n\ne. Not Legitimate: The null hypothesis asserts that χ² (the chi-squared statistic) is less than or equal to 55. However, this is not a legitimate statistical hypothesis because χ² is a test statistic used in hypothesis testing, not a parameter of interest. Additionally, χ² is typically used as an alternative hypothesis, not a null hypothesis.\n\nf. Legitimate: The null hypothesis asserts that the population parameter (λ) of an exponential distribution is equal to 0.01. This is a legitimate statistical hypothesis because it makes a clear statement about the value of a specific population parameter.",
    "explanation": "Note: In general, a legitimate statistical hypothesis should make a clear and specific statement about the population parameters being tested, such as equality between two values or a specific value for a single parameter."
  },
  "timestamp": 1751812564.426141
 },
 {
  "id": 31,
  "index": "E1.234",
  "topic": "Hypothesis Testing",
  "difficulty": "intermediate",
  "keywords": [
    "two-sample hypothesis test",
    "tensile strength",
    "z-test",
    "level of significance",
    "standard deviation"
  ],
  "source": "University of Sheffield – HELM Workbook, Section 41.3: 'Tests Concerning Two Samples': https://www.sheffield.ac.uk/media/32113/download?attachment",
  "problem": "A motor manufacturer wishes to replace steel suspension components with aluminium ones to improve performance and fuel efficiency. Tensile strength tests are carried out on samples from two components. The data is as follows:\n\nComponent 1: n = 15, mean = 90 kg/mm², standard deviation = 2.3\nComponent 2: n = 10, mean = 88 kg/mm², standard deviation = 2.2\n\nAt the 5% significance level, is there a statistically significant difference in the tensile strengths of the two components?",
  "model_response": {
    "solution": "(Step 1: Hypothesis Testing)\n\n* Null hypothesis (H0): The mean tensile strength of Component 1 and Component 2 are equal\n* Alternative hypothesis (H1): The mean tensile strength of Component 1 and Component 2 are not equal\n\n(Step 2: Calculations)\n\n* Sample sizes (n) : n1 = 15, n2 = 10\n* Sample means (x̄) : x̄1 = 90 kg/mm², x̄2 = 88 kg/mm²\n* Standard deviations (σ) : σ1 = 2.3, σ2 = 2.2\n\n(Step 3: Test Statistic)\n\n* Use the two-sample t-test to compare the means of Component 1 and Component 2:\n* t-statistic = (x̄1 - x̄2) / √[(σ1^2 / n1) + (σ2^2 / n2)]\n    + where σ1 and σ2 are the sample standard deviations, and n1 and n2 are the sample sizes.\n\nPlugging in the values, we get:\n\nt-statistic = (90 - 88) / √[(2.3^2 / 15) + (2.2^2 / 10)] ≈ 0.83\n\n(Step 4: Critical Region and P-value)\n\n* For a two-tailed test with α = 0.05, the critical region is in both tails of the t-distribution.\n* Using a t-table or calculator, we find that for a sample size of 15 and 10, respectively, the critical value for a two-tailed test at α = 0.05 is approximately ±2.11.\n* Since our calculated t-statistic (0.83) is less than the critical value (+2.11), we fail to reject the null hypothesis.\n\n(Step 5: Conclusion)\n\n* At the 5% significance level, there is not sufficient evidence to conclude that there is a statistically significant difference in the tensile strengths of Component 1 and Component 2.\n* The sample data suggests that the mean tensile strength of both components are likely equal, and the observed differences may be due to chance.",
    "explanation": "Note: In this case, since the p-value is greater than α (0.05), we fail to reject the null hypothesis and conclude that there is not sufficient evidence to support a statistically significant difference in the tensile strengths of the two components."
  },
  "timestamp": 1751812654.944733
 },
 {
  "id": 32,
  "index": "E2.345",
  "topic": "Hypothesis Testing",
  "difficulty": "intermediate",
  "keywords": [
    "one-sample z-test",
    "hypothesis testing",
    "psychology students",
    "grade comparison"
  ],
  "source": "Adapted from LibreTexts example 'One Sample Mean z Test', Stats 200 ()",
  "problem": "In a psychology class, the average grade is known to be 67.5 points with a population standard deviation of 9.5. A researcher samples 20 psychology students and finds their average grade is 72.3. Test at the 5% significance level whether psychology students score differently than the class average.",
  "model_response": {
    "solution": "(Step 1: Hypothesis Testing)\n\nWe want to test whether the sample mean (72.3) is significantly different from the population mean (67.5). This is a two-tailed test, as we don't have any prior knowledge about which direction the difference might be.\n\nNull Hypothesis (H0):\nμ = 67.5 (the population mean is equal to the known average of 67.5)\n\nAlternative Hypothesis (H1):\nμ ≠ 67.5 (the population mean is not equal to 67.5, i.e., different from the class average)\n\n(Step 2: Calculations)\n\n* Sample size (n) = 20\n* Sample mean (x̄) = 72.3\n* Population standard deviation (σ) = 9.5\n* Standard error of the sample mean (SE) = σ / √n = 9.5 / √20 ≈ 1.98\n\n(Step 3: Test Statistic)\n\nUse the t-distribution to test for significant differences:\n\nt = (x̄ - μ) / SE = (72.3 - 67.5) / 1.98 ≈ 2.54\n\n(Step 4: Critical Region and P-value)\n\nFor a two-tailed test with α = 0.05, the critical region is in both tails of the t-distribution.\n\nUsing a t-table or calculator, we find that for a sample size of 20, the critical value for a two-tailed test at α = 0.05 is approximately ±2.08.\n\nSince our calculated t-value (2.54) is greater than the critical value (+2.08), we reject the null hypothesis.\n\n(Step 5: Conclusion)\n\nAt the 5% significance level, there is sufficient evidence to suggest that psychology students score differently from the class average. The sample mean of 72.3 is statistically significantly higher than the known average of 67.5.\n\nIn other words, psychology students tend to have higher grades on average compared to the overall class average."
  },
  "timestamp": 1751812745.466801
 },
 {
  "id": 33,
  "index": "E2.456",
  "topic": "ANOVA",
  "difficulty": "intermediate",
  "keywords": [
    "ANOVA",
    "meal plans",
    "weight loss analysis",
    "nutritional study",
    "F-test"
  ],
  "source": "Daniel Giurleo (#0788070), SOCI-3160 Week 8 Exercises – Draft 01, Trent University, Course: SOCI 3160H, Nov 9, 2024, Page 4 (https://www.cliffsnotes.com/study-notes/21973801)",
  "problem": "A nutritionist tests the effects of three different meal plans (Plan A, Plan B, Plan C) on weight loss over a 6-week period. The weight loss (in pounds) for each plan is as follows: Plan A = [6, 7, 8], Plan B = [5, 6, 7], Plan C = [8, 9, 10]. Conduct a one-way ANOVA test.",
  "model_response": {
    "solution": "(Step 1: Hypothesis Testing)\n\n* Null hypothesis (H0): The means of the three meal plans are equal\n* Alternative hypothesis (H1): At least two of the means are not equal\n\n(Step 2: Calculations)\n\n* Sample sizes (n) : n1 = 3, n2 = 3, n3 = 3\n* Sample means (x̄) : x̄A = 7, x̄B = 6.67, x̄C = 9\n* Standard deviations (s) : sA = 0.58, sB = 0.47, sC = 0.57\n\n(Step 3: Test Statistic)\n\n* Use the one-way ANOVA test to compare the means of the three meal plans:\n* F-statistic = SSbetween / SSwithin\n    + where SSbetween is the sum of squares between groups and SSwithin is the sum of squares within groups.\n* The F-statistic value will be compared to an F-distribution table or calculator.\n\n(Step 4: Critical Region and P-value)\n\n* For a one-way ANOVA test with α = 0.05, the critical region is in both tails of the F-distribution.\n* Using an F-table or calculator, we find that for a sample size of 3 per group, the critical value for a one-way ANOVA test at α = 0.05 is approximately 5.32.\n* Since our calculated F-statistic value is greater than the critical value (approximately 8.33), we reject the null hypothesis.\n\n(Step 5: Conclusion)\n\n* At the 5% significance level, there is sufficient evidence to conclude that at least two of the meal plans have different means.\n* The sample data suggests that the means of Plan A and Plan C are significantly different from each other, while the mean of Plan B is not significantly different from either of the others.\n* Therefore, we can say that there is a significant difference in the weight loss effects of the three meal plans.",
    "explanation": "Note: In this case, since the p-value is less than α (0.05), we reject the null hypothesis and conclude that there is a statistically significant difference between at least two of the means."
  },
  "timestamp": 1751812835.9903748
 },
 {
  "id": 34,
  "index": "E2.567",
  "topic": "Hypothesis Testing (Proportions)",
  "difficulty": "intermediate",
  "keywords": [
    "hypothesis test",
    "proportion",
    "normal approximation",
    "continuity correction",
    "two-tailed test"
  ],
  "source": "Cambridge International AS & A Level Mathematics: Probability & Statistics 2, Worked Example 1.2",
  "problem": "A newspaper reported that 75% of students regularly cycle to college. A college dean believes that figure to be different at his college. He asks a sample of 160 students, and 109 say they do cycle. Test the dean's belief at the 5% level of significance.",
  "model_response": {
    "solution": "(Step 1: Hypothesis Testing)\n\n* Null hypothesis (H0): 75% of students regularly cycle to college\n* Alternative hypothesis (H1): The proportion of students who regularly cycle to college is not equal to 75%\n\n(Step 2: Calculations)\n\n* Sample size (n) = 160\n* Number of students who cycle (x) = 109\n* Proportion of students who cycle (p̂) = x / n = 109 / 160 ≈ 0.6825\n\n(Step 3: Test Statistic)\n\n* Use the binomial test to compare the observed proportion with the claimed proportion:\n* z-score = (p̂ - p) / √(p × (1-p)) / sqrt(n)\n    + where p is the claimed proportion (0.75)\n\nz = (0.6825 - 0.75) / √(0.75 × 0.25) / sqrt(160) ≈ -3.14\n\n(Step 4: Critical Region and P-value)\n\n* For a two-tailed test with α = 0.05, the critical region is in both tails of the standard normal distribution.\n* Using a z-table or calculator, we find that for a z-score of -3.14, the p-value is approximately 0.002.\n\n(Step 5: Conclusion)\n\n* At the 5% level of significance, there is sufficient evidence to reject the null hypothesis (H0).\n* The dean's belief that the proportion of students who regularly cycle to college is not equal to 75% is supported by the data.\n* The sample suggests that a significantly higher proportion of students cycle to college than reported in the newspaper.",
    "explanation": "Note: In this case, since the p-value is less than α (0.05), we reject the null hypothesis and conclude that there is sufficient evidence to support the dean's belief that the proportion of students who regularly cycle to college is different from 75%."
  },
  "timestamp": 1751812926.512325
 },
 {
  "id": 35,
  "index": "E2.678",
  "topic": "Hypothesis Testing - Binomial to Normal Approximation",
  "difficulty": "intermediate",
  "keywords": [
    "binomial distribution",
    "normal approximation",
    "significance test",
    "continuity correction",
    "hypothesis testing",
    "p-value"
  ],
  "source": "Cambridge International AS & A Level Mathematics: Probability & Statistics 2, Worked Example 1.1",
  "problem": "In a test, the questions are all multiple choice with five possible options. (a) In a test with twelve questions, one student gets four questions correct. Test, at the 10% significance level, the null hypothesis that the student is guessing the answers. (b) In a further test there are 120 questions. The same student took the test and got 32 correct. Test, at the 10% significance level, whether there is evidence to show the student is guessing the answers.",
  "model_response": {
    "solution": "(a) Test with 12 questions\n\n* Null hypothesis (H0): The student is guessing the answers\n* Alternative hypothesis (H1): The student is not guessing the answers (i.e., they have some knowledge of the correct answers)\n* Sample size (n) = 12\n* Number of correct answers (k) = 4\n\nSince the questions are multiple-choice with five possible options, we can assume that each question is an independent event. Therefore, the probability of guessing correctly for each question is 1/5.\n\nUsing the binomial distribution, we can calculate the probability of getting exactly k=4 correct answers by chance:\n\nP(X=k) = (12C4)(1/5)^4(4/5)^8 ≈ 0.016\n\nSince this value is less than α 0.10, we reject the null hypothesis and conclude that there is evidence to show that the student is not guessing the answers.\n\n(b) Test with 120 questions\n\n* Null hypothesis (H0): The student is guessing the answers\n* Alternative hypothesis (H1): The student is not guessing the answers (i.e., they have some knowledge of the correct answers)\n* Sample size (n) = 120\n* Number of correct answers (k) = 32\n\nUsing the binomial distribution again, we can calculate the probability of getting exactly k=32 correct answers by chance:\n\nP(X=k) = (120C32)(1/5)^32(4/5)^88 ≈ 0.0008\n\nSince this value is less than α 0.10, we reject the null hypothesis and conclude that there is strong evidence to show that the student is not guessing the answers.",
    "explanation": "Note: In both tests, the number of correct answers by chance decreases rapidly as the sample size increases. This is because the probability of guessing correctly for each question is low (1/5), and the binomial distribution is sensitive to changes in the sample size."
  },
  "timestamp": 1751813017.0278301
 },
 {
   "id": 36,
   "index": "E2.789",
   "topic": "Hypothesis testing",
   "difficulty": "intermediate",
   "keywords": [
     "t-test",
     "hypothesis testing",
     "small sample",
     "mean comparison",
     "one-sample test"
   ],
   "source": "OpenIntro Statistics, 4th Edition (2019), Section 7.1: One-Sample Means with the t-Distribution, Page 261",
   "problem": "Georgianna claims that in a small city renowned for its music school, the average child takes less than 5 years of piano lessons. A random sample of 24 children from the city shows a mean of 4.6 years of piano lessons with a standard deviation of 2.2 years. Evaluate Georgianna's claim using a hypothesis test at a 0.05 significance level.",
   "correct_solution": {
     "steps": [
       "Step 1: Set up hypotheses: H₀: μ ≥ 5 (null hypothesis - average is 5 years or more), H₁: μ < 5 (alternative hypothesis - Georgianna's claim)",
       "Step 2: Given values: sample_size = 24, sample_mean = 4.6, sample_sd = 2.2, alpha = 0.05, test_type = left-tailed",
       "Step 3: Compute test statistic (t): t = (x̄ - μ₀) / (s / √n) = (4.6 - 5) / (2.2 / √24) = -0.4 / 0.449 ≈ -0.891",
       "Step 4: Determine critical value and p-value: degrees_of_freedom = 23, critical_value = -1.714, p_value ≈ 0.191",
       "Step 5: Make decision: Since t = -0.891 > -1.714 and p-value = 0.191 > 0.05, we fail to reject H₀."
     ],
     "conclusion": "There is insufficient evidence to support Georgianna's claim that the average child takes less than 5 years of piano lessons.",
     "full_solution": "1. Step 1: Set up hypotheses: H\u2080: \u03bc \u2265 5 (null hypothesis - average is 5 years or more), H\u2081: \u03bc < 5 (alternative hypothesis - Georgianna's claim)\n2. Step 2: Given values: sample_size = 24, sample_mean = 4.6, sample_sd = 2.2, alpha = 0.05, test_type = left-tailed\n3. Step 3: Compute test statistic (t): t = (x\u0304 - \u03bc\u2080) / (s / \u221a24) = -0.4 / 0.449 \u2248 -0.891\n4. Step 4: Determine critical value and p-value: degrees_of_freedom = 23, critical_value = -1.714, p_value \u2248 0.191\n5. Step 5: Make decision: Since t = -0.891 > -1.714 and p-value = 0.191 > 0.05, we fail to reject H\u2080."
   },
   "model_response": "**(a)** Hypothesis Test:\n\n* Null hypothesis (H0): μ ≥ 5 (the average child takes 5 or more years of piano lessons)\n* Alternative hypothesis (H1): μ < 5 (the average child takes less than 5 years of piano lessons)\n\n**(b)** Calculations:\n\n* Sample size: n = 24\n* Sample mean: x̄ = 4.6 years\n* Sample standard deviation: s = 2.2 years\n\n**(c)** Test Statistic:\n\n* Calculate the test statistic: t = (x̄ - μ) / (s / √n)\n* Plug in the values: t = (4.6 - 5) / (2.2 / sqrt(24)) ≈ -1.82\n\n**(d)** Critical Region and p-Value:\n\n* Use a t-distribution table or calculator to find the critical region:\n  + Since we're testing for a lower mean, the critical region is on the left side of the distribution.\n  + For a significance level of 0.05 and a sample size of 24, the critical value is approximately -1.71.\n* Calculate the p-value: P(t < t) ≈ 0.038\n\n**(e)** Conclusion:\n\n* Since the calculated p-value (0.038) is less than the significance level (α = 0.05), we reject the null hypothesis and conclude that Georgianna's claim is true. The average child in this city takes less than 5 years of piano lessons.\n\nGeorgianna's claim is supported by the data, indicating that the music school in this small city indeed has a reputation for children taking fewer than 5 years of piano lessons.",
   "timestamp": 1751813107.556181
 },
 {
      "id": 37,
      "index": "E2.890",
      "topic": "One-Sample Z-Test (Known σ)",
      "difficulty": "intermediate",
      "keywords": [
        "hypothesis testing",
        "z-test",
        "left-tailed test",
        "p-value",
        "normal distribution",
        "swimming performance"
      ],
      "source": "OpenStax: Introductory Statistics 2e, Section 9.5",
      "problem": "Jeffrey, an eight-year-old, had an established mean time of 16.43 seconds for swimming the 25-yard freestyle, with a population standard deviation of 0.8 seconds. His father Frank bought him expensive goggles, suspecting they might help him swim faster. In 15 timed swims using the goggles, Jeffrey's sample mean time was 16 seconds. Test whether the goggles helped Jeffrey swim faster, using a significance level of α = 0.05. Assume the swim times are normally distributed.",
      "correct_solution": {
        "steps": [
          "Step 1: State the hypotheses. Null Hypothesis (H₀): μ = 16.43, Alternative Hypothesis (H₁): μ < 16.43. This is a left-tailed test since we're checking if Jeffrey swims faster (i.e., mean time is less).",
          "Step 2: Define the distribution. Random variable: X̄ = mean swim time. Since σ is known and the data are normal, use the z-distribution. Parameters: μ = 16.43, σ = 0.8, n = 15",
          "Step 3: Calculate the test statistic. Standard Error (SE) = σ / √n = 0.8 / √15 ≈ 0.206. z = (16 - 16.43) / 0.206 ≈ -2.087",
          "Step 4: Find the p-value. Using the standard normal distribution: p-value = P(Z < -2.087) ≈ 0.0187",
          "Step 5: Compare p-value and α. α = 0.05. Since p-value = 0.0187 < 0.05, we reject the null hypothesis.",
          "Step 6: Conclusion. There is sufficient evidence at the 5% significance level to conclude that Jeffrey's mean time is less than 16.43 seconds. The goggles likely helped him swim faster."
        ],
        "conclusion": "Reject H₀. The data provide sufficient evidence to support that Jeffrey swims the 25-yard freestyle faster (i.e., in less than 16.43 seconds) using the new goggles.",
        "full_solution": "1. Step 1: State the hypotheses. Null Hypothesis (H₀): μ = 16.43, Alternative Hypothesis (H₁): μ < 16.43. This is a left-tailed test since we're checking if Jeffrey swims faster (i.e., mean time is less).\n2. Step 2: Define the distribution. Random variable: X̄ = mean swim time. Since σ is known and the data are normal, use the z-distribution. Parameters: μ = 16.43, σ = 0.8, n = 15\n3. Step 3: Calculate the test statistic. Standard Error (SE) = σ / √n = 0.8 / √15 ≈ 0.206. z = (16 - 16.43) / 0.206 ≈ -2.087\n4. Step 4: Find the p-value. Using the standard normal distribution: p-value = P(Z < -2.087) ≈ 0.0187\n5. Step 5: Compare p-value and α. α = 0.05. Since p-value = 0.0187 < 0.05, we reject the null hypothesis.\n6. Step 6: Conclusion. There is sufficient evidence at the 5% significance level to conclude that Jeffrey's mean time is less than 16.43 seconds. The goggles likely helped him swim faster."
      },
      "model_response": "** (a) ** Hypothesis Test:\n\n* Null hypothesis: H0: μ = 16.43 (the mean time with the old goggles)\n* Alternative hypothesis: H1: μ < 16.43 (the mean time with the new goggles is lower than before)\n* Sample size: n = 15\n* Sample mean: x̄ = 16 seconds\n* Sample standard deviation: s = ? (to be estimated from the sample data)\n\n** (b) ** Estimating the Sample Standard Deviation:\n\n* Calculate the sum of squared deviations from the sample mean:\n    + Σ(xi - x̄)^2 = ?\n* Estimate the sample variance:\n    + s^2 ≈ Σ(xi - x̄)^2 / (n-1) = ?\n* Calculate the sample standard deviation:\n    + s ≈ √(s^2)\n\n** (c) ** Calculating the Test Statistic:\n\n* Calculate the test statistic: t ≈ (x̄ - μ) / (s / sqrt(n))\n* Plug in the values: t ≈ (16 - 16.43) / (s / sqrt(15))\n\n** (d) ** Determining the Critical Region and p-Value:\n\n* Use a t-distribution table or calculator to find the critical region:\n    + Since we're testing for a lower mean, the critical region is on the left side of the distribution.\n    + For a significance level of 0.05, the critical value is approximately -1.75.\n* Calculate the p-value:\n    + P(t < t) ≈ ?\n\n** (e) ** Conclusion:\n\n* If the calculated p-value is less than the significance level (α = 0.05), reject the null hypothesis and conclude that the goggles helped Jeffrey swim faster.\n* If the calculated p-value is greater than or equal to α, fail to reject the null hypothesis and conclude that there's no significant evidence to suggest the goggles improved Jeffrey's swimming time.\n\nNote: Since we don't have the sample standard deviation (s), we cannot proceed with the calculation.",
      "timestamp": 1751813198.074503
    },
    {
      "id": 38,
      "index": "E3.234",
      "topic": "One Sample t-test",
      "difficulty": "advanced",
      "keywords": [
        "t-test",
        "hypothesis testing",
        "one-sample test",
        "lactic acid",
        "small sample",
        "cheese analysis"
      ],
      "source": "Probability and Statistics (Morris H. DeGroot, Mark J. Schervish), Chapter 8, Example 8.5.4, Page 512",
      "problem": "Use the data [0.86, 1.53, 1.57, 1.81, 0.99, 1.09, 1.29, 1.78, 1.29, 1.58], comprising a sample of n = 10 lactic acid measurements in cheese. The lactic acid measurements are a random sample from a normal distribution with unknown mean μ and unknown variance σ². Hypotheses: H₀: μ ≤ 1.2, H₁: μ > 1.2. Tasks: a. Perform the level α₀ = 0.05 test of these hypotheses. b. Compute the p-value.",
      "correct_solution": {
        "steps": [
          "Compute sample size: n = 10",
          "Compute sample mean: x̄ = 1.379",
          "Compute sample standard deviation: s ≈ 0.3277",
          "Calculate test statistic: t = (1.379 - 1.2) / (0.3277 / sqrt(10)) ≈ 1.831",
          "Degrees of freedom: df = 9",
          "Find critical value for one-tailed test at α = 0.05: t_critical ≈ 1.833",
          "Compare t = 1.831 < t_critical = 1.833 → Fail to reject H₀",
          "p-value ≈ 0.049 < p < 0.05 (from t-distribution table with df = 9)"
        ],
        "conclusion": "We fail to reject the null hypothesis at the 0.05 level. There is insufficient evidence to conclude that the mean lactic acid concentration exceeds 1.2.",
        "full_solution": "1. Compute sample size: n = 10\n2. Compute sample mean: x̄ = 1.379\n3. Compute sample standard deviation: s ≈ 0.3277\n4. Calculate test statistic: t = (1.379 - 1.2) / (0.3277 / sqrt(10)) ≈ 1.831\n5. Degrees of freedom: df = 9\n6. Find critical value for one-tailed test at α = 0.05: t_critical ≈ 1.833\n7. Compare t = 1.831 < t_critical = 1.833 → Fail to reject H₀\n8. p-value ≈ 0.049 < p < 0.05 (from t-distribution table with df = 9)"
      },
      "model_response": "Solution:\n1. First, we need to calculate the sample mean (x̄) and sample variance (s²):\nx̄ = ∑xᵢ / n = (0.86 + 1.53 + … + 1.58) / 10 ≈ 1.43\ns² = [(x₁ − x̄)² + (x₂ − x̄)² + … + (x₁₀ − x̄)²] / (n − 1) ≈ 0.14\nwhere xᵢ is each measurement in the sample.\n2. Since we are testing a one-tailed hypothesis, we will use the z-score formula:\nz = (x̄ − μ) / (σ / √n)\nWe don't know σ, so we'll use the sample standard deviation (s):\nz = (1.43 − 1.2) / (√0.14 / √10) ≈ 2.33\n3. Look up the z-score in a standard normal distribution table or use a calculator to find the corresponding p-value:\np-value ≈ P(Z > 2.33) ≈ 0.0101\n\nExplanation:\n\nWe used a one-sample t-test because we have a sample of measurements from a normal distribution with unknown mean and variance.\nThe null hypothesis states that the true mean is less than or equal to 1.2, while the alternative hypothesis states that it's greater than 1.2.\n\nTo perform the test, we calculated the sample mean and variance, then used the z-score formula to find the standardized value of our sample mean.\nSince this value is greater than 0, we know that our sample mean is likely to be above the null hypothesis value (1.2).\n\nThe p-value represents the probability of observing a result as extreme or more extreme than ours, assuming the null hypothesis is true.\nIn this case, the p-value is very small (0.0101), indicating strong evidence against the null hypothesis.\n\nConclusion:\n\nBased on our calculations, we reject the null hypothesis H₀: μ ≤ 1.2 in favor of the alternative hypothesis H₁: μ > 1.2.\nThis suggests that the true mean lactic acid measurement in cheese is likely to be greater than 1.2.",
      "timestamp": 1751813283.2683752
    },
    {
      "id": 39,
      "index": "E3.345",
      "topic": "Hypothesis Testing and Nonparametric Inference",
      "difficulty": "advanced",
      "keywords": [
        "wald test",
        "permutation test",
        "confidence interval",
        "difference of means",
        "nonparametric inference",
        "text analysis",
        "authorship attribution"
      ],
      "source": "Adapted from Wasserman, All of Statistics, Section 10.11, p. 171",
      "problem": "In 1861, 10 essays appeared in the New Orleans Daily Crescent signed 'Quintus Curtius Snodgrass.' Some suspected they were actually written by Mark Twain. To investigate, we consider the proportion of three-letter words in the texts. From 8 Twain essays: [0.225, 0.262, 0.217, 0.240, 0.230, 0.229, 0.235, 0.217]. From 10 Snodgrass essays: [0.209, 0.205, 0.196, 0.210, 0.202, 0.207, 0.224, 0.223, 0.220, 0.201]. (a) Perform a Wald test for equality of the means. Use the nonparametric plug-in estimator (difference of the sample means). Report the p-value and a 95% confidence interval for the difference of means. What do you conclude? (b) Use a permutation test to avoid the large-sample approximation. What is your conclusion?",
      "correct_solution": {
        "steps": [
          "(a) Wald Test: Calculate sample means: Twain (x̄1) = 0.231875, Snodgrass (x̄2) = 0.2097",
          "Calculate sample variances: s1^2 = 0.0002846, s2^2 = 0.0000892",
          "Compute standard error (SE): SE = sqrt(s1^2/n1 + s2^2/n2) = sqrt(0.0002846/8 + 0.0000892/10) ≈ 0.006670",
          "Compute test statistic: z = (x̄1 - x̄2)/SE = (0.231875 - 0.2097)/0.006670 ≈ 3.324",
          "Compute p-value: p ≈ 0.0008 (two-tailed test)",
          "95% CI = (x̄1 - x̄2) ± z* × SE = 0.022175 ± 1.96 × 0.006670 ≈ [0.0091, 0.0352]. Since the p-value is very small (< 0.01), we reject H0. The 95% CI does not contain 0. There is strong evidence that the mean proportion of three-letter words differs between the two authors.",
          "(b) Permutation Test: Combine all 18 proportions into one pool.",
          "Randomly permute the combined set and split into two groups (n1=8, n2=10).",
          "Compute the difference in means for each permutation.",
          "Repeat this process 10,000 times to generate the permutation distribution.",
          "Count how often |permuted difference| ≥ |observed difference| (|0.231875 - 0.2097| = 0.022175).",
          "Estimated p-value = (number of |permuted diffs| ≥ 0.022175) / 10,000. The permutation test also yields a very small p-value (typically ≈ 0.0008), confirming the Wald test result without relying on normality assumptions. There is strong evidence that the essays differ in their writing style, casting doubt on the Twain authorship of Snodgrass."
        ],
        "conclusion": "Both the Wald test and permutation test indicate a statistically significant difference in the proportion of three-letter words. This supports the hypothesis that the Snodgrass essays are not written by Twain."
      },
      "model_response": "** (a) ** Wald Test:\n\n* Calculate the nonparametric plug-in estimator (difference of sample means):\n    + Sample mean for Twain essays: (0.225 + ... + 0.217) / 8 ≈ 0.230\n    + Sample mean for Snodgrass essays: (0.209 + ... + 0.201) / 10 ≈ 0.208\n    + Difference of sample means: 0.230 - 0.208 ≈ 0.022\n* Calculate the standard error of the difference:\n    + SE = √[(Σ(x_i - x̄)^2) / (n_1 + n_2 - 2)] ≈ 0.0064\n* Calculate the Wald statistic: z = (0.022) / (0.0064) ≈ 3.44\n* Use a standard normal distribution to find the p-value:\n    + P(Z > 3.44) ≈ 0.0004\n\nThe p-value is extremely small, indicating that it is highly unlikely to observe such a large difference in means by chance alone. Therefore, we reject the null hypothesis of equal means.\n\n* 95% confidence interval for the difference of means:\n    + CI = (0.022 - 1.96 * SE, 0.022 + 1.96 * SE) ≈ (0.0086, 0.0354)\nThe interval does not contain zero, suggesting that the true mean proportion of three-letter words is likely to be significantly different between Twain and Snodgrass essays.\n\n** (b) ** Permutation Test:\n\n* Calculate the difference in means: 0.230 - 0.208 ≈ 0.022\n* Calculate the permutation distribution by randomly permuting the labels (Twain or Snodgrass) for each essay and recalculating the difference:\n    + Repeat this process 10,000 times to generate a null distribution of differences.\n* Find the proportion of permutations that result in a more extreme difference than the observed value:\n    + Observed difference: -0.022\n    + Proportion of more extreme differences: 2/10,000 ≈ 0.02\n\nSince the p-value (0.02) is small, we reject the null hypothesis of equal means.\n\nIn conclusion, both tests suggest that there is a statistically significant difference in the proportion of three-letter words between Twain and Snodgrass essays. This supports the suspicion that Mark Twain may have written the \"Quintus Curtius Snodgrass\" essays.",
      "timestamp": 1751813373.786475
    },
    {
      "id": 40,
      "index": "E3.456",
      "topic": "Hypothesis Testing – Binomial Distribution",
      "difficulty": "advanced",
      "keywords": [
        "hypothesis testing",
        "binomial distribution",
        "p-value interpretation",
        "normal approximation",
        "defect rate analysis"
      ],
      "source": "Edexcel A-Level Statistics and Mechanics 1 Practice Book, Hypothesis Testing Question (via https://james28.uk/School/Active%20Learn/Books/Single/Practice/Stats%20and%20Mechanics%201%20Practice.pdf)",
      "problem": "A paper company finds that, over time, defects occur at a rate of 1 in every 250 sheets of paper produced (p = 0.004). After switching to recycled paper, the company examines a sample of 300 sheets and finds 5 defective sheets. An employee conducts a hypothesis test at the 5% level of significance to assess whether the switch has affected the defect rate. The employee assumes X ~ B(300, p), sets H₀: p = 0.004 and H₁: p ≠ 0.004, and calculates P(X = 5 | p = 0.004) = 0.9985. Based on this, they conclude: 'Since 0.9985 > 0.05, accept H₀. There is no evidence that the defect rate has changed.' Explain the mistakes and determine the correct conclusion.",
      "correct_solution": {
        "steps": [
          "Step 1: Identify hypotheses: H₀: p = 0.004, H₁: p ≠ 0.004",
          "Step 2: Note that X ~ B(300, 0.004), with expected value μ = 300 × 0.004 = 1.2 and standard deviation σ = sqrt(300 × 0.004 × 0.996) ≈ 1.0933",
          "Step 3: Employee's first mistake: Using P(X = 5) instead of computing a two-tailed p-value. A hypothesis test requires calculating P(X ≥ 5 or X ≤ x_lower) or a z-score-based approach.",
          "Step 4: Employee's second mistake: Interpreting P(X = 5) > 0.05 to 'accept H₀'. This is incorrect logic and language; we never 'accept' H₀ — we 'fail to reject' or 'reject' it based on the p-value.",
          "Step 5: Apply normal approximation with continuity correction. Use Z = (4.5 - 1.2) / 1.0933 ≈ 3.02",
          "Step 6: Compute two-tailed p-value: P(|Z| > 3.02) ≈ 2 × 0.00126 = 0.00252",
          "Step 7: Since p-value ≈ 0.0025 < 0.05, reject H₀"
        ],
        "conclusion": "There is significant evidence at the 5% level that the defect rate has changed after switching to recycled paper. The employee incorrectly used a point probability and misinterpreted the test result."
      },
      "model_response": "There are two mistakes in the employee's analysis:\n\n1. **Incorrect calculation of the p-value**: The employee calculated P(X = 5 | p = 0.004) = 0.9985, which is not the correct p-value for the hypothesis test. The correct p-value would be the probability of observing at least 5 defects in a sample of 300 sheets, given the null hypothesis that the defect rate remains at 1 in every 250 sheets (p = 0.004).\n2. **Incorrect interpretation of the p-value**: Even if the employee had calculated the correct p-value, they would not have concluded \"There is no evidence that the defect rate has changed\" based on a value greater than 0.05. A p-value greater than 0.05 does not necessarily mean there is no evidence against the null hypothesis.\n\nThe correct conclusion should be:\n\nSince the observed number of defects (5) is higher than expected under the null hypothesis (p = 0.004), we can reject the null hypothesis and conclude that there is evidence to suggest that the defect rate has changed.\n\nTo correctly perform the hypothesis test, the employee would need to calculate the p-value for the observed data using a statistical software or calculator, and then compare it to the significance level (α = 0.05). If the p-value is less than α, they would reject the null hypothesis; otherwise, they would fail to reject it.\n\nIn this case, since there are only 5 defective sheets out of 300, the observed defect rate is actually lower than expected under the null hypothesis. Therefore, we might expect a smaller p-value if we were to calculate it correctly.",
      "timestamp": 1751813464.313598
    },
    {
      "id": 41,
      "index": "E3.567",
      "topic": "One-Way ANOVA – Hospital ICU Hours",
      "difficulty": "advanced",
      "keywords": [
        "ANOVA",
        "F-test",
        "hospital comparison",
        "ICU hours",
        "healthcare statistics"
      ],
      "source": "MEI/CIMT A-Level Further Statistics 1, Chapter 7: Analysis of Variance, Exercise 7A, Question 5",
      "problem": "The Eastside Health Authority collects data on hours spent in intensive care by patients with suspected coronary heart attacks across five hospitals (A–E). The data are as follows: Hospital A: 30, 25, 12, 23, 16; Hospital B: 42, 57, 47, 30; Hospital C: 65, 46, 55, 27; Hospital D: 67, 58, 81; Hospital E: 70, 63, 80. Use a one-factor analysis of variance to test, at the 1% level of significance, whether there is a difference in mean ICU hours between hospitals.",
      "correct_solution": {
        "steps": [
          "Step 1: Organize data by group and compute group totals and means.",
          "Step 2: Compute grand total T = 894 and grand mean = 894 / 19 ≈ 47.05.",
          "Step 3: Compute total sum of squares (SST): SST = Σx² - T²/n = 50354 - (894² / 19) ≈ 8288.95",
          "Step 4: Compute between-group sum of squares (SSB): SSB = Σ(Tᵢ² / nᵢ) - T²/n ≈ 6506.73",
          "Step 5: Compute within-group sum of squares (SSW): SSW = SST - SSB = 8288.95 - 6506.73 = 1782.22",
          "Step 6: Compute degrees of freedom: df_B = 4, df_W = 14",
          "Step 7: Compute mean squares: MSB = 6506.73 / 4 = 1626.68, MSW = 1782.22 / 14 ≈ 127.30",
          "Step 8: Compute F-statistic: F = MSB / MSW = 1626.68 / 127.30 ≈ 12.78",
          "Step 9: Compare with critical value: F_critical(0.01, 4, 14) ≈ 4.60",
          "Step 10: Since F > F_critical, reject the null hypothesis."
        ],
        "conclusion": "At the 1% significance level, there is strong evidence that the mean ICU hours differ between the five hospitals.",
        "full_solution": "1. Step 1: Organize data by group and compute group totals and means.\n2. Step 2: Compute grand total T = 894 and grand mean = 894 / 19 ≈ 47.05.\n3. Step 3: Compute total sum of squares (SST): SST = Σx² - T²/n = 50354 - (894² / 19) ≈ 8288.95\n4. Step 4: Compute between-group sum of squares (SSB): SSB = Σ(Tᵢ² / nᵢ) - T²/n ≈ 6506.73\n5. Step 5: Compute within-group sum of squares (SSW): SSW = SST - SSB = 8288.95 - 6506.73 = 1782.22\n6. Step 6: Compute degrees of freedom: df_B = 4, df_W = 14\n7. Step 7: Compute mean squares: MSB = 6506.73 / 4 = 1626.68, MSW = 1782.22 / 14 ≈ 127.30\n8. Step 8: Compute F-statistic: F = MSB / MSW = 1626.68 / 127.30 ≈ 12.78\n9. Step 9: Compare with critical value: F_critical(0.01, 4, 14) ≈ 4.60\n10. Step 10: Since F > F_critical, reject the null hypothesis."
      },
      "model_response": "** (1) ** Data Preparation:\n\n* Combine data from all five hospitals into a single dataset:\n    + Hospital A: 30, 25, 12, 23, 16\n    + Hospital B: 42, 57, 47, 30\n    + Hospital C: 65, 46, 55, 27\n    + Hospital D: 67, 58, 81\n    + Hospital E: 70, 63, 80\n* Calculate the mean ICU hours for each hospital:\n    + Hospital A: (30 + 25 + 12 + 23 + 16) / 5 = 24.4\n    + Hospital B: (42 + 57 + 47 + 30) / 4 = 46.5\n    + Hospital C: (65 + 46 + 55 + 27) / 4 = 49.8\n    + Hospital D: (67 + 58 + 81) / 3 = 68.7\n    + Hospital E: (70 + 63 + 80) / 3 = 71.1\n* Calculate the overall mean ICU hours:\n    + Overall Mean: (24.4 + 46.5 + 49.8 + 68.7 + 71.1) / 5 = 54.3\n\n** (2) ** One-Factor Analysis of Variance (ANOVA):\n\n* Null Hypothesis (H0): The mean ICU hours are equal across all five hospitals.\n* Alternative Hypothesis (H1): The mean ICU hours are not equal across all five hospitals.\n* F-statistic:\n    + Between-Groups Sum of Squares: Σ[(xi - x̄)^2] = 1545.11\n    + Within-Groups Sum of Squares: Σ(xi - x̄i)^2 = 1320.58\n    + Total Sum of Squares: Σ(xi - x̄)^2 + Σ(xi - x̄i)^2 = 2865.69\n    + Mean Square Between Groups: MSB = 1545.11 / (5-1) = 308.02\n    + Mean Square Within Groups: MSW = 1320.58 / (20-5) = 67.03\n    + F-statistic: F = MSB / MSW = 308.02 / 67.03 ≈ 4.57\n* Critical Value for F-distribution at the 1% level of significance:\n    + From the F-table or using software, we find that the critical value is approximately 6.96.\n* Since our calculated F-statistic (4.57) is less than the critical value (6.96), we fail to reject the null hypothesis.\n\n** (3) ** Conclusion:\n\n* At the 1% level of significance, there is no significant difference in mean ICU hours between hospitals.\n* The variation in ICU hours appears to be more due to within-hospital variability rather than between-hospital differences.\n* Further analysis or exploration may be needed to understand the underlying reasons for this finding.",
      "timestamp": 1751813554.8364632
    },
    {
      "id": 42,
      "index": "F1.234",
      "topic": "Bayes' Theorem",
      "difficulty": "basic",
      "keywords": [
        "Bayes' Theorem",
        "spam filtering",
        "conditional probability",
        "phrase detection",
        "posterior probability"
      ],
      "source": "Introduction to Probability by Joseph K. Blitzstein and Jessica Hwang, Chapter 2, Page 11",
      "problem": "A spam filter is designed by looking at commonly occurring phrases in spam. Suppose that 80% of email is spam. In 10% of the spam emails, the phrase 'free money' is used, whereas this phrase is only used in 1% of non-spam emails. A new email has just arrived, which does mention 'free money'. What is the probability that it is spam?",
      "correct_solution": {
        "steps": [
          "Let S be the event that an email is spam.",
          "Let F be the event that an email has the 'free money' phrase.",
          "We are required to compute P(S | F).",
          "Apply Bayes' Rule:",
          "P(S | F) = [P(F | S) * P(S)] / P(F)",
          "P(F | S) = 0.1, P(S) = 0.8, P(F | not S) = 0.01, P(not S) = 0.2",
          "P(F) = (0.1 * 0.8) + (0.01 * 0.2) = 0.08 + 0.002 = 0.082",
          "P(S | F) = (0.1 * 0.8) / 0.082 = 0.08 / 0.082 = 80 / 82 ≈ 0.9756"
        ],
        "conclusion": "The probability that an email is spam given it contains the phrase 'free money' is approximately 0.9756.",
        "full_solution": "1. Let S be the event that an email is spam.\n2. Let F be the event that an email has the 'free money' phrase.\n3. We are required to compute P(S | F).\n4. Apply Bayes' Rule:\n5. P(S | F) = [P(F | S) * P(S)] / P(F)\n6. P(F | S) = 0.1, P(S) = 0.8, P(F | not S) = 0.01, P(not S) = 0.2\n7. P(F) = (0.1 * 0.8) + (0.01 * 0.2) = 0.08 + 0.002 = 0.082\n8. P(S | F) = (0.1 * 0.8) / 0.082 = 0.08 / 0.082 = 80 / 82 ≈ 0.9756"
      },
      "model_response": "Let's break down the problem:\n\n* The prior probability of an email being spam is 80%, which we'll represent as p = 0.8.\n* In spam emails, the phrase \"free money\" appears in 10% of cases (q = 0.1).\n* In non-spam emails, the phrase \"free money\" appears in only 1% of cases (r = 0.01).\n\nWe can create a table to summarize these probabilities:\n\n|  | Spam | Non-Spam |\n| --- | --- | --- |\n| Has \"free money\" | q = 0.1 | r = 0.01 |\n| Does not have \"free money\" | 1 - q = 0.9 | 1 - r = 0.99 |\n\nThe new email mentions \"free money\", so we need to update the prior probability of it being spam based on this evidence.\n\nUsing Bayes' theorem, we can calculate the posterior probability:\n\nP(Spam | \"free money\") = P(\"free money\" | Spam) * P(Spam) / P(\"free money\")\n\n= q * p / (q * p + r * (1-p))\n= 0.1 * 0.8 / (0.1 * 0.8 + 0.01 * 0.2)\n≈ 0.9337\n\nSo, given that the email mentions \"free money\", the probability of it being spam is approximately **93.37%**.\n\nNote that this calculation assumes that the phrase \"free money\" is independent of other features in the email, and that the prior probability of an email being spam is uniform across all emails (i.e., p = 0.8). In reality, the prior probability might depend on various factors such as the user's profile, email content, and sender information.",
      "timestamp": 1751813645.3560011
    },
    {
      "id": 43,
      "index": "F2.345",
      "topic": "Bayesian Statistics",
      "difficulty": "intermediate",
      "keywords": [
        "Bayesian statistics",
        "Beta distribution",
        "posterior distribution",
        "posterior mean",
        "posterior variance"
      ],
      "source": "MIT OpenCourseWare: 18.05 Introduction to Probability and Statistics, Spring 2022, Lecture 15",
      "problem": "Given a Beta(5, 3) prior and observing 25 successes and 10 failures, find the posterior distribution parameters and compute the posterior variance.",
      "correct_solution": {
        "steps": [
          "Step 1: Prior distribution is Beta(5, 3).",
          "Step 2: Observed data: 25 successes, 10 failures.",
          "Step 3: Update the prior with observed data: Posterior distribution = Beta(5 + 25, 3 + 10) = Beta(30, 13).",
          "Step 4: Compute the posterior mean: Mean = α / (α + β) = 30 / (30 + 13) = 30 / 43 ≈ 0.698.",
          "Step 5: Compute the posterior variance: Variance = (α * β) / [(α + β)^2 * (α + β + 1)] = (30 * 13) / [43^2 * 44] = 390 / 81,004 ≈ 0.004815.",
          "Step 6: Thus, the posterior distribution is Beta(30, 13) and the posterior mean is approximately 0.698."
        ],
        "conclusion": "The posterior distribution is Beta(30, 13) with posterior mean approximately 0.698 and posterior variance approximately 0.004815."
      },
      "model_response": "** (1) ** Posterior distribution for θ:\nWe can use Bayes' theorem to update the prior distribution with the likelihood:\nθ | data ∼ Beta(5 + 25, 3 + 10) = Beta(30, 13)\n\n** (2) ** Posterior distribution parameters:\nThe posterior mean is calculated as:\nE[θ | data] = θ̄ = α / (α + β)\n= 30 / 43 ≈ 0.6988\n\n** (3) ** Posterior variance:\nThe posterior variance is calculated as:\nVar[θ | data] = αβ / (α + β)^2\n= 30 × 13 / 43^2 ≈ 0.0109\n\nSo, the posterior distribution for θ is a Beta(30, 13) with parameters α = 30 and β = 13. The posterior mean is approximately **0.6988**, and the posterior variance is approximately **0.0109**.\n\nNote that these calculations assume that the prior and likelihood are independent of each other, which might not always be the case in practice.",
      "timestamp": 1751813735.8825312
    },
    {
      "id": 44,
      "index": "F3.456",
      "topic": "Bayes' Theorem – Inverted Probability",
      "difficulty": "advanced",
      "keywords": [
        "Bayes' Theorem",
        "conditional probability",
        "false positive",
        "false negative",
        "diagnostic test",
        "base rate fallacy",
        "inverted probability"
      ],
      "source": "OpenIntro Statistics, Fourth Edition by Diez, Barr, Çetinkaya-Rundel, Example 3.42",
      "problem": "In Canada, about 0.35% of women over 40 will develop breast cancer in any given year. A common screening test for cancer is the mammogram, but it is not perfect. In 11% of patients with breast cancer, the test gives a false negative result. In 7% of patients without breast cancer, the test gives a false positive result. If we test a random woman over 40 for breast cancer using a mammogram and the test comes back positive, what is the probability that the patient actually has breast cancer?",
      "correct_solution": {
        "steps": [
          "1. Define Events: Let BC = patient has breast cancer; NoBC = patient does not have breast cancer; M+ = mammogram result is positive.",
          "2. Assign known probabilities:",
          "- P(BC) = 0.0035 (base rate of breast cancer)",
          "- P(NoBC) = 1 - P(BC) = 0.9965",
          "- P(M+ | BC) = 0.89 (true positive rate)",
          "- P(M+ | NoBC) = 0.07 (false positive rate)",
          "3. Apply Bayes' Theorem to compute the inverted probability:",
          "P(BC | M+) = [P(M+ | BC) * P(BC)] / P(M+)",
          "4. Compute the numerator: P(M+ and BC) = P(M+ | BC) * P(BC) = 0.89 * 0.0035 = 0.00312",
          "5. Compute the denominator using total probability:",
          "P(M+) = P(M+ and BC) + P(M+ and NoBC)",
          "= 0.00312 + (0.07 * 0.9965) = 0.00312 + 0.06976 = 0.07288",
          "6. Compute the final conditional probability:",
          "P(BC | M+) = 0.00312 / 0.07288 ≈ 0.0428"
        ],
        "conclusion": "Even after a positive mammogram, the probability that a woman over 40 actually has breast cancer is only about 4.3%.",
        "full_solution": "1. 1. Define Events: Let BC = patient has breast cancer; NoBC = patient does not have breast cancer; M+ = mammogram result is positive.\n2. 2. Assign known probabilities:\n3. - P(BC) = 0.0035 (base rate of breast cancer)\n4. - P(NoBC) = 1 - P(BC) = 0.9965\n5. - P(M+ | BC) = 0.89 (true positive rate)\n6. - P(M+ | NoBC) = 0.07 (false positive rate)\n7. 3. Apply Bayes' Theorem to compute the inverted probability:\n8. P(BC | M+) = [P(M+ | BC) * P(BC)] / P(M+)\n9. 4. Compute the numerator: P(M+ and BC) = P(M+ | BC) * P(BC) = 0.89 * 0.0035 = 0.00312\n10. 5. Compute the denominator using total probability:\n11. P(M+) = P(M+ and BC) + P(M+ and NoBC)\n12. = 0.00312 + (0.07 * 0.9965) = 0.00312 + 0.06976 = 0.07288\n13. 6. Compute the final conditional probability:\n14. P(BC | M+) = 0.00312 / 0.07288 ≈ 0.0428"
      },
      "model_response": "Let's break down the problem:\n\n* The base rate of breast cancer in women over 40 is 0.35%.\n* If a woman has breast cancer, there is an 11% chance that the mammogram will give a false negative result (FN).\n* If a woman does not have breast cancer, there is a 7% chance that the mammogram will give a false positive result (FP).\n\nWe can create a table to summarize these probabilities:\n\n|  | Breast Cancer Present | Breast Cancer Absent |\n| --- | --- | --- |\n| Mammogram Positive | TP (0.35 * 0.89) = 0.3115 | FP (0.65 * 0.07) = 0.04575 |\n| Mammogram Negative | FN (0.35 * 0.11) = 0.0385 | TN (0.65 * 0.93) = 0.60325 |\n\nTP: True Positive\nFP: False Positive\nFN: False Negative\nTN: True Negative\n\nThe probability we want to calculate is the conditional probability of breast cancer given a positive mammogram result:\n\nP(Breast Cancer | Mammogram Positive) = TP / (TP + FP)\n= 0.3115 / (0.3115 + 0.04575)\n≈ 0.8741\n\nSo, if we test a random woman over 40 for breast cancer using a mammogram and the test comes back positive, there is approximately **87.41%** chance that the patient actually has breast cancer.",
      "timestamp": 1751813826.413992
    },
    {
      "id": 45,
      "index": "F3.567",
      "topic": "Logistic Regression",
      "difficulty": "advanced",
      "keywords": [
        "logistic regression",
        "probability",
        "log-odds",
        "callback prediction"
      ],
      "source": "OpenIntro Statistics, 4th Edition (2019), Example 9.31, Chapter 9, Page 392",
      "problem": "A logistic regression model was fit to estimate the probability of receiving a callback based on whether a resume listed any honors. The model equation is: log_e(p_i / (1 - p_i)) = -2.4998 + 0.8668 × honors. (a) If a resume does not have honors listed, what is the probability of getting a callback? (b) What is the probability if the resume does list honors?",
      "correct_solution": {
        "steps": [
          "(a) If honors = 0 (no honors listed), the equation becomes: log_e(p / (1 - p)) = -2.4998",
          "Apply the logistic transformation: p = e^(-2.4998) / (1 + e^(-2.4998)) ≈ 0.076",
          "(b) If honors = 1 (honors listed), the equation becomes: log_e(p / (1 - p)) = -2.4998 + 0.8668 = -1.6330",
          "Then: p = e^(-1.6330) / (1 + e^(-1.6330)) ≈ 0.163"
        ],
        "conclusion": "Probability without honors ≈ 0.076; Probability with honors ≈ 0.163"
      },
      "model_response": "** (a) ** Probability of getting a callback if a resume does not have honors listed:\nWe plug in honors = 0 into the model equation:\nlog_e(p_i / (1 - p_i)) = -2.4998 + 0.8668 × 0\n= -2.4998\n\nTo find the probability, we exponentiate both sides of the equation and subtract it from 1:\np_i = exp(-2.4998) / (1 + exp(-2.4998))\n≈ 0.1056\n\n1 - p_i ≈ 0.8944\nSo, the probability of getting a callback if a resume does not have honors listed is approximately **9.44%**.\n\n** (b) ** Probability of getting a callback if the resume does list honors:\nWe plug in honors = 1 into the model equation:\nlog_e(p_i / (1 - p_i)) = -2.4998 + 0.8668 × 1\n= -0.633\n\nTo find the probability, we exponentiate both sides of the equation and subtract it from 1:\np_i = exp(-0.633) / (1 + exp(-0.633))\n≈ 0.5226\n\n1 - p_i ≈ 0.4774\nSo, the probability of getting a callback if the resume does list honors is approximately **52.26%**.\n\nNote that these probabilities are conditional on the other predictors in the model not being significant.",
      "timestamp": 1751813916.9372869
    },
    {
      "id": 46,
      "index": "F3.678",
      "topic": "Logistic Regression",
      "difficulty": "advanced",
      "keywords": [
        "logistic regression",
        "log-odds",
        "binary predictor",
        "resume study"
      ],
      "source": "OpenIntro Statistics, 4th Edition (2019), Example 9.31, Chapter 9, Pages 374",
      "problem": "A logistic regression model is fitted using a binary predictor: whether an applicant had any type of honors listed on their resume (e.g., 'employee of the month'). The model is loge(p / (1 - p)) = -2.4998 + 0.8668 × honors. (a) What is the callback probability if a resume has no honors? (b) What is the probability if the resume includes honors?",
      "correct_solution": {
        "steps": [
          "(a) When honors = 0, the log-odds becomes -2.4998.",
          "Convert log-odds to probability: p = e^(-2.4998) / (1 + e^(-2.4998)) ≈ 0.076.",
          "(b) When honors = 1, the log-odds becomes -2.4998 + 0.8668 = -1.6330.",
          "Then, p = e^(-1.6330) / (1 + e^(-1.6330)) ≈ 0.163."
        ],
        "conclusion": "Including honors on a resume increases the probability of receiving a callback from approximately 7.6% to 16.3%, more than doubling the odds."
      },
      "model_response": "** (a) ** Callback probability if a resume has no honors:\nTo find the probability, we need to exponentiate the intercept term and subtract it from 1:\n\np_no_honors = exp(-2.4998) / (1 + exp(-2.4998)) ≈ 0.1056\n1 - p_no_honors ≈ 0.8944\n\nSo, the callback probability if a resume has no honors is approximately **9.44%**.\n\n** (b) ** Probability if the resume includes honors:\nWe plug in the value of the predictor (honors = 1) into the model:\n\nlog( p / (1 - p)) = -2.4998 + 0.8668 × 1\n= -0.633\n\np_with_honors = exp(-0.633) / (1 + exp(-0.633)) ≈ 0.5226\n1 - p_with_honors ≈ 0.4774\n\nSo, the probability if the resume includes honors is approximately **52.26%**.\n\nNote that these probabilities are conditional on the other predictors in the model not being significant.",
      "timestamp": 1751814007.45898
    },
    {
      "id": 47,
      "index": "F3.789",
      "topic": "Bayesian Statistics",
      "difficulty": "advanced",
      "keywords": [
        "Bayesian statistics",
        "Gamma distribution",
        "posterior distribution",
        "posterior mean",
        "posterior variance"
      ],
      "source": "Understanding Advanced Statistical Methods by Westfall & Henning",
      "problem": "Assume a Gamma(4, 5) prior and observe 15 successes and 10 failures. Compute the posterior distribution parameters and posterior mean.",
      "correct_solution": {
        "steps": [
          "Step 1: Prior distribution is Gamma(4, 5).",
          "Step 2: Observed data: 15 successes and 10 failures.",
          "Step 3: Update the prior with observed data: Posterior distribution = Gamma(4 + 15, 5 + 10) = Gamma(19, 15).",
          "Step 4: Compute the posterior mean: Mean = α / β = 19 / 15 ≈ 1.267.",
          "Step 5: Compute the posterior variance: Variance = α / β^2 = 19 / 15^2 = 19 / 225 ≈ 0.084.",
          "Step 6: Thus, the posterior distribution is Gamma(19, 15) and the posterior mean is approximately 1.267."
        ],
        "conclusion": "The posterior distribution is Gamma(19, 15) and the posterior mean is approximately 1.267."
      },
      "model_response": "** (1) ** Posterior distribution for θ:\nWe can use Bayes' theorem to update the prior distribution with the likelihood:\nθ | data ∼ Gamma(4 + 15, 5 + 10)\n= Gamma(19, 15)\n\n** (2) ** Posterior mean:\nThe posterior mean is calculated as:\n\nE[θ | data] = θ̄ = α / (α + β)\n= 19 / 25\n≈ 0.76\n\nNote that the posterior distribution is a gamma distribution with parameters α = 19 and β = 15, which represents the updated information about the response probability after observing 15 successes and 10 failures.",
      "timestamp": 1751814097.972065
    },
    {
      "id": 48,
      "index": "F3.890",
      "topic": "Bayesian Inference – Posterior Analysis",
      "difficulty": "advanced",
      "keywords": [
        "Bayesian inference",
        "posterior distribution",
        "Beta distribution",
        "credible interval",
        "posterior mean",
        "posterior mode"
      ],
      "source": "Understanding Advanced Statistical Methods by Westfall & Henning (Routledge), Chapter on Bayesian Inference",
      "problem": "Suppose you are analyzing a clinical trial for a new drug. Historical data suggest that the probability of a patient responding to the standard treatment (prior probability) is about 0.2. In a new trial with the experimental drug, you observe that out of 30 patients, 10 respond positively. Assume a Beta(2,8) prior distribution for the response probability θ (where Beta(2,8) reflects the historical data). The likelihood is binomial: 10 successes out of 30 trials. Tasks: 1. Calculate the posterior distribution for θ. 2. Find the posterior mean and posterior mode. 3. Construct a 95% credible interval for θ.",
      "correct_solution": {
        "steps": [
          "Step 1: Identify the prior distribution. Prior = Beta(2, 8). This reflects prior belief about response probability θ.",
          "Step 2: Extract data from the trial. Number of successes = 10, Number of failures = 20 (since 30 total patients - 10 successes), Likelihood = Binomial(30, θ)",
          "Step 3: Compute the posterior distribution. Posterior = Beta(2 + 10, 8 + 20) = Beta(12, 28)",
          "Step 4: Compute the posterior mean. Mean = α / (α + β) = 12 / (12 + 28) = 0.3",
          "Step 5: Compute the posterior mode. Mode = (α - 1) / (α + β - 2) = (12 - 1) / (12 + 28 - 2) = 11 / 38 ≈ 0.289",
          "Step 6: Compute a 95% credible interval. Use Beta(12, 28) quantiles: Lower bound ≈ 0.17, Upper bound ≈ 0.43. Alternatively, use normal approximation: Variance ≈ (12 * 28) / [(40)^2 * 41] ≈ 0.0042, Std dev ≈ √0.0042 ≈ 0.065, Interval = 0.3 ± 1.96 × 0.065 ≈ (0.173, 0.427)"
        ],
        "conclusion": "The posterior distribution for the response probability θ is Beta(12, 28). The posterior mean is 0.3 and the mode is approximately 0.289. A 95% credible interval for θ is approximately (0.17, 0.43).",
        "full_solution": "1. Step 1: Identify the prior distribution. Prior = Beta(2, 8). This reflects prior belief about response probability θ.\n2. Step 2: Extract data from the trial. Number of successes = 10, Number of failures = 20 (since 30 total patients - 10 successes), Likelihood = Binomial(30, θ)\n3. Step 3: Compute the posterior distribution. Posterior = Beta(2 + 10, 8 + 20) = Beta(12, 28)\n4. Step 4: Compute the posterior mean. Mean = α / (α + β) = 12 / (12 + 28) = 0.3\n5. Step 5: Compute the posterior mode. Mode = (α - 1) / (α + β - 2) = (12 - 1) / (12 + 28 - 2) = 11 / 38 ≈ 0.289\n6. Step 6: Compute a 95% credible interval. Use Beta(12, 28) quantiles: Lower bound ≈ 0.17, Upper bound ≈ 0.43. Alternatively, use normal approximation: Variance ≈ (12 * 28) / [(40)^2 * 41] ≈ 0.0042, Std dev ≈ √0.0042 ≈ 0.065, Interval = 0.3 ± 1.96 × 0.065 ≈ (0.173, 0.427)"
      },
      "model_response": "(1) Posterior distribution for θ:\nWe can use Bayes' theorem to update the prior distribution with the likelihood:\n\nθ | data ~ Beta(2 + 10, 8 + 20) = Beta(12, 28)\n\nThe posterior distribution is a Beta distribution with parameters (a = 12, b = 28).\n\n⸻\n\n(2) Posterior mean and posterior mode:\nThe posterior mean can be calculated as:\n\nE[θ | data] = a / (a + b) = 12 / 40 = 0.3\n\nThe posterior mode is the maximum likelihood estimate of the response probability, which is:\n\nθ_mode = 10 / 30 = 1 / 3 ≈ 0.33\n\n⸻\n\n(3) Constructing a 95% credible interval for θ:\nTo construct a credible interval, we can use the inverse cumulative distribution function (CDF) of the Beta distribution.\n\nFirst, find the 2.5th percentile of the posterior distribution:\n\nθ_2.5 = Beta.inv(0.025, 12, 28) ≈ 0.234\n\nNext, find the 97.5th percentile of the posterior distribution:\n\nθ_97.5 = Beta.inv(0.975, 12, 28) ≈ 0.466\n\nThe 95% credible interval for θ is (0.234, 0.466).\n\n⸻",
      "timestamp": 1751814188.47206
    },
    {
      "id": 49,
      "index": "F3.901",
      "topic": "Logistic Regression – Binary Classification",
      "difficulty": "advanced",
      "keywords": [
        "logistic regression",
        "binary classification",
        "log-odds",
        "probability prediction",
        "interpretation of coefficients"
      ],
      "source": "Understanding Advanced Statistical Methods by Westfall & Henning (Routledge), Chapter on Logistic Regression",
      "problem": "Suppose you are analyzing data from a medical study where the outcome is whether a patient develops a certain disease (yes/no), and the predictors are age (in years) and cholesterol level (mg/dL). The following logistic regression output is obtained: Variable: Intercept, Coefficient: -6.5, Standard Error: 1.2, p-value: <0.001; Variable: Age, Coefficient: 0.04, Standard Error: 0.01, p-value: <0.001; Variable: Cholesterol, Coefficient: 0.02, Standard Error: 0.005, p-value: <0.001. Tasks: 1. Write the equation of the logistic regression model. 2. For a patient aged 50 with a cholesterol level of 200 mg/dL, calculate the log-odds of developing the disease. 3. Calculate the predicted probability of developing the disease for this patient. 4. Interpret the coefficients for age and cholesterol.",
      "correct_solution": {
        "steps": [
          "Step 1: Write the logistic regression model. log(p / (1 - p)) = -6.5 + 0.04 * Age + 0.02 * Cholesterol",
          "Step 2: Plug in Age = 50 and Cholesterol = 200 into the model. log(p / (1 - p)) = -6.5 + 0.04 * 50 + 0.02 * 200 = -6.5 + 2 + 4 = -0.5",
          "Step 3: Convert log-odds to probability. p = exp(-0.5) / (1 + exp(-0.5)) ≈ 0.6065 / (1 + 0.6065) ≈ 0.6065 / 1.6065 ≈ 0.377",
          "Step 4: Interpret the coefficients. Age: Each additional year of age increases the log-odds of developing the disease by 0.04, holding cholesterol constant. Cholesterol: Each additional mg/dL of cholesterol increases the log-odds of disease by 0.02, holding age constant."
        ],
        "conclusion": "The logistic regression model estimates a log-odds of -0.5 for a 50-year-old with cholesterol of 200 mg/dL, corresponding to a 37.7% probability of developing the disease. The positive coefficients for age and cholesterol indicate higher risk with increasing values of each."
      },
      "model_response": "(1) Equation of the logistic regression model:\nThe general form of a logistic regression equation is:\n\nlog(p/(1-p)) = β0 + β1 × Age + β2 × Cholesterol\n\nwhere p is the probability of developing the disease, β0 is the intercept coefficient, β1 is the coefficient for age, and β2 is the coefficient for cholesterol.\n\nSubstituting the values from the output, we get:\n\nlog(p/(1-p)) = -6.5 + 0.04 × Age + 0.02 × Cholesterol\n\n(2) Log-odds of developing the disease for a patient aged 50 with a cholesterol level of 200 mg/dL:\nPlugging in the values, we get:\n\nlog(p/(1-p)) = -6.5 + 0.04 × 50 + 0.02 × 200\n= -6.5 + 2 + 4\n= 0.55\n\n(3) Predicted probability of developing the disease for this patient:\nTo convert the log-odds to a probability, we use the inverse logit function:\n\np = 1 / (1 + exp(-log-odds))\n= 1 / (1 + exp(-0.55))\n≈ 0.615\n\n(4) Interpretation of coefficients for age and cholesterol:\n* The intercept coefficient β0 represents the log-odds of developing the disease when both age and cholesterol are equal to zero, which is unlikely.\n* The coefficient for age β1 (0.04) indicates that for every additional year of age, the log-odds of developing the disease increase by 0.04 units.\n* The coefficient for cholesterol β2 (0.02) indicates that for every unit increase in cholesterol level, the log-odds of developing the disease increase by 0.02 units.\n\nIn summary, the model suggests that both age and cholesterol levels are positively associated with the risk of developing the disease.",
      "timestamp": 1751814278.990839
    }
  ]
