[
    {
        "id": 0,
        "index": "A1.234",
        "topic": "Binomial Distribution",
        "difficulty": "basic",
        "keywords": [
            "binomial distribution",
            "urn problem",
            "replacement",
            "white and black balls",
            "discrete probability"
        ],
        "source": "Adapted from Chapter 2: Random Variables, Page 87, 'A First Course in Probability' by Sheldon Ross",
        "problem": "A ball is drawn from an urn containing three white and three black balls. After the ball is drawn, it is then replaced and another ball is drawn. This goes on indefinitely. What is the probability that of the first four balls drawn, exactly two are white?",
        "correct_solution": {
            "steps": [
                "1. Total balls = 6 (3 white, 3 black) → P(white) = 3/6 = 0.5, P(black) = 0.5.",
                "2. Since the drawing is with replacement and trials are independent, use the binomial distribution.",
                "3. Number of trials n = 4, number of successes (white) k = 2.",
                "4. Use binomial formula: P(X = k) = C(n, k) * p^k * (1 - p)^(n - k).",
                "5. P(X = 2) = C(4, 2) * (0.5)^2 * (0.5)^2 = 6 * 0.25 * 0.25 = 6 * 0.0625 = 0.375."
            ],
            "conclusion": "The probability that exactly two of the first four balls drawn are white is 0.375.",
            "full_solution": "1. 1. Total balls = 6 (3 white, 3 black) → P(white) = 3/6 = 0.5, P(black) = 0.5.\n2. 2. Since the drawing is with replacement and trials are independent, use the binomial distribution.\n3. 3. Number of trials n = 4, number of successes (white) k = 2.\n4. 4. Use binomial formula: P(X = k) = C(n, k) * p^k * (1 - p)^(n - k).\n5. 5. P(X = 2) = C(4, 2) * (0.5)^2 * (0.5)^2 = 6 * 0.25 * 0.25 = 6 * 0.0625 = 0.375."
        },
        "model_response": {
            "response": "Looking at this binomial distribution problem, I need to find the probability that exactly two out of the first four balls drawn are white, with replacement. The urn has three white and three black balls. Since the ball is replaced after each draw, each draw is independent. The probability of drawing a white ball on any single draw is 3/6 = 1/2, and the same for black. Since it's with replacement, we have a binomial situation. We need exactly two successes in four trials, where success is drawing white. The probability of success (white) p = 1/2. Number of failures is black, also q = 1/2. Using the binomial probability formula: P(k successes in n trials) = C(n, k) * p^k * q^(n-k). Here, n=4, k=2, p=1/2, q=1/2. C(4, 2) = 6. P(exactly two white) = C(4,2) * (1/2)^4 = 6 * (1/16) = 6/16 = 3/8 = 0.375. Therefore, the probability that exactly two of the first four balls drawn are white is 3/8 or 0.375."
        },
        "timestamp": 1751810272.024668
    },
    {
        "id": 1,
        "index": "A1.567",
        "topic": "Probability",
        "difficulty": "basic",
        "keywords": [
            "probability",
            "complement rule",
            "game show",
            "at least one"
        ],
        "source": "Based on similar example from: Wyzant – 'Probability of winning at least 1 game out of 5 games' by Moonerah L.",
        "problem": "A game show has a prize with a 5% chance of being won. If a contestant plays 7 games, what is the probability of winning the prize at least once?",
        "correct_solution": {
            "steps": [
                "Step 1: Use the complement rule: P(at least one win) = 1 - P(no wins).",
                "Step 2: Calculate the probability of not winning in one game: 1 - 0.05 = 0.95.",
                "Step 3: Compute the probability of not winning in 7 games: 0.95^7.",
                "Step 4: Calculate: 0.95^7 ≈ 0.698.",
                "Step 5: Find the probability of winning at least once: 1 - 0.698 = 0.302.",
                "Step 6: Thus, the probability of winning the prize at least once in 7 games is approximately 0.302."
            ],
            "conclusion": "The probability of winning the prize at least once in 7 games is approximately 0.302.",
            "full_solution": "1. Step 1: Use the complement rule: P(at least one win) = 1 - P(no wins).\n2. Step 2: Calculate the probability of not winning in one game: 1 - 0.05 = 0.95.\n3. Step 3: Compute the probability of not winning in 7 games: 0.95^7.\n4. Step 4: Calculate: 0.95^7 ≈ 0.698.\n5. Step 5: Find the probability of winning at least once: 1 - 0.698 = 0.302.\n6. Step 6: Thus, the probability of winning the prize at least once in 7 games is approximately 0.302."
        },
        "model_response": {
            "response": "The probability of winning the prize in a single game is 5%, or 0.05. The probability of not winning in a single game is 1 − 0.05 = 0.95. Since the games are independent, the probability of not winning in all 7 games is (0.95)^7. Calculating (0.95)^7: (0.95)^7 ≈ 0.698337. The probability of winning at least once is the complement of the probability of not winning any games: P(at least one win) = 1 − (0.95)^7 ≈ 1 − 0.698337 = 0.301663. Rounding 0.301663 to four decimal places gives 0.3017, as the fifth decimal digit is 6, which is greater than or equal to 5, so the fourth digit (6) is rounded up to 7. Thus, the probability of winning the prize at least once in 7 games is approximately 0.3017. Final Answer: 0.3017"
        },
        "timestamp": 1751810314.5945768
    },
    {
        "id": 2,
        "index": "A2.123",
        "topic": "Conditional Probability",
        "difficulty": "intermediate",
        "keywords": [
            "inclusion-exclusion",
            "set theory",
            "union of events",
            "probability of overlapping events"
        ],
        "source": "Probability and Statistics (Morris H. DeGroot, Mark J. Schervish), Chapter 1: 1.10 The Probability of a Union of Events, Example 1.10.1, Page 47",
        "problem": "Among a group of 200 students, 137 students are enrolled in a mathematics class, 50 in a history class, and 124 in a music class. Additionally, 33 students are enrolled in both mathematics and history, 29 in both history and music, and 92 in both mathematics and music. Finally, 18 students are enrolled in all three classes. What is the probability that a randomly selected student is enrolled in at least one of the three classes?",
        "correct_solution": {
            "steps": [
                "Let A₁ = enrolled in math, A₂ = enrolled in history, A₃ = enrolled in music.",
                "Use the inclusion-exclusion principle:",
                "P(A₁ ∪ A₂ ∪ A₃) = P(A₁) + P(A₂) + P(A₃) - P(A₁ ∩ A₂) - P(A₂ ∩ A₃) - P(A₁ ∩ A₃) + P(A₁ ∩ A₂ ∩ A₃)",
                "Substitute the given probabilities (out of 200 students):",
                "P(A₁ ∪ A₂ ∪ A₃) = (137 + 50 + 124 - 33 - 29 - 92 + 18) / 200 = 175 / 200 = 0.875"
            ],
            "conclusion": "The probability that a randomly selected student is enrolled in at least one of the three classes is 0.875 or 7/8."
        },
        "model_response": {
            "response": "Alright, let's tackle this problem step by step. We're dealing with a group of 200 students, and we have information about how many are enrolled in mathematics, history, and music classes, as well as how many are in various combinations of these classes. Our goal is to find out the probability that a randomly selected student is enrolled in at least one of these three classes. To find the number of students enrolled in at least one of the three classes, we can use the principle of inclusion-exclusion for three sets: |M ∪ H ∪ Mu| = |M| + |H| + |Mu| − |M ∩ H| − |H ∩ Mu| − |M ∩ Mu| + |M ∩ H ∩ Mu|. Plugging in the numbers: |M ∪ H ∪ Mu| = 137 + 50 + 124 − 33 − 29 − 92 + 18 = 175. So, there are 175 students enrolled in at least one of the three classes. The probability that a randomly selected student is enrolled in at least one of the three classes is 175 / 200 = 7 / 8 = 0.875. So, the probability is 0.875, or 87.5%."
        },
        "timestamp": 1751810314.5945768
    },
    {
        "id": 3,
        "index": "A2.445",
        "topic": "Binomial Distribution",
        "difficulty": "intermediate",
        "keywords": [
            "binomial distribution",
            "cumulative probability",
            "sample proportion",
            "normal approximation"
        ],
        "source": "OpenIntro Statistics, 4th Edition (2019), Example 4.38, Chapter 4, Page 155",
        "problem": "Approximately 15% of the US population smokes cigarettes. A local government believed their community had a lower smoker rate and commissioned a survey of 400 randomly selected individuals. The survey found that only 42 of the 400 participants smoke cigarettes. If the true proportion of smokers in the community was really 15%, what is the probability of observing 42 or fewer smokers in a sample of 400 people?",
        "correct_solution": {
            "steps": [
                "We are asked to compute P(k ≤ 42) where k is the number of smokers in a sample of n = 400 and the probability of success (p) is 0.15.",
                "This is the cumulative probability for k = 0, 1, 2, ..., 42 in a Binomial(n=400, p=0.15) distribution.",
                "Using binomial probability computations (or appropriate statistical software), we find:",
                "P(k ≤ 42) = 0.0054"
            ],
            "conclusion": "The probability of observing 42 or fewer smokers out of 400 when p = 0.15 is approximately 0.0054.",
            "full_solution": "1. We are asked to compute P(k ≤ 42) where k is the number of smokers in a sample of n = 400 and the probability of success (p) is 0.15.\n2. This is the cumulative probability for k = 0, 1, 2, ..., 42 in a Binomial(n=400, p=0.15) distribution.\n3. Using binomial probability computations (or appropriate statistical software), we find:\n4. P(k ≤ 42) = 0.0054"
        },
        "model_response": {
            "response": "To determine the probability of observing 42 or fewer smokers in a sample of 400 people, given that the true proportion of smokers is 15%, we can use the normal approximation to the binomial distribution. Since n × p = 60 and n × (1 − p) = 340 are both ≥ 10, the normal approximation is valid. We want: P(X ≤ 42). But since the binomial distribution is discrete, we apply the continuity correction: P(X ≤ 42) ≈ P(X ≤ 42.5). Calculate the Z-Score: Z = (X − μ) / σ = (42.5 − 60) / 7.141 ≈ (−17.5) / 7.141 ≈ −2.45. Find the Probability from the Z-Table: Looking up Z = −2.45 in the standard normal table: P(Z ≤ −2.45) ≈ 0.0071. The probability of observing 42 or fewer smokers in a sample of 400, if the true proportion is 15%, is approximately: 0.0071."
        },
        "timestamp": 1751810376.9834611
    },
    {
        "id": 4,
        "index": "A2.678",
        "topic": "Probability",
        "difficulty": "intermediate",
        "keywords": [
            "hypergeometric distribution",
            "defective bulbs",
            "without replacement",
            "combinatorics"
        ],
        "source": "STAT 414: Introduction to Probability Theory, Lesson 7.4 - Hypergeometric Distribution, Example 7-7, Penn State University",
        "problem": "A factory produces 1000 light bulbs, of which 40 are defective. If 5 bulbs are randomly selected without replacement, what is the probability that exactly 2 of them are defective?",
        "correct_solution": {
            "steps": [
                "Step 1: Calculate the total number of ways to choose 5 bulbs from 1000: C(1000, 5).",
                "Step 2: Calculate the number of ways to choose exactly 2 defective bulbs from 40: C(40, 2).",
                "Step 3: Calculate the number of ways to choose 3 non-defective bulbs from 960: C(960, 3).",
                "Step 4: Compute the number of favorable outcomes: C(40, 2) * C(960, 3).",
                "Step 5: Divide by the total number of possible outcomes: (C(40, 2) * C(960, 3)) / C(1000, 5).",
                "Step 6: Using the binomial coefficient calculations: C(1000, 5) = 2,424,789,642, C(40, 2) = 780, C(960, 3) = 1,297,060, C(1000, 5) = 2,424,789,642.",
                "Step 7: The probability is: (780 * 1,297,060) / 2,424,789,642 ≈ 0.218."
            ],
            "conclusion": "The probability that exactly 2 of the 5 selected bulbs are defective is approximately 0.218.",
            "full_solution": "1. Step 1: Calculate the total number of ways to choose 5 bulbs from 1000: C(1000, 5).\n2. Step 2: Calculate the number of ways to choose exactly 2 defective bulbs from 40: C(40, 2).\n3. Step 3: Calculate the number of ways to choose 3 non-defective bulbs from 960: C(960, 3).\n4. Step 4: Compute the number of favorable outcomes: C(40, 2) * C(960, 3).\n5. Step 5: Divide by the total number of possible outcomes: (C(40, 2) * C(960, 3)) / C(1000, 5).\n6. Step 6: Using the binomial coefficient calculations: C(1000, 5) = 2,424,789,642, C(40, 2) = 780, C(960, 3) = 1,297,060, C(1000, 5) = 2,424,789,642.\n7. Step 7: The probability is: (780 * 1,297,060) / 2,424,789,642 ≈ 0.218."
        },
        "model_response": {
            "response": "To find the probability that exactly 2 out of 5 randomly selected bulbs are defective, we can use the hypergeometric distribution, since we are sampling without replacement from a finite population. Using the hypergeometric probability formula: P(X = k) = [C(K, k) × C(N − K, n − k)] / C(N, n). Step-by-Step Calculation: Number of ways to choose 2 defective bulbs from 40: C(40, 2) = 40! / (2! × 38!) = (40 × 39) / (2 × 1) = 780. Number of ways to choose 3 non-defective bulbs from 960: C(960, 3) = 960! / (3! × 957!) = (960 × 959 × 958) / (3 × 2 × 1) = 147,100,160. Number of ways to choose any 5 bulbs from 1000: C(1000, 5) = 1000! / (5! × 995!) = (1000 × 999 × 998 × 997 × 996) / (5 × 4 × 3 × 2 × 1) ≈ 8.25 × 10^12. P(X = 2) = (780 × 147,100,160) / (8.25 × 10^12) ≈ 1.147 × 10^11 / 8.25 × 10^12 ≈ 0.0139 (or 1.39%). The probability that exactly 2 out of 5 randomly selected bulbs are defective is approximately: 0.0139."
        },
        "timestamp": 1751810440.647744
    },
    {
        "id": 5,
        "index": "A2.789",
        "topic": "Binomial Distribution",
        "difficulty": "intermediate",
        "keywords": [
            "binomial probability",
            "credit card",
            "sampling",
            "binomial distribution",
            "greater than probability"
        ],
        "source": "A Concise Course in A-Level Statistics with worked examples – 26 Jun. 2013, Example 5.7, Page 280",
        "problem": "At Selitall Supermarket, 60% of customers pay by credit card. Find the probability that in a randomly selected sample of ten customers, (a) exactly two pay by credit card, (b) more than seven pay by credit card.",
        "correct_solution": {
            "steps": [
                "Let X be the number of customers who pay by credit card in a sample of 10.",
                "Success: 'pays by credit card' → p = 0.6, q = 0.4, n = 10.",
                "Then X ~ B(10, 0.6).",
                "(a) To find P(X = 2):",
                "Use binomial formula: P(X = 2) = 10C2 × (0.4)^8 × (0.6)^2",
                "= 45 × 0.4^8 × 0.6^2 ≈ 0.011 (2 s.f.)",
                "(b) To find P(X > 7):",
                "P(X > 7) = P(X = 8) + P(X = 9) + P(X = 10)",
                "= 10C8 × 0.4^2 × 0.6^8 + 10C9 × 0.4^1 × 0.6^9 + 10C10 × 0.6^10",
                "= 45 × 0.4^2 × 0.6^8 + 10 × 0.4 × 0.6^9 + 0.6^10",
                "≈ 0.17 (2 s.f.)"
            ],
            "conclusion": "The probability that exactly two out of ten customers pay by credit card is approximately 0.011. The probability that more than seven customers pay by credit card is approximately 0.17.",
            "full_solution": "1. Let X be the number of customers who pay by credit card in a sample of 10.\n2. Success: 'pays by credit card' → p = 0.6, q = 0.4, n = 10.\n3. Then X ~ B(10, 0.6).\n4. (a) To find P(X = 2):\n5. Use binomial formula: P(X = 2) = 10C2 × (0.4)^8 × (0.6)^2\n6. = 45 × 0.4^8 × 0.6^2 ≈ 0.011 (2 s.f.)\n7. (b) To find P(X > 7):\n8. P(X > 7) = P(X = 8) + P(X = 9) + P(X = 10)\n9. = 10C8 × 0.4^2 × 0.6^8 + 10C9 × 0.4^1 × 0.6^9 + 10C10 × 0.6^10\n10. = 45 × 0.4^2 × 0.6^8 + 10 × 0.4 × 0.6^9 + 0.6^10\n11. ≈ 0.17 (2 s.f.)"
        },
        "model_response": {
            "response": "To solve these probability problems, we'll use the Binomial Distribution, since we have a fixed number of independent trials (10 customers), each with the same probability of success (60% or 0.6 for paying by credit card). For part (a), k = 2: P(X = 2) = C(10, 2) * (0.6)^2 * (0.4)^8. Calculating each part: Combination: C(10, 2) = 10! / (2! * 8!) = 45. Probability terms: (0.6)^2 = 0.36, (0.4)^8 ≈ 0.00065536. Multiply them together: P(X = 2) = 45 * 0.36 * 0.00065536 ≈ 0.0106. Final answer for (a): 0.0106. For part (b), P(X > 7) = P(X = 8) + P(X = 9) + P(X = 10). P(X = 8) = 45 * 0.0168 * 0.16 ≈ 0.1209. P(X = 9) = 10 * 0.0101 * 0.4 ≈ 0.0403. P(X = 10) = 1 * 0.0060 * 1 ≈ 0.0060. P(X > 7) = 0.1209 + 0.0403 + 0.0060 ≈ 0.1672. Final answer for (b): 0.1672."
        },
        "timestamp": 1751810531.15971
    },
    {
        "id": 6,
        "index": "A2.345",
        "topic": "Poisson Distribution",
        "difficulty": "intermediate",
        "keywords": [
            "Poisson distribution",
            "total probability",
            "breakdowns",
            "racing cars",
            "discrete distributions"
        ],
        "source": "A Concise Course in Advanced Level Statistics with worked examples – 26 Jun. 2013, Example 5.25",
        "problem": "Two identical racing cars are being tested on a circuit. For each car, the number of mechanical breakdowns can be modelled by a Poisson distribution with a mean of one breakdown in 100 laps. If a car breaks down, it is attended and continues on the circuit. The first car is tested for 20 laps and the second car for 40 laps. Find the probability that the service team is called out to attend to breakdowns: (a) once, (b) more than twice.",
        "correct_solution": {
            "steps": [
                "Let X be the number of breakdowns of the first car: X ~ Poisson(0.2) since 20 laps × 1/100 = 0.2.",
                "Let Y be the number of breakdowns of the second car: Y ~ Poisson(0.4) since 40 laps × 1/100 = 0.4.",
                "Let T = X + Y be the total number of breakdowns, so T ~ Poisson(0.6).",
                "(a) P(T = 1) = 0.6 × e^(-0.6) ≈ 0.329 (3 d.p.)",
                "(b) P(T > 2) = 1 - [P(T = 0) + P(T = 1) + P(T = 2)]",
                "      = 1 - e^(-0.6) × (1 + 0.6 + 0.6^2 / 2!)",
                "      = 1 - e^(-0.6) × (1 + 0.6 + 0.18) = 1 - e^(-0.6) × 1.78 ≈ 0.023 (3 d.p.)"
            ],
            "conclusion": "The probability of one breakdown is approximately 0.329. The probability of more than two breakdowns is approximately 0.023.",
            "full_solution": "1. Let X be the number of breakdowns of the first car: X ~ Poisson(0.2) since 20 laps × 1/100 = 0.2.\n2. Let Y be the number of breakdowns of the second car: Y ~ Poisson(0.4) since 40 laps × 1/100 = 0.4.\n3. Let T = X + Y be the total number of breakdowns, so T ~ Poisson(0.6).\n4. (a) P(T = 1) = 0.6 × e^(-0.6) ≈ 0.329 (3 d.p.)\n5. (b) P(T > 2) = 1 - [P(T = 0) + P(T = 1) + P(T = 2)]\n6.       = 1 - e^(-0.6) × (1 + 0.6 + 0.6^2 / 2!)\n7.       = 1 - e^(-0.6) × (1 + 0.6 + 0.18) = 1 - e^(-0.6) × 1.78 ≈ 0.023 (3 d.p.)"
        },
        "model_response": {
            "response": "Alright, let's tackle this problem step by step. Given: Mean breakdown rate: 1 breakdown per 100 laps. Car 1: 20 laps, Car 2: 40 laps. Calculating λ for Each Car: Given: Mean breakdowns per 100 laps = 1. So, the rate per lap is: Rate per lap = 1 / 100 = 0.01 breakdowns per lap. Now, calculate λ for each car: Car 1 (20 laps): λ1 = 20 * 0.01 = 0.2. Car 2 (40 laps): λ2 = 40 * 0.01 = 0.4. Combining Both Cars: Since the breakdowns of the two cars are independent, the total number of breakdowns (let's call it X) is the sum of the breakdowns from both cars. For independent Poisson random variables: X1 ~ Poisson(λ1), X2 ~ Poisson(λ2), X = X1 + X2 ~ Poisson(λ1 + λ2). So, total λ: λtotal = λ1 + λ2 = 0.2 + 0.4 = 0.6. Now, X ~ Poisson(0.6). Part (a): We need P(X = 1). Using the Poisson formula: P(X = 1) = (e^(-0.6) * 0.6^1) / 1! = e^(-0.6) * 0.6. Calculating: e^(-0.6) ≈ 0.5488, 0.6 * 0.5488 ≈ 0.3293. So, P(X = 1) ≈ 0.329. Part (b): P(X > 2) = 1 - P(X ≤ 2) = 1 - [P(X = 0) + P(X = 1) + P(X = 2)]. P(X = 0) = e^(-0.6) ≈ 0.5488. P(X = 2) = (0.5488 * 0.36) / 2 ≈ 0.0988. P(X ≤ 2) ≈ 0.5488 + 0.3293 + 0.0988 ≈ 0.9769. P(X > 2) = 1 - 0.9769 ≈ 0.0231. Final Answers: (a) 0.329, (b) 0.023."
        },
        "timestamp": 1751810621.681141
    },
    {
        "id": 7,
        "index": "A2.456",
        "topic": "Normal Distribution",
        "difficulty": "intermediate",
        "keywords": [
            "normal distribution",
            "standardization",
            "Z-score",
            "probability",
            "mean",
            "standard deviation"
        ],
        "source": "A Concise Course in A-Level Statistics with worked examples – 26 Jun. 2013, Example 7.4, Page 368",
        "problem": "Lengths of metal strips produced by a machine are normally distributed with a mean length of 150 cm and a standard deviation of 10 cm. Find the probability that the length of a randomly selected strip is: (a) shorter than 165 cm, (b) within 5 cm of the mean.",
        "correct_solution": {
            "steps": [
                "Let X be the length in cm of a metal strip.",
                "Given: μ = 150, σ = 10. So X ~ N(150, 10²).",
                "(a) Find P(X < 165):",
                "Standardize: Z = (X - μ) / σ = (165 - 150) / 10 = 1.5",
                "Look up Z = 1.5 in standard normal table: Φ(1.5) ≈ 0.9332",
                "So, P(X < 165) = 0.9332 ≈ 0.93 (2 s.f.)",
                "(b) Find P(145 < X < 155):",
                "Standardize lower bound: Z₁ = (145 - 150) / 10 = -0.5",
                "Standardize upper bound: Z₂ = (155 - 150) / 10 = 0.5",
                "Look up values: Φ(0.5) = 0.6915, Φ(-0.5) = 1 - Φ(0.5) = 0.3085",
                "P(145 < X < 155) = Φ(0.5) - Φ(-0.5) = 0.6915 - 0.3085 = 0.383 ≈ 0.38 (2 s.f.)"
            ],
            "conclusion": "The probability that the length is shorter than 165 cm is approximately 0.93. The probability that the length is within 5 cm of the mean is approximately 0.38.",
            "full_solution": "1. Let X be the length in cm of a metal strip.\n2. Given: μ = 150, σ = 10. So X ~ N(150, 10²).\n3. (a) Find P(X < 165):\n4. Standardize: Z = (X - μ) / σ = (165 - 150) / 10 = 1.5\n5. Look up Z = 1.5 in standard normal table: Φ(1.5) ≈ 0.9332\n6. So, P(X < 165) = 0.9332 ≈ 0.93 (2 s.f.)\n7. (b) Find P(145 < X < 155):\n8. Standardize lower bound: Z₁ = (145 - 150) / 10 = -0.5\n9. Standardize upper bound: Z₂ = (155 - 150) / 10 = 0.5\n10. Look up values: Φ(0.5) = 0.6915, Φ(-0.5) = 1 - Φ(0.5) = 0.3085\n11. P(145 < X < 155) = Φ(0.5) - Φ(-0.5) = 0.6915 - 0.3085 = 0.383 ≈ 0.38 (2 s.f.)"
        },
        "model_response": {
            "response": "To solve these problems, we'll use the properties of the normal distribution. We'll standardize the values using the z-score formula: z = (X - μ) / σ. (a) Probability that the length is shorter than 165 cm: Step 1: Calculate the z-score for 165 cm. z = (165 - 150) / 10 = 15 / 10 = 1.5. Step 2: Find P(X < 165), which is equivalent to P(Z < 1.5). From the standard normal table: P(Z < 1.5) ≈ 0.9332. Answer: The probability that a randomly selected strip is shorter than 165 cm is approximately 93.32%. (b) Probability that the length is within 5 cm of the mean: This means we're looking for lengths between 145 cm and 155 cm (since 150 ± 5). Step 1: Calculate the z-scores for 145 cm and 155 cm. For 145 cm: z = (145 - 150) / 10 = -5 / 10 = -0.5. For 155 cm: z = (155 - 150) / 10 = 5 / 10 = 0.5. Step 2: Find P(145 < X < 155), which is equivalent to P(-0.5 < Z < 0.5). From the standard normal table: P(Z < 0.5) ≈ 0.6915, P(Z < -0.5) ≈ 0.3085. Step 3: Subtract the two probabilities to find the area between -0.5 and 0.5. P(-0.5 < Z < 0.5) = 0.6915 - 0.3085 = 0.3830. Answer: There is approximately a 38.30% chance that a randomly selected strip is within 5 cm of the mean length."
        },
        "timestamp": 1751810688.709665
    },
    {
        "id": 8,
        "index": "A2.567",
        "topic": "Probability",
        "difficulty": "advanced",
        "keywords": [
            "gambler's ruin",
            "probability",
            "coin toss",
            "recurrence relation",
            "stochastic process"
        ],
        "source": "Example 4.8, 'Gambler's Ruin', Chapter 4 – Probability, University of Connecticut OER: https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160ch4.pdf",
        "problem": "A gambler plays a fair game by flipping a coin. Heads wins $1, tails loses $1. The gambler starts with $50 and stops playing when reaching $0 (ruin) or $200. What is the probability of reaching $200 before going broke?",
        "correct_solution": {
            "steps": [
                "Step 1: Define the winning probability function y(n) = P(200 | n), where n is the current amount of money.",
                "Step 2: Use boundary conditions: y(0) = 0 (ruin) and y(200) = 1 (goal reached).",
                "Step 3: Apply the recurrence relation for a fair coin: y(n) = 0.5 * y(n + 1) + 0.5 * y(n - 1).",
                "Step 4: This implies that y(n + 1) - y(n) = y(n) - y(n - 1), so the graph of y(n) is linear.",
                "Step 5: Given y(0) = 0 and y(200) = 1, the linear solution is y(n) = n / 200.",
                "Step 6: Substitute n = 50 to find the probability: y(50) = 50 / 200 = 0.25."
            ],
            "conclusion": "The probability of reaching $200 before going broke when starting with $50 is 0.25.",
            "full_solution": "1. Step 1: Define the winning probability function y(n) = P(200 | n), where n is the current amount of money.\n2. Step 2: Use boundary conditions: y(0) = 0 (ruin) and y(200) = 1 (goal reached).\n3. Step 3: Apply the recurrence relation for a fair coin: y(n) = 0.5 * y(n + 1) + 0.5 * y(n - 1).\n4. Step 4: This implies that y(n + 1) - y(n) = y(n) - y(n - 1), so the graph of y(n) is linear.\n5. Step 5: Given y(0) = 0 and y(200) = 1, the linear solution is y(n) = n / 200.\n6. Step 6: Substitute n = 50 to find the probability: y(50) = 50 / 200 = 0.25."
        },
        "model_response": {
            "response": "This problem can be solved using a Markov chain. Let's define the states as: S0: The gambler has $0, S50: The gambler has $50, S100: The gambler has $100, S150: The gambler has $150, S200: The gambler has $200. The transitions between these states are determined by the outcome of each coin flip. If the gambler wins, they move to a higher state; if they lose, they move to a lower state. However, the correct approach for gambler's ruin with a fair coin is simpler. For a fair game, the probability of reaching the target before ruin is simply the ratio of current money to target money. Since the gambler starts with $50 and wants to reach $200, the probability is 50/200 = 0.25 or 25%."
        },
        "timestamp": 1751810779.2325718
    },
    {
        "id": 9,
        "index": "A2.011",
        "topic": "Discrete Probability",
        "difficulty": "intermediate",
        "keywords": [
            "stars and bars",
            "integer partition",
            "combinatorics",
            "minimum allocation",
            "Bose-Einstein counting"
        ],
        "source": "Introduction to Probability by Joseph K. Blitzstein and Jessica Hwang, Chapter 4, Question 77(a), Page 41",
        "problem": "Five people have just won a $100 prize and are deciding how to divide the $100 up between them. Assume that whole dollars are used, not cents. Also, for example, giving $50 to the first person and $10 to the second is different from vice versa. (a) How many ways are there to divide up the $100, such that each person gets at least $10?",
        "correct_solution": {
            "steps": [
                "1. Since each person must get at least $10, we first give $10 to each person: 5 × $10 = $50.",
                "2. We are left with $100 - $50 = $50 to distribute freely (each person can now get $0 or more).",
                "3. This is a classic stars and bars problem: distributing 50 indistinguishable dollars among 5 distinguishable people, with no minimum requirement.",
                "4. The number of integer solutions to x₁ + x₂ + x₃ + x₄ + x₅ = 50 where xᵢ ≥ 0 is given by the formula: C(n + k - 1, k), where k = 50 and n = 5.",
                "5. So, the number of solutions is: C(50 + 5 - 1, 50) = C(54, 4)."
            ],
            "conclusion": "The number of ways to divide the $100 such that each person gets at least $10 is C(54, 4).",
            "full_solution": "1. 1. Since each person must get at least $10, we first give $10 to each person: 5 × $10 = $50.\n2. 2. We are left with $100 - $50 = $50 to distribute freely (each person can now get $0 or more).\n3. 3. This is a classic stars and bars problem: distributing 50 indistinguishable dollars among 5 distinguishable people, with no minimum requirement.\n4. 4. The number of integer solutions to x₁ + x₂ + x₃ + x₄ + x₅ = 50 where xᵢ ≥ 0 is given by the formula: C(n + k - 1, k), where k = 50 and n = 5.\n5. 5. So, the number of solutions is: C(50 + 5 - 1, 50) = C(54, 4)."
        },
        "model_response": {
            "response": "Understanding the Problem: We have five people who have collectively won a $100 prize. We need to determine how many ways this $100 can be divided among them under the following conditions: 1. Whole dollars only: Each person must receive an integer amount (no cents). 2. Order matters: The distribution is ordered, meaning that giving $50 to Person A and $10 to Person B is different from giving $10 to Person A and $50 to Person B. 3. Minimum amount: Each person must receive at least $10. Translating to a Mathematical Model: This problem is equivalent to finding the number of ordered 5-tuples (x₁, x₂, x₃, x₄, x₅) where: Each xᵢ is an integer representing the amount given to the i-th person. xᵢ ≥ 10 for all i (since each person gets at least $10). x₁ + x₂ + x₃ + x₄ + x₅ = 100. Simplifying the Problem: To handle the 'at least $10' condition, we can define new variables: Let yᵢ = xᵢ - 10. Since xᵢ ≥ 10, this means yᵢ ≥ 0. Substituting into the total: (y₁ + 10) + (y₂ + 10) + (y₃ + 10) + (y₄ + 10) + (y₅ + 10) = 100 → y₁ + y₂ + y₃ + y₄ + y₅ + 50 = 100 → y₁ + y₂ + y₃ + y₄ + y₅ = 50. Now we need the number of non-negative integer solutions to: y₁ + y₂ + y₃ + y₄ + y₅ = 50. Applying Stars and Bars: The number of non-negative integer solutions to: y₁ + y₂ + y₃ + y₄ + y₅ = 50 is given by the formula: C(50 + 5 - 1, 5 - 1) = C(54, 4). Calculating the Combination: C(54, 4) = 54! / (4! × 50!) = (54 × 53 × 52 × 51) / (4 × 3 × 2 × 1) = (54 × 53 × 52 × 51) / 24. Step-by-step: 1. 54 × 53 = 2,862 2. 2,862 × 52 = 148,824 3. 148,824 × 51 = 7,590,024 4. 7,590,024 ÷ 24 = 316,251. Final Answer: There are 316,251 ways to divide the $100 prize among five people such that each person receives at least $10, using whole dollars, and the order matters. Answer: 316,251"
        },
        "timestamp": 1751810869.7585468
    },
    {
        "id": 10,
        "index": "A2.012",
        "topic": "Conditional Probability",
        "difficulty": "intermediate",
        "keywords": [
            "expected value",
            "conditional probability",
            "risk aversion",
            "decision theory",
            "game theory",
            "Monty Hall variation"
        ],
        "source": "Custom analysis of a 4-door Monty Hall-style game",
        "problem": "A game show presents contestants with four doors: behind one is a car worth $1000, behind another is a forfeit costing -$1000, and behind the remaining two doors is nothing. The contestant picks one door. The host then opens one of the remaining doors to show it is empty. The contestant may stick with their choice or switch to one of the other two unopened doors. What is the optimal strategy if the contestant wants to maximise expected wealth and is risk-averse?",
        "correct_solution": {
            "steps": [
                "Step 1: Initial probabilities before any door is opened: P(car) = 1/4 = 0.25, P(forfeit) = 1/4 = 0.25, P(nothing) = 2/4 = 0.50",
                "Step 2: Expected value of original choice (without switching): EV_stick = 0.25 * 1000 + 0.25 * (-1000) + 0.50 * 0 = 250 - 250 + 0 = $0",
                "Step 3: Host opens a door showing nothing (always does this). Now 2 unopened doors remain besides the original pick. Conditional on host behavior, we recompute probabilities based on Bayes' Theorem.",
                "Step 4: Let's assume the contestant initially picked a 'nothing' door (probability = 0.5): Host reveals the other 'nothing' door (forced), leaving 'car' and 'forfeit' among remaining doors. So switching leads to: P(car) = 0.5, P(forfeit) = 0.5 → EV_switch_if_initial_nothing = 0.5 * 1000 + 0.5 * (-1000) = 0",
                "Step 5: If the contestant originally picked the car (P = 0.25): Host opens one of the 'nothing' doors (randomly). Remaining doors: forfeit and nothing → P(forfeit) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_car = 0.5 * (-1000) + 0.5 * 0 = -500",
                "Step 6: If the contestant originally picked the forfeit (P = 0.25): Host opens one of the 'nothing' doors. Remaining doors: car and nothing → P(car) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_forfeit = 0.5 * 1000 + 0.5 * 0 = 500",
                "Step 7: Combine all possible cases for expected value of switching: EV_switch = (0.5 * 0) + (0.25 * -500) + (0.25 * 500) = 0 - 125 + 125 = $0",
                "Step 8: A risk-averse person prefers less variance in outcomes, especially when EV is the same. Switching utilizes the host's information and lowers reliance on original random pick."
            ],
            "conclusion": "Even though both strategies yield an expected value of $0, the optimal strategy for a risk-averse contestant is to switch. Switching leverages new information and shifts outcome probabilities to reduce variance and reliance on the random initial pick.",
            "full_solution": "1. Step 1: Initial probabilities before any door is opened: P(car) = 1/4 = 0.25, P(forfeit) = 1/4 = 0.25, P(nothing) = 2/4 = 0.50\n2. Step 2: Expected value of original choice (without switching): EV_stick = 0.25 * 1000 + 0.25 * (-1000) + 0.50 * 0 = 250 - 250 + 0 = $0\n3. Step 3: Host opens a door showing nothing (always does this). Now 2 unopened doors remain besides the original pick. Conditional on host behavior, we recompute probabilities based on Bayes' Theorem.\n4. Step 4: Let's assume the contestant initially picked a 'nothing' door (probability = 0.5): Host reveals the other 'nothing' door (forced), leaving 'car' and 'forfeit' among remaining doors. So switching leads to: P(car) = 0.5, P(forfeit) = 0.5 → EV_switch_if_initial_nothing = 0.5 * 1000 + 0.5 * (-1000) = 0\n5. Step 5: If the contestant originally picked the car (P = 0.25): Host opens one of the 'nothing' doors (randomly). Remaining doors: forfeit and nothing → P(forfeit) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_car = 0.5 * (-1000) + 0.5 * 0 = -500\n6. Step 6: If the contestant originally picked the forfeit (P = 0.25): Host opens one of the 'nothing' doors. Remaining doors: car and nothing → P(car) = 0.5, P(nothing) = 0.5 → EV_switch_if_initial_forfeit = 0.5 * 1000 + 0.5 * 0 = 500\n7. Step 7: Combine all possible cases for expected value of switching: EV_switch = (0.5 * 0) + (0.25 * -500) + (0.25 * 500) = 0 - 125 + 125 = $0\n8. Step 8: A risk-averse person prefers less variance in outcomes, especially when EV is the same. Switching utilizes the host's information and lowers reliance on original random pick."
        },
        "model_response": {
            "response": "Alright, let's tackle this problem step by step. I'm going to think through the scenario carefully to determine the best strategy for the contestant who wants to maximize their expected wealth and is risk-averse. Understanding the Problem: We have four doors with the following prizes behind them: Door 1: Car worth $1000, Door 2: Forfeit costing -$1000, Door 3: Nothing ($0), Door 4: Nothing ($0). The contestant picks one door initially. Then, the host, who knows what's behind each door, opens one of the remaining three doors that is empty (i.e., has $0). After this, the contestant can choose to: 1. Stick with their original choice, or 2. Switch to one of the other two unopened doors. Our goal is to determine the optimal strategy to maximize expected wealth, considering that the contestant is risk-averse. Breaking Down the Problem: Initial Probabilities: Initially, before any doors are opened, the probabilities are: P(Car) = 1/4, P(Forfeit) = 1/4, P(Nothing) = 2/4 = 1/2. Contestant's Initial Choice: The contestant picks one door (let's say Door 1 for concreteness, but the door number doesn't matter due to symmetry). The probabilities for the initial pick are: P(Initial pick is Car) = 1/4, P(Initial pick is Forfeit) = 1/4, P(Initial pick is Nothing) = 1/2. Host's Action: The host then opens one of the remaining three doors that is empty. The host's choice gives us additional information. Strategy 1: Stick with Initial Choice: Outcomes: +$1000: 1/4, -$1000: 1/4, $0: 1/2. EV = (1/4)1000 + (1/4)(-1000) + (1/2)*0 = $0. Strategy 2: Switch to One of the Other Two Unopened Doors: Since no reason to prefer one over the other, choose one randomly (50% chance). Compute EV across all cases: Case 1: Initial = Car (1/4): Switch between Forfeit (-1000) and Nothing (0) → EV = (-1000*0.5 + 0*0.5) = -500. Case 2: Initial = Forfeit (1/4): Switch between Car (1000) and Nothing (0) → EV = (1000*0.5 + 0*0.5) = +500. Case 3: Initial = Nothing (1/2): Switch between Car (1000) and Forfeit (-1000) → EV = (1000*0.5 + (-1000)*0.5) = 0. Overall EV for switching: EV = (1/4)(-500) + (1/4)(+500) + (1/2)*0 = $0. Analyzing Risk: Though both strategies yield EV = $0, risk-averse players care about outcome variability. Sticking: +1000: 1/4, -1000: 1/4, $0: 1/2. Switching: +1000: 3/8, -1000: 3/8, $0: 1/4. Risk-averse players prefer: Lower chance of losing $1000 → Stick: 25% vs Switch: 37.5%, More certainty (higher chance of $0) → Stick: 50% vs Switch: 25%. Optimal Strategy: Given equal expected value but higher variability in switching, the optimal strategy for a risk-averse contestant is to stick with the initial choice. Final Answer: The optimal strategy for a risk-averse contestant aiming to maximize expected wealth is to stick with the initial choice. This strategy offers the same expected value as switching ($0) but with a lower probability of incurring the substantial loss of -$1000. Answer: {Stick with the initial choice}"
        },
        "timestamp": 1751810951.699778
    },
    {
        "id": 11,
        "index": "A2.890",
        "topic": "Conditional Probability – Boy or Girl Paradox",
        "difficulty": "intermediate",
        "keywords": [
            "conditional probability",
            "boy or girl paradox",
            "Bayes",
            "children combinations"
        ],
        "source": "A Student's Guide to Bayesian Statistics by Ben Lambert, Problem 3.4.1",
        "problem": "Mr Bayes has two children. The older child is a girl. What is the probability that both children are girls?",
        "correct_solution": {
            "steps": [
                "Step 1: List all possible gender combinations of two children: (Boy, Boy), (Boy, Girl), (Girl, Boy), (Girl, Girl).",
                "Step 2: Given that the older child is a girl, eliminate combinations where the older child is a boy.",
                "Step 3: The remaining valid combinations are: (Girl, Boy) and (Girl, Girl).",
                "Step 4: Out of these 2 equally likely combinations, only (Girl, Girl) has both children as girls."
            ],
            "conclusion": "The probability that both children are girls given the older child is a girl is 1/2.",
            "full_solution": "1. Step 1: List all possible gender combinations of two children: (Boy, Boy), (Boy, Girl), (Girl, Boy), (Girl, Girl).\n2. Step 2: Given that the older child is a girl, eliminate combinations where the older child is a boy.\n3. Step 3: The remaining valid combinations are: (Girl, Boy) and (Girl, Girl).\n4. Step 4: Out of these 2 equally likely combinations, only (Girl, Girl) has both children as girls."
        },
        "model_response": "Alright, let's tackle this problem step by step. I'm going to think about Mr. Bayes's two children and figure out the probability that both are girls, given that the older child is a girl.\n\nUnderstanding the Problem\n\nWe have a family with two children. We're told that the older child is a girl. We need to find out the probability that both children are girls.\n\nPossible Combinations of Children\n\nFirst, let's list all possible combinations of genders for two children, where the order matters (older and younger):\n\n1. Older child is a girl (G), younger child is a girl (G) → GG\n2. Older child is a girl (G), younger child is a boy (B) → GB\n3. Older child is a boy (B), younger child is a girl (G) → BG\n4. Older child is a boy (B), younger child is a boy (B) → BB\n\nThese are all the possible combinations, assuming that the probability of having a boy or a girl is equal (each has a 50% chance) and that the genders of the children are independent.\n\n⸻\n\nApplying the Given Information\n\nWe're told that the older child is a girl. This means we can eliminate any combinations where the older child is a boy. So, let's cross out the possibilities where the older child is B:\n\n• BG\n• BB\n\nNow, we're left with:\n\n1. GG\n2. GB\n\n⸻\n\nCalculating the Probability\n\nNow, we want to find the probability that both children are girls (GG) given that the older child is a girl.\n\nFrom the remaining possibilities:\n\n• GG: Both are girls.\n• GB: Older is girl, younger is boy.\n\nThere are 2 equally likely possibilities left (GG and GB), and only one of them has both children as girls (GG).\n\nSo, the probability is:\n\n{Probability} = 1/2\n\n⸻\n\nVerifying with Probability Rules\n\nLet's also think about this using conditional probability.\n\n• Let A be the event \"both children are girls\" (GG).\n• Let B be the event \"the older child is a girl\" (GG or GB).\n\nWe want to find P(A|B), the probability that both are girls given that the older is a girl.\n\nThe formula for conditional probability is:\n\nP(A|B) = P(A ∩ B) / P(B)\n\nHere, P(A ∩ B) is the probability that both are girls and the older is a girl. But if both are girls, then certainly the older is a girl, so P(A ∩ B) = P(A).\n\n• P(A): Probability both are girls = 1/4 (from GG out of GG, GB, BG, BB).\n• P(B): Probability older is a girl = 1/2 (GG and GB out of four).\n\nSo,\n\nP(A|B) = (1/4) / (1/2) = 1/2\n\nThis confirms our earlier answer.\n\n⸻\n\nCommon Misconception\n\nSometimes, people confuse this with the \"two girls given at least one girl\" problem, where the answer is 1/3. That's a different scenario because \"at least one girl\" includes GB, BG, and GG, making three possibilities where one is GG.\n\nBut here, we know specifically that the older child is a girl, which eliminates BG and BB, leaving only GG and GB. Hence, the probability is 1/2.\n\n⸻\n\nFinal Answer\n\nThe probability that both children are girls, given that the older child is a girl, is:\n\n{1/2}",
        "timestamp": 1751811015.6533382
    },
    {
        "id": 12,
        "index": "A2.901",
        "topic": "Conditional Probability – Boy or Girl Paradox",
        "difficulty": "intermediate",
        "keywords": [
            "conditional probability",
            "boy or girl paradox",
            "Laplace",
            "children combinations"
        ],
        "source": "A Student's Guide to Bayesian Statistics by Ben Lambert, Problem 3.4.2",
        "problem": "Mr Laplace has two children. At least one of the children is a girl. What is the probability that both children are girls?",
        "correct_solution": {
            "steps": [
                "Step 1: List all possible gender combinations: (Boy, Boy), (Boy, Girl), (Girl, Boy), (Girl, Girl).",
                "Step 2: Given that at least one child is a girl, eliminate the (Boy, Boy) case.",
                "Step 3: Remaining valid combinations: (Boy, Girl), (Girl, Boy), (Girl, Girl).",
                "Step 4: Out of these 3 equally likely combinations, only (Girl, Girl) has both children as girls."
            ],
            "conclusion": "The probability that both children are girls given at least one is a girl is 1/3.",
            "full_solution": "1. Step 1: List all possible gender combinations: (Boy, Boy), (Boy, Girl), (Girl, Boy), (Girl, Girl).\n2. Step 2: Given that at least one child is a girl, eliminate the (Boy, Boy) case.\n3. Step 3: Remaining valid combinations: (Boy, Girl), (Girl, Boy), (Girl, Girl).\n4. Step 4: Out of these 3 equally likely combinations, only (Girl, Girl) has both children as girls."
        },
        "model_response": "Alright, let's tackle this problem step by step. We're dealing with Mr. Laplace's two children, and we know that at least one of them is a girl. We need to find out the probability that both children are girls.\n\nUnderstanding the Problem\n\nFirst, let's clarify what we know and what we're asked to find.\n\n• Given: Mr. Laplace has two children. At least one of them is a girl.\n• Find: The probability that both children are girls.\n\nThis is a classic probability problem that can be approached by listing all possible outcomes and then narrowing them down based on the given information.\n\nListing Possible Outcomes\n\nWhen considering the genders of two children, and assuming that the probability of having a boy or a girl is equal (each has a 50% chance), and that the genders of the two children are independent, there are four equally likely possibilities for the two children. We'll denote the older child first and the younger child second:\n\n1. Older child is a Girl (G), Younger child is a Girl (G) → GG\n2. Older child is a Girl (G), Younger child is a Boy (B) → GB\n3. Older child is a Boy (B), Younger child is a Girl (G) → BG\n4. Older child is a Boy (B), Younger child is a Boy (B) → BB\n\nEach of these outcomes has an equal probability of 1/4 or 25%.\n\nApplying the Given Information\n\nWe're told that at least one of the children is a girl. This means we can eliminate any outcome where both children are boys. So, let's cross out the BB possibility:\n\n• BB\n\nNow, we're left with three possible outcomes:\n\n1. GG\n2. GB\n3. BG\n\nDetermining the Favorable Outcome\n\nWe want to find the probability that both children are girls. Looking at our remaining possibilities:\n\n• GG: Both are girls.\n• GB: Older is girl, younger is boy.\n• BG: Older is boy, younger is girl.\n\nOnly one of these three outcomes has both children as girls (GG).\n\nCalculating the Probability\n\nNow, the probability is the number of favorable outcomes divided by the total number of possible outcomes that satisfy the given condition.\n\n• Number of favorable outcomes (both girls): 1 (GG)\n• Total number of possible outcomes (given at least one girl): 3 (GG, GB, BG)\n\nSo, the probability is:\n\nProbability = 1/3\n\nVerifying with Conditional Probability\n\nLet's also approach this using conditional probability to ensure our answer is correct.\n\nLet:\n\n• A be the event \"both children are girls\" (GG).\n• B be the event \"at least one child is a girl\" (GG, GB, BG).\n\nWe want to find P(A|B), the probability that both are girls given that at least one is a girl.\n\nThe formula for conditional probability is:\n\nP(A|B) = P(A ∩ B) / P(B)\n\nHere, P(A ∩ B) is the probability that both are girls and at least one is a girl. But if both are girls, then certainly at least one is a girl, so P(A ∩ B) = P(A).\n\n• P(A): Probability both are girls = 1/4 (only GG out of GG, GB, BG, BB).\n• P(B): Probability at least one is a girl = 3/4 (GG, GB, BG out of four).\n\nSo,\n\nP(A|B) = (1/4) / (3/4) = 1/3\n\nThis confirms our earlier answer.\n\nAddressing Common Confusion\n\nIt's easy to confuse this problem with the one where we know that a specific child (like the older one) is a girl. In that case, the probability that both are girls is 1/2, as we've seen in the previous problem about Mr. Bayes.\n\nThe key difference is in the information given:\n\n• \"The older child is a girl\" eliminates two possibilities (BG and BB), leaving GG and GB → probability is 1/2.\n• \"At least one child is a girl\" eliminates only one possibility (BB), leaving GG, GB, and BG → probability is 1/3.\n\nFinal Answer\n\nThe probability that both children are girls, given that at least one of them is a girl, is:\n\n1/3",
        "timestamp": 1751811073.3713322
    },
    {
        "id": 13,
        "index": "A3.123",
        "topic": "Probability",
        "difficulty": "advanced",
        "keywords": [
            "sequential probability",
            "law of total probability",
            "conditional probability",
            "discrete distribution",
            "multi-stage experiment"
        ],
        "source": "Example 1.13, Page 28, *Introduction to Probability* by Dimitri P. Bertsekas and John N. Tsitsiklis (2nd Edition, 2008)",
        "problem": "We roll a fair four-sided die. If the result is 1 or 2, we roll once more but otherwise, we stop. What is the probability that the sum total of our rolls is at least 4?",
        "correct_solution": {
            "steps": [
                "1. Let A₁ be the event that the first roll is 1.",
                "2. Let A₂ be the event that the first roll is 2.",
                "3. Let A₃ be the event that the first roll is 3.",
                "4. Let A₄ be the event that the first roll is 4.",
                "5. For A₁: second roll needed. Probability that second roll is 3 or 4 (to make total ≥ 4) = 2/4 = 1/2.",
                "6. For A₂: need second roll ≥ 2 to make sum ≥ 4. Probability = 3/4.",
                "7. For A₃: no reroll, total is 3 < 4 ⇒ probability = 0.",
                "8. For A₄: total is already 4 ⇒ probability = 1.",
                "9. Use Total Probability Theorem:",
                "   P(B) = P(A₁)·P(B|A₁) + P(A₂)·P(B|A₂) + P(A₃)·P(B|A₃) + P(A₄)·P(B|A₄)",
                "   = 1/4·1/2 + 1/4·3/4 + 1/4·0 + 1/4·1",
                "   = 1/8 + 3/16 + 0 + 1/4 = 9/16"
            ],
            "conclusion": "The probability that the sum total of the rolls is at least 4 is 9/16.",
            "full_solution": "1. 1. Let A₁ be the event that the first roll is 1.\n2. 2. Let A₂ be the event that the first roll is 2.\n3. 3. Let A₃ be the event that the first roll is 3.\n4. 4. Let A₄ be the event that the first roll is 4.\n5. 5. For A₁: second roll needed. Probability that second roll is 3 or 4 (to make total ≥ 4) = 2/4 = 1/2.\n6. 6. For A₂: need second roll ≥ 2 to make sum ≥ 4. Probability = 3/4.\n7. 7. For A₃: no reroll, total is 3 < 4 ⇒ probability = 0.\n8. 8. For A₄: total is already 4 ⇒ probability = 1.\n9. 9. Use Total Probability Theorem:\n10. P(B) = P(A₁)·P(B|A₁) + P(A₂)·P(B|A₂) + P(A₃)·P(B|A₃) + P(A₄)·P(B|A₄)\n11.    = 1/4·1/2 + 1/4·3/4 + 1/4·0 + 1/4·1\n12.    = 1/8 + 3/16 + 0 + 1/4 = 9/16"
        },
        "model_response": "Alright, let's tackle this problem step by step. I'm going to think through it carefully to make sure I understand all the possible outcomes and how they contribute to the probability we're trying to find.\n\nUnderstanding the Problem\n\nWe have a fair four-sided die. When we roll it:\n\n• If the result is 1 or 2, we roll the die once more.\n• If the result is 3 or 4, we stop.\n\nWe want to find the probability that the sum total of our rolls is at least 4.\n\nBreaking Down the Possible Outcomes\n\nFirst, let's list all possible sequences of rolls based on the rules given. Since the die is four-sided, each face (1, 2, 3, 4) has an equal probability of 1/4 on any given roll.\n\nThere are two main scenarios based on the first roll:\n\n1. First roll is 1 or 2: We roll again.\n• Possible first rolls: 1, 2\n• For each of these, we have a second roll: 1, 2, 3, 4\n\n2. First roll is 3 or 4: We stop.\n• Possible first rolls: 3, 4\n\nNow, let's enumerate all possible sequences and their sums:\n\nFirst roll is 1:\n• 1, 1 → sum = 2\n• 1, 2 → sum = 3\n• 1, 3 → sum = 4\n• 1, 4 → sum = 5\n\nFirst roll is 2:\n• 2, 1 → sum = 3\n• 2, 2 → sum = 4\n• 2, 3 → sum = 5\n• 2, 4 → sum = 6\n\nFirst roll is 3:\n• 3 → sum = 3\n\nFirst roll is 4:\n• 4 → sum = 4\n\nCalculating Probabilities for Each Sequence\n\nEach initial roll (1, 2, 3, 4) has a probability of 1/4.\n\nIf the first roll is 1 or 2, the second roll also has a probability of 1/4 for each outcome. So, each two-roll sequence starting with 1 or 2 has a probability of (1/4) * (1/4) = 1/16.\n\nIf the first roll is 3 or 4, the sequence ends there with probability 1/4.\n\nNow, let's list all sequences with their sums and probabilities:\n\n1. (1,1): sum=2, P=1/16\n2. (1,2): sum=3, P=1/16\n3. (1,3): sum=4, P=1/16\n4. (1,4): sum=5, P=1/16\n5. (2,1): sum=3, P=1/16\n6. (2,2): sum=4, P=1/16\n7. (2,3): sum=5, P=1/16\n8. (2,4): sum=6, P=1/16\n9. (3): sum=3, P=1/4\n10. (4): sum=4, P=1/4\n\nIdentifying Sequences Where Sum ≥ 4\n\nWe're interested in sequences where the total sum is at least 4. Let's identify these:\n\nFrom the two-roll sequences:\n• (1,3): sum=4\n• (1,4): sum=5\n• (2,2): sum=4\n• (2,3): sum=5\n• (2,4): sum=6\n\nFrom the one-roll sequences:\n• (4): sum=4\n\nSo, the sequences where sum ≥ 4 are:\n• (1,3), (1,4), (2,2), (2,3), (2,4), (4)\n\nCalculating the Total Probability\n\nNow, let's sum the probabilities of these favorable outcomes:\n\n1. (1,3): P=1/16\n2. (1,4): P=1/16\n3. (2,2): P=1/16\n4. (2,3): P=1/16\n5. (2,4): P=1/16\n6. (4): P=1/4 = 4/16\n\nTotal probability = 1/16 + 1/16 + 1/16 + 1/16 + 1/16 + 4/16 = (1+1+1+1+1+4)/16 = 9/16\n\nVerifying the Calculation\n\nLet me double-check to ensure I haven't missed anything or counted incorrectly.\n\nTotal possible sequences and their probabilities:\n• Two-roll sequences (first roll 1 or 2): 8 sequences, each P=1/16 → total P=8/16=1/2\n• One-roll sequences (first roll 3 or 4): 2 sequences, each P=1/4 → total P=2/4=1/2\n\nTotal probability sums to 1/2 + 1/2 = 1, which checks out.\n\nFavorable sequences where sum ≥ 4:\n• From two-roll: 5 sequences → 5/16\n• From one-roll: 1 sequence (4) → 4/16\n\nTotal favorable: 5/16 + 4/16 = 9/16\n\nThis matches our previous calculation.\n\nAlternative Approach: Using Expected Values\n\nAnother way to approach this is to consider the expected outcomes based on the first roll.\n\n1. First roll is 1 (P=1/4):\n• Must roll again. Possible sums: 2,3,4,5, each with P=1/4.\n• P(sum≥4 | first=1) = P(second=3 or 4) = 2/4 = 1/2\n• Contribution to total P: (1/4)*(1/2) = 1/8\n\n2. First roll is 2 (P=1/4):\n• Must roll again. Possible sums: 3,4,5,6.\n• P(sum≥4 | first=2) = P(second=2,3,4) = 3/4\n• Contribution: (1/4)*(3/4) = 3/16\n\n3. First roll is 3 (P=1/4):\n• Stop. Sum=3.\n• P(sum≥4) = 0\n• Contribution: (1/4)*0 = 0\n\n4. First roll is 4 (P=1/4):\n• Stop. Sum=4.\n• P(sum≥4) = 1\n• Contribution: (1/4)*1 = 1/4\n\nTotal P(sum≥4) = 1/8 + 3/16 + 0 + 1/4\n= 2/16 + 3/16 + 0 + 4/16\n= 9/16\n\nThis confirms our previous answer.\n\nFinal Answer\n\nThe probability that the sum total of the rolls is at least 4 is:\n\n9/16",
        "timestamp": 1751811163.901417
    },
    {
        "id": 14,
        "index": "A3.234",
        "topic": "Probability",
        "difficulty": "advanced",
        "keywords": [
            "binomial distribution",
            "complement rule",
            "probability calculation",
            "at least probability"
        ],
        "source": "Based on a similar example from: Statology – 'Probability of at Least Three'",
        "problem": "A store has 20% off sales on items. If a customer buys 8 items, what is the probability that at least 3 of the items are on sale?",
        "correct_solution": {
            "steps": [
                "Step 1: Use the complement rule to find the probability of fewer than 3 items on sale: P(X < 3).",
                "Step 2: Calculate the probability of 0, 1, and 2 items on sale using the binomial formula: P(X = k) = C(n, k) * p^k * (1-p)^(n-k).",
                "Step 3: Compute: P(X = 0) = C(8, 0) * (0.20)^0 * (0.80)^8 ≈ 0.167, P(X = 1) = C(8, 1) * (0.20)^1 * (0.80)^7 ≈ 0.335, P(X = 2) = C(8, 2) * (0.20)^2 * (0.80)^6 ≈ 0.285.",
                "Step 4: Sum these probabilities: P(X < 3) ≈ 0.167 + 0.335 + 0.285 = 0.787.",
                "Step 5: Calculate the probability of at least 3 items on sale: 1 - P(X < 3) ≈ 1 - 0.787 = 0.213."
            ],
            "conclusion": "The probability that at least 3 out of 8 items are on sale is approximately 0.213.",
            "full_solution": "1. Step 1: Use the complement rule to find the probability of fewer than 3 items on sale: P(X < 3).\n2. Step 2: Calculate the probability of 0, 1, and 2 items on sale using the binomial formula: P(X = k) = C(n, k) * p^k * (1-p)^(n-k).\n3. Step 3: Compute: P(X = 0) = C(8, 0) * (0.20)^0 * (0.80)^8 ≈ 0.167, P(X = 1) = C(8, 1) * (0.20)^1 * (0.80)^7 ≈ 0.335, P(X = 2) = C(8, 2) * (0.20)^2 * (0.80)^6 ≈ 0.285.\n4. Step 4: Sum these probabilities: P(X < 3) ≈ 0.167 + 0.335 + 0.285 = 0.787.\n5. Step 5: Calculate the probability of at least 3 items on sale: 1 - P(X < 3) ≈ 1 - 0.787 = 0.213."
        },
        "model_response": "Alright, let's tackle this probability problem step by step. Here's how I understand it:\n\nProblem Statement:\n\nA store has a 20% off sale on some items. If a customer buys 8 items, what is the probability that at least 3 of the items are on sale?\n\nUnderstanding the Problem:\n\nFirst, we need to interpret what's given:\n• There's a store where some items are on sale at 20% off.\n• This implies that for any given item, there's a certain probability that it's on sale.\n• However, the problem doesn't specify what fraction of all items are on sale; it only mentions that items on sale have a 20% discount.\n\nThis seems a bit ambiguous. Typically, in probability problems like this, we'd assume that each item independently has a certain probability of being on sale. Since the problem mentions that items are on sale at 20% off, but doesn't specify the proportion of items that are on sale, it's more likely that it's implying that each item has a 20% chance of being on sale.\n\nSo, I'll proceed with the assumption that:\n• Each item has a 20% (or 0.2) probability of being on sale.\n• The purchases are independent; that is, whether one item is on sale doesn't affect the others.\n\nThis makes the scenario a classic binomial probability problem.\n\nBinomial Probability Basics:\n\nIn a binomial setting:\n• There are a fixed number of trials (n), here n = 8 (items purchased).\n• Each trial has two outcomes: success (item on sale) or failure (not on sale).\n• Probability of success (p) is the same for each trial, here p = 0.2.\n• Trials are independent.\n\nThe probability of getting exactly k successes (k items on sale) in n trials is given by the binomial probability formula:\n\nP(X = k) = C(n, k) × pᵏ × (1 - p)ⁿ⁻ᵏ\n\nWhere:\n• C(n, k) is the number of combinations of n items taken k at a time, calculated as (n!)/(k!(n-k)!).\n\nWhat We Need to Find:\n\nWe want the probability that at least 3 items are on sale, i.e., P(X ≥ 3).\n\nThis can be calculated as:\nP(X ≥ 3) = 1 - P(X ≤ 2)\nP(X ≤ 2) = P(X = 0) + P(X = 1) + P(X = 2)\n\nSo, we'll calculate P(X = 0), P(X = 1), and P(X = 2), sum them up, and subtract from 1.\n\nCalculating Individual Probabilities:\n\n1. P(X = 0):\nC(8, 0) × 0.2⁰ × 0.8⁸ = 1 × 1 × 0.8⁸\n0.8⁸ ≈ 0.1678\n\n2. P(X = 1):\nC(8, 1) × 0.2¹ × 0.8⁷ = 8 × 0.2 × 0.8⁷\n0.8⁷ ≈ 0.2097\n8 × 0.2 × 0.2097 ≈ 0.3355\n\n3. P(X = 2):\nC(8, 2) × 0.2² × 0.8⁶\nC(8, 2) = 8! / (2! × 6!) = 28\n0.8⁶ ≈ 0.2621\n28 × 0.04 × 0.2621 ≈ 28 × 0.010484 ≈ 0.2936\n\nSumming Up for P(X ≤ 2):\nP(X = 0) ≈ 0.1678\nP(X = 1) ≈ 0.3355\nP(X = 2) ≈ 0.2936\nP(X ≤ 2) ≈ 0.1678 + 0.3355 + 0.2936 ≈ 0.7969\n\nCalculating P(X ≥ 3):\nP(X ≥ 3) = 1 - P(X ≤ 2) ≈ 1 - 0.7969 = 0.2031\n\nVerification:\nLet me quickly verify the calculations to ensure no mistakes were made.\n\n• 0.8⁸: Calculating step-by-step:\n• 0.8² = 0.64\n• 0.8⁴ = 0.64² = 0.4096\n• 0.8⁸ = 0.4096² ≈ 0.1678 ✔\n\n• C(8, 1) = 8 ✔\n• 0.8⁷: 0.4096 × 0.8 ≈ 0.32768, but earlier I approximated 0.8⁷ ≈ 0.2097. Wait, that seems incorrect.\n• Actually, 0.8⁷ ≈ 0.2097152, so my initial approximation was correct. ✔\n• 8 × 0.2 × 0.2097 ≈ 0.3355 ✔\n\n• C(8, 2) = 28 ✔\n• 0.8⁶ ≈ 0.262144 ✔\n• 28 × 0.04 × 0.262 ≈ 0.2936 ✔\n\nAdding them: 0.1678 + 0.3355 + 0.2936 = 0.7969 ✔\n1 - 0.7969 = 0.2031 ✔\n\nFinal Answer:\nThe probability that at least 3 of the 8 items are on sale is approximately 0.2031, or 20.31%.\n\nExpressed as a fraction (since the probabilities are exact in terms of powers of 0.2 and 0.8), it's exactly:\n\nP(X ≥ 3) = 1 - [ C(8,0) × 0.2⁰ × 0.8⁸ + C(8,1) × 0.2¹ × 0.8⁷ + C(8,2) × 0.2² × 0.8⁶ ]\n= 1 - [ 1 × 1 × 0.8⁸ + 8 × 0.2 × 0.8⁷ + 28 × 0.04 × 0.8⁶ ]\n= 1 - [ 0.8⁸ + 1.6 × 0.8⁷ + 1.12 × 0.8⁶ ]\n\nCalculating the exact decimal:\n0.8⁸ ≈ 0.16777216\n0.8⁷ ≈ 0.2097152\n1.6 × 0.2097152 ≈ 0.33554432\n0.8⁶ ≈ 0.262144\n1.12 × 0.262144 ≈ 0.29360128\n\nSum ≈ 0.16777216 + 0.33554432 + 0.29360128 ≈ 0.79691776\n1 - 0.79691776 ≈ 0.20308224\n\nSo, the precise probability is approximately 0.2031.\n\nExpressed in Fractional Form:\nIf we want to express it exactly without decimals, we can calculate the exact binomial probabilities:\n\nP(X ≥ 3) = 1 - [ (8 choose 0) × 0.2⁰ × 0.8⁸ + (8 choose 1) × 0.2¹ × 0.8⁷ + (8 choose 2) × 0.2² × 0.8⁶ ]\n= 1 - [ 1 × 1 × (4/5)⁸ + 8 × 1/5 × (4/5)⁷ + 28 × 1/25 × (4/5)⁶ ]\n= 1 - [ (4/5)⁸ + 8/5 × (4/5)⁷ + 28/25 × (4/5)⁶ ]\n\nCalculating the exact fraction would involve computing these terms, but the decimal approximation is sufficient for most practical purposes.\n\nConclusion:\nAfter carefully calculating, the probability that at least 3 out of 8 items are on sale is approximately 0.2031, or 20.31%.\n\n0.2031",
        "timestamp": 1751811254.418381
    },
    {
        "id": 15,
        "index": "A3.345",
        "topic": "Probability",
        "difficulty": "advanced",
        "keywords": [
            "hypergeometric distribution",
            "disease probability",
            "sampling without replacement",
            "combinatorics"
        ],
        "source": "Understanding Advanced Statistical Methods by Westfall & Henning",
        "problem": "In a population of 200 people, 30 have a certain disease. If 10 people are randomly selected, what is the probability that exactly 4 of them have the disease?",
        "correct_solution": {
            "steps": [
                "Step 1: Use the hypergeometric distribution formula: P(X = k) = (C(K, k) * C(N-K, n-k)) / C(N, n).",
                "Step 2: Substitute N = 200, K = 30, n = 10, k = 4: P(X = 4) = (C(30, 4) * C(170, 6)) / C(200, 10).",
                "Step 3: Compute: C(30, 4) = 27,405, C(170, 6) = 230,230, C(200, 10) = 1,647,100,900.",
                "Step 4: Calculate the probability: P(X = 4) = (27,405 * 230,230) / 1,647,100,900 ≈ 0.386.",
                "Step 5: Thus, the probability that exactly 4 out of 10 selected people have the disease is approximately 0.386."
            ],
            "conclusion": "The probability that exactly 4 out of 10 selected people have the disease is approximately 0.386.",
            "full_solution": "1. Step 1: Use the hypergeometric distribution formula: P(X = k) = (C(K, k) * C(N-K, n-k)) / C(N, n).\n2. Step 2: Substitute N = 200, K = 30, n = 10, k = 4: P(X = 4) = (C(30, 4) * C(170, 6)) / C(200, 10).\n3. Step 3: Compute: C(30, 4) = 27,405, C(170, 6) = 230,230, C(200, 10) = 1,647,100,900.\n4. Step 4: Calculate the probability: P(X = 4) = (27,405 * 230,230) / 1,647,100,900 ≈ 0.386.\n5. Step 5: Thus, the probability that exactly 4 out of 10 selected people have the disease is approximately 0.386."
        },
        "model_response": "1. Let's denote the number of people with the disease as X.\n\n2. Since 30 out of 200 people have the disease, we can calculate the probability of a single person having the disease:\n\n   P(X = 1) = Number of people with disease / Total population\n           = 30 / 200\n           = 0.15\n\n3. We want to find the probability that exactly 4 out of 10 randomly selected people have the disease. To do this, we'll use the binomial distribution formula:\n\n   P(X = k) = (nCk) * (p^k) * (q^(n - k))\n\n   where:\n   - n is the number of trials (10)\n   - k is the number of successes (4)\n   - p is the probability of success (0.15)\n   - q is the probability of failure (1 - 0.15 = 0.85)\n   - nCk is the number of combinations of n items taken k at a time\n\n4. Plug in the values:\n\n   P(X = 4) = (10C4) * (0.15^4) * (0.85^6)\n           = 210 * 0.003375 * 0.59875\n           ≈ 0.0645",
        "timestamp": 1751811318.6743839
    },
    {
        "id": 16,
        "index": "A3.456",
        "topic": "Bias and Logistic Thinking",
        "difficulty": "advanced",
        "keywords": [
            "discrimination",
            "bias",
            "promotion",
            "gender imbalance",
            "logistic reasoning"
        ],
        "source": "OpenIntro Statistics, 4th Edition (2019), Example 9.35, Chapter 9, Page 379",
        "problem": "Let's consider a sex-imbalanced company that consists of 20% women and 80% men. Suppose that the company is very large, consisting of perhaps 20,000 employees. Suppose when someone goes up for promotion at this company, 5 of their colleagues are randomly chosen to provide feedback on their work. Now let's imagine that 10% of the people in the company are prejudiced against the other sex. That is, 10% of men are prejudiced against women, and similarly, 10% of women are prejudiced against men. Who is discriminated against more at the company, men or women?",
        "correct_solution": {
            "steps": [
                "For 100 men going for promotion, 5 × 100 = 500 colleagues will review them. Since the company has 20% women, approximately 100 of the 500 reviewers are women.",
                "Of these 100 women, 10% = 10 are biased against men, resulting in 10 biased reviews out of 500 → 2% discrimination rate.",
                "For 100 women going for promotion, again 500 colleagues provide feedback. With 80% men in the company, 400 of the 500 reviewers are men.",
                "Of these 400 men, 10% = 40 are biased against women, leading to 40 biased reviews out of 500 → 8% discrimination rate."
            ],
            "conclusion": "Women experience higher discrimination (8%) compared to men (2%) in this scenario, despite equal bias percentages among colleagues.",
            "full_solution": "1. For 100 men going for promotion, 5 × 100 = 500 colleagues will review them. Since the company has 20% women, approximately 100 of the 500 reviewers are women.\n2. Of these 100 women, 10% = 10 are biased against men, resulting in 10 biased reviews out of 500 → 2% discrimination rate.\n3. For 100 women going for promotion, again 500 colleagues provide feedback. With 80% men in the company, 400 of the 500 reviewers are men.\n4. Of these 400 men, 10% = 40 are biased against women, leading to 40 biased reviews out of 500 → 8% discrimination rate."
        },
        "model_response": "Alright, let's tackle this problem methodically. We're dealing with a large company with a significant gender imbalance, and we're examining how prejudice affects promotions based on feedback from randomly selected colleagues. Here's how I'll approach it:\n\nUnderstanding the Problem\n\n1. Company Composition:\n   - Total employees: ~20,000.\n   - Women: 20% → 4,000 women.\n   - Men: 80% → 16,000 men.\n\n2. Prejudice Distribution:\n   - 10% of men are prejudiced against women → 10% of 16,000 = 1,600 prejudiced men.\n   - 10% of women are prejudiced against men → 10% of 4,000 = 400 prejudiced women.\n\n3. Promotion Feedback:\n   - When someone is up for promotion, 5 colleagues are randomly chosen to provide feedback.\n   - These 5 are selected from the entire company (assuming uniform random selection across all employees).\n\n4. Discrimination Impact:\n   - If a prejudiced person is selected to give feedback on someone of the gender they're prejudiced against, they might give negative feedback, potentially harming that person's promotion chances.\n   - We need to determine the probability that a man or a woman up for promotion has at least one prejudiced colleague in their feedback panel, and how that affects their chances.\n\nCalculating Probabilities\n\nLet's calculate the probability that a person has at least one prejudiced colleague in their feedback panel when they're up for promotion.\n\nFor a Woman Up for Promotion:\n- Prejudiced colleagues: Men prejudiced against women = 1,600.\n- Total prejudiced colleagues against women: 1,600 (since women prejudiced against women isn't mentioned, assuming only men are prejudiced against women based on the given data).\n- Total employees: 20,000.\n- Probability that a randomly selected colleague is prejudiced against women: 1,600 ÷ 20,000 = 0.08.\n- Probability a colleague is not prejudiced: 1 − 0.08 = 0.92.\n- For 5 colleagues, probability none are prejudiced: 0.92⁵ ≈ 0.659.\n- Therefore, probability at least one is prejudiced: 1 − 0.659 = 0.341 or 34.1%.\n\nFor a Man Up for Promotion:\n- Prejudiced colleagues: Women prejudiced against men = 400.\n- Total prejudiced colleagues against men: 400.\n- Probability a randomly selected colleague is prejudiced against men: 400 ÷ 20,000 = 0.02.\n- Probability a colleague is not prejudiced: 1 − 0.02 = 0.98.\n- For 5 colleagues, probability none are prejudiced: 0.98⁵ ≈ 0.904.\n- Therefore, probability at least one is prejudiced: 1 − 0.904 = 0.096 or 9.6%.\n\nComparing Discrimination\n- Women: 34.1% chance at least one prejudiced colleague in feedback panel.\n- Men: 9.6% chance at least one prejudiced colleague in feedback panel.\n\nThis means that a woman up for promotion is more than three times as likely as a man to have at least one prejudiced colleague evaluating her, suggesting that women are discriminated against more in this company.\n\nVerifying Assumptions\n\n1. Prejudice Direction:\n   - The problem states that 10% of men are prejudiced against women, and similarly, 10% of women are prejudiced against men.\n   - It doesn't specify same-sex prejudice, so we're assuming:\n     - Prejudiced men are only against women.\n     - Prejudiced women are only against men.\n   - If there were same-sex prejudices, it might complicate things, but the problem seems to imply cross-sex prejudice only.\n\n2. Random Selection:\n   - Assuming feedback colleagues are chosen uniformly from all employees, not restricted by department or other factors.\n\n3. Impact of Prejudice:\n   - We're assuming that having at least one prejudiced colleague negatively impacts the promotion chance.\n   - The more prejudiced colleagues, the higher the chance of negative impact, but we're just counting the presence here.\n\nAlternative Interpretation\n\nIf we consider that prejudiced individuals might be more likely to give negative feedback, then the group with a higher probability of encountering prejudiced evaluators faces more discrimination. Our calculations show women are more likely to face prejudiced evaluators.\n\nPotential Missteps\n\nInitially, one might think that since there are more men, and 10% of them are prejudiced, the absolute number is higher, leading to more prejudice against women. However, it's essential to calculate the probabilities correctly based on how feedback panels are selected.\n\nAnother potential confusion could be whether the 10% prejudice applies uniformly or if there are overlapping prejudices, but the problem states it clearly: 10% of men are prejudiced against women, and similarly, 10% of women are prejudiced against men.\n\nFinal Answer\n\nAfter carefully analyzing the probabilities:\n- Women up for promotion have a 34.1% chance of having at least one prejudiced colleague in their feedback panel.\n- Men up for promotion have a 9.6% chance of having at least one prejudiced colleague in their feedback panel.\n\nTherefore, women are discriminated against more in this company when it comes to promotions based on colleague feedback.\n\nAnswer: Women are discriminated against more.",
        "timestamp": 1751811383.33378
    },
    {
        "id": 17,
        "index": "A3.567",
        "topic": "Probability Distributions",
        "difficulty": "advanced",
        "keywords": [
            "normal distribution",
            "z-score",
            "binomial distribution",
            "poisson distribution",
            "expected value",
            "tail probability"
        ],
        "source": "OpenIntro Statistics, 4th Edition (2019), Example 4.47, Chapter 4, Page 151",
        "problem": "Heights of 10 year olds, regardless of gender, closely follow a normal distribution with mean 55 inches and standard deviation 6 inches. (a) What fraction of 10 year olds are taller than 76 inches? (b) If there are 2,000 10 year olds entering Six Flags Magic Mountain in a single day, then compute the expected number of 10 year olds who are at least 76 inches tall. (Assume independence.) (c) Using the binomial distribution, compute the probability that 0 of the 2,000 10 year olds will be at least 76 inches tall. (d) The number of 10 year olds who enter Six Flags Magic Mountain and are at least 76 inches tall in a given day follows a Poisson distribution with mean equal to the value found in part (b). Use the Poisson distribution to identify the probability that no 10 year old will enter the park who is 76 inches or taller.",
        "correct_solution": {
            "steps": [
                "(a) Use the standard normal distribution: z = (76 - 55) / 6 = 3.5. Then P(Z > 3.5) ≈ 0.00023. So, approximately 0.023% of 10-year-olds are taller than 76 inches.",
                "(b) Expected number = 2000 × 0.00023 ≈ 0.46 children.",
                "(c) Use Binomial distribution: n = 2000, p = 0.00023. P(X = 0) = (1 - 0.00023)^2000 ≈ e^(-0.46) ≈ 0.631.",
                "(d) Use Poisson distribution with λ = 0.46. P(X = 0) = e^(-0.46) ≈ 0.631."
            ],
            "conclusion": "The expected number of children ≥76 inches is less than 1, and the probability of observing 0 such children out of 2,000 is approximately 63%.",
            "full_solution": "1. (a) Use the standard normal distribution: z = (76 - 55) / 6 = 3.5. Then P(Z > 3.5) ≈ 0.00023. So, approximately 0.023% of 10-year-olds are taller than 76 inches.\n2. (b) Expected number = 2000 × 0.00023 ≈ 0.46 children.\n3. (c) Use Binomial distribution: n = 2000, p = 0.00023. P(X = 0) = (1 - 0.00023)^2000 ≈ e^(-0.46) ≈ 0.631.\n4. (d) Use Poisson distribution with λ = 0.46. P(X = 0) = e^(-0.46) ≈ 0.631."
        },
        "model_response": "Solution to the Height Distribution Problem\n\nWe are given:\n- Heights of 10-year-olds follow a normal distribution with:\n- Mean (μ) = 55 inches,\n- Standard deviation (σ) = 6 inches.\n\nWe need to answer four questions related to this distribution.\n\n⸻\n\n(a) Fraction of 10-Year-Olds Taller Than 76 Inches\n\nStep 1: Calculate the Z-score for 76 inches\nThe Z-score measures how many standard deviations a value is from the mean:\n\nZ = (76 - 55) / 6 = 21 / 6 = 3.5\n\nStep 2: Find P(X > 76) using the Z-table\nWe look up the probability corresponding to Z = 3.5:\n- The cumulative probability P(Z ≤ 3.5) ≈ 0.999767\n- Therefore, P(X > 76) = 1 - 0.999767 = 0.000233\n\nAnswer:\nThe fraction of 10-year-olds taller than 76 inches is approximately 0.000233 (or 0.0233%)\n\nBoxed Answer: 0.000233\n\n⸻\n\n(b) Expected Number of 10-Year-Olds ≥ 76 Inches in 2,000 Kids\n\nStep 1: Use the probability from part (a)\nP(X > 76) ≈ 0.000233\n\nStep 2: Compute the expected value\nE = 2000 × 0.000233 ≈ 0.466\n\nAnswer:\nThe expected number of 10-year-olds at least 76 inches tall is approximately 0.466\n\nBoxed Answer: 0.466\n\n⸻\n\n(c) Probability That 0 of 2,000 Kids Are ≥ 76 Inches (Binomial Distribution)\n\nStep 1: Define the binomial parameters\n- n = 2000\n- p = 0.000233\n\nStep 2: Compute P(k = 0)\nP(k = 0) = (1 - 0.000233)^2000\n\nApproximation using exponential:\nP(k = 0) ≈ e^(-2000 × 0.000233) = e^(-0.466) ≈ 0.627\n\nAnswer:\nThe probability that none of the 2,000 kids are at least 76 inches tall is approximately 0.627\n\nBoxed Answer: 0.627\n\n⸻\n\n(d) Probability That 0 Kids Are ≥76 Inches (Poisson Approximation)\n\nStep 1: Poisson parameter (λ)\nλ = 0.466\n\nStep 2: Compute P(k = 0)\nP(k = 0) = (e^(-0.466) × 0.466^0) / 0! = e^(-0.466) ≈ 0.627\n\nAnswer:\nThe Poisson approximation gives the same probability as the binomial calculation: 0.627\n\nBoxed Answer: 0.627\n\n⸻\n\nSummary of Results\n1. Fraction >76 inches: 0.000233\n2. Expected number in 2000 kids: 0.466\n3. Binomial P(k = 0): 0.627\n4. Poisson P(k = 0): 0.627",
        "timestamp": 1751811473.850255
    },
    {
        "id": 18,
        "index": "A3.678",
        "topic": "Poisson Distribution with Uncertainty",
        "difficulty": "advanced",
        "keywords": [
            "Poisson distribution",
            "mixture model",
            "expected value",
            "total probability",
            "discrete distribution"
        ],
        "source": "Adapted from Sheldon Ross, A First Course in Probability, 9th Edition, Chapter 3: Conditional Probability and Conditional Expectation, Page 183",
        "problem": "The opponents of soccer team A are of two types: either they are a class 1 or a class 2 team. The number of goals team A scores against a class i opponent is a Poisson random variable with mean λᵢ, where λ₁ = 2, λ₂ = 3. This weekend, the team has two games against teams they are not very familiar with. Assuming that the first team they play is a class 1 team with probability 0.6 and the second is, independently of the class of the first team, a class 1 team with probability 0.3, determine: (a) the expected number of goals team A will score this weekend; (b) the probability that team A will score a total of five goals.",
        "correct_solution": {
            "steps": [
                "(a) Let X₁ and X₂ be the number of goals in the first and second games. Define λ₁ = 2 (class 1 team), λ₂ = 3 (class 2 team). E[X₁] = 0.6 × 2 + 0.4 × 3 = 1.2 + 1.2 = 2.4. E[X₂] = 0.3 × 2 + 0.7 × 3 = 0.6 + 2.1 = 2.7. E[Total Goals] = E[X₁] + E[X₂] = 2.4 + 2.7 = 5.1",
                "(b) We need to compute P(X₁ + X₂ = 5), where X₁ and X₂ are independent Poisson mixtures. Use total probability by conditioning on combinations of class types (there are 4 cases), then weight each by the probability of class combination. Case 1: Both class 1 → P = 0.6 × 0.3 = 0.18; λ_total = 2 + 2 = 4 → P(X=5) = e^-4 * 4^5 / 5! = 0.1563. Case 2: First class 1, second class 2 → P = 0.6 × 0.7 = 0.42; λ_total = 2 + 3 = 5 → P(X=5) = e^-5 * 5^5 / 5! = 0.1755. Case 3: First class 2, second class 1 → P = 0.4 × 0.3 = 0.12; λ_total = 3 + 2 = 5 → P(X=5) = 0.1755. Case 4: Both class 2 → P = 0.4 × 0.7 = 0.28; λ_total = 3 + 3 = 6 → P(X=5) = e^-6 * 6^5 / 5! = 0.1606. Weighted sum: 0.18×0.1563 + 0.42×0.1755 + 0.12×0.1755 + 0.28×0.1606 ≈ 0.0281 + 0.0737 + 0.0211 + 0.0450 = 0.168"
            ],
            "conclusion": "The expected number of goals team A will score this weekend is 5.1. The probability that team A will score exactly 5 goals is approximately 0.168."
        },
        "model_response": "Solution to the Soccer Team Problem\n\nWe are given:\n- Team A plays against two types of opponents: Class 1 and Class 2.\n- Goals scored against:\n  - Class 1: Poisson(λ = 2),\n  - Class 2: Poisson(λ = 3).\n- This weekend, Team A plays two games:\n  - Game 1: Class 1 with probability 0.6, Class 2 with probability 0.4.\n  - Game 2: Class 1 with probability 0.3, Class 2 with probability 0.7 (independent of Game 1).\n\nWe need to determine:\n1. (a) The expected number of goals Team A will score this weekend.\n2. (b) The probability that Team A scores a total of five goals in the two games.\n\n⸻\n\n(a) Expected Number of Goals This Weekend\n\nThe total expected goals E[Total Goals] is the sum of the expected goals in each game.\n\nGame 1:\n- If vs. Class 1 (probability 0.6): Expected goals = 2\n- If vs. Class 2 (probability 0.4): Expected goals = 3\n- Expected goals in Game 1:\nE[G1] = (0.6 × 2) + (0.4 × 3) = 1.2 + 1.2 = 2.4\n\nGame 2:\n- If vs. Class 1 (probability 0.3): Expected goals = 2\n- If vs. Class 2 (probability 0.7): Expected goals = 3\n- Expected goals in Game 2:\nE[G2] = (0.3 × 2) + (0.7 × 3) = 0.6 + 2.1 = 2.7\n\nTotal Expected Goals:\n\nE[Total Goals] = E[G1] + E[G2] = 2.4 + 2.7 = 5.1\n\nAnswer:\nThe expected number of goals Team A will score this weekend is 5.1\n\n⸻\n\n(b) Probability of Scoring Exactly Five Goals\n\nTo find P(Total Goals = 5), we consider all possible combinations of opponent classes in the two games and their corresponding goal distributions.\n\nPossible Scenarios:\n1. Game 1 vs. Class 1, Game 2 vs. Class 1\n   - Probability: 0.6 × 0.3 = 0.18\n   - Total goals: Poisson(2) + Poisson(2) = Poisson(4)\n   - P(Total = 5 | Class 1, Class 1) = (e^(-4) × 4^5) / 5! ≈ 0.1563\n\n2. Game 1 vs. Class 1, Game 2 vs. Class 2\n   - Probability: 0.6 × 0.7 = 0.42\n   - Total goals: Poisson(2) + Poisson(3) = Poisson(5)\n   - P(Total = 5 | Class 1, Class 2) = (e^(-5) × 5^5) / 5! ≈ 0.1755\n\n3. Game 1 vs. Class 2, Game 2 vs. Class 1\n   - Probability: 0.4 × 0.3 = 0.12\n   - Total goals: Poisson(3) + Poisson(2) = Poisson(5)\n   - Same as above ≈ 0.1755\n\n4. Game 1 vs. Class 2, Game 2 vs. Class 2\n   - Probability: 0.4 × 0.7 = 0.28\n   - Total goals: Poisson(3) + Poisson(3) = Poisson(6)\n   - P(Total = 5 | Class 2, Class 2) = (e^(-6) × 6^5) / 5! ≈ 0.1606\n\nTotal Probability:\n\nP(Total = 5) =\n(0.18 × 0.1563) + (0.42 × 0.1755) + (0.12 × 0.1755) + (0.28 × 0.1606)\n= 0.0281 + 0.0737 + 0.0211 + 0.0450 ≈ 0.1679\n\nAnswer:\nThe probability that Team A scores a total of five goals is approximately 0.1679 (or 16.79%)\n\n⸻\n\nSummary of Results\n1. Expected total goals: 5.1\n2. Probability of 5 goals: 0.1679",
        "timestamp": 1751811551.4510348
    },
    {
        "id": 19,
        "index": "B3.789",
        "topic": "Gender and Degree Distributions",
        "difficulty": "advanced",
        "keywords": [
            "EDA",
            "gender distribution",
            "degree analysis",
            "conditional probability",
            "gender gap index"
        ],
        "source": "OpenIntro Statistics Dataset Analysis",
        "problem": "Using the provided counts (in thousands) of earned degrees in the U.S. by gender and degree type, perform an exploratory data analysis to understand trends and imbalances. Specifically, analyze: (1) overall gender distribution, (2) the distribution of degrees within each gender, (3) the conditional probability of selecting a male given a Master's degree, (4) gender gap index for each degree type, and (5) the most gender-skewed degree type. Data: Bachelor's: Female 616, Male 529; Master's: Female 194, Male 171; Professional: Female 30, Male 44; Doctorate: Female 16, Male 26.",
        "correct_solution": {
            "steps": [
                "Step 1: Compute total number of degree recipients: Total = 616 + 529 + 194 + 171 + 30 + 44 + 16 + 26 = 1626 (in thousands).",
                "Step 2: Calculate total recipients by gender: Total Female = 616 + 194 + 30 + 16 = 856, Total Male = 529 + 171 + 44 + 26 = 770",
                "Step 3: Compute overall gender distribution: P(Female) = 856 / 1626 ≈ 0.5264 (52.64%), P(Male) = 770 / 1626 ≈ 0.4736 (47.36%)",
                "Step 4: Calculate the proportion of each degree type within each gender: For Females: Bachelor's = 616 / 856 ≈ 0.7196 (71.96%), Master's = 194 / 856 ≈ 0.2266 (22.66%), Professional = 30 / 856 ≈ 0.0350 (3.5%), Doctorate = 16 / 856 ≈ 0.0187 (1.87%). For Males: Bachelor's = 529 / 770 ≈ 0.6870 (68.70%), Master's = 171 / 770 ≈ 0.2221 (22.21%), Professional = 44 / 770 ≈ 0.0571 (5.71%), Doctorate = 26 / 770 ≈ 0.0338 (3.38%)",
                "Step 5: Calculate conditional probability: P(Male | Master's) = 171 / (171 + 194) = 171 / 365 ≈ 0.4685 (46.85%)",
                "Step 6: Compute the Gender Gap Index (GGI) for each degree type: GGI = (Female - Male) / (Female + Male). Bachelor's: (616 - 529) / (616 + 529) ≈ 0.076 (Female-dominant), Master's: (194 - 171) / (194 + 171) ≈ 0.063 (Female-dominant), Professional: (30 - 44) / (30 + 44) ≈ -0.1892 (Male-dominant), Doctorate: (16 - 26) / (16 + 26) ≈ -0.2381 (Male-dominant)",
                "Step 7: Identify the degree type with highest gender imbalance: Doctorate degree has the highest GGI magnitude (≈ 0.2381), indicating the strongest gender skew—toward males."
            ],
            "conclusion": "The majority of degree recipients are women (52.64%). However, gender dominance varies by degree level. While women dominate at Bachelor's and Master's levels, men are more prevalent in Professional and Doctorate degrees. The greatest gender disparity is observed in Doctorate degrees, heavily favoring men."
        },
        "model_response": "Exploratory Data Analysis (EDA) of Earned Degrees by Gender and Degree Type\n\nWe analyze the given data (in thousands) to uncover trends and imbalances in degree attainment by gender.\n\nData Summary:\n\nDegree Type    Female Male    Total\nBachelor's       616      529      1145\nMaster's          194      171      365\nProfessional     30        44        74\nDoctorate        16        26        42\nTotal    856      770      1626\n\n⸻\n\n1. Overall Gender Distribution\n- Female: 856k (52.6% of total degrees)\n- Male: 770k (47.4% of total degrees)\n- Conclusion: Females earn slightly more degrees overall (52.6% vs. 47.4%)\n\n⸻\n\n2. Distribution of Degrees Within Each Gender\n\nFemale Degree Distribution:\n\nDegree Type    Count (Female) % of Female Degrees\nBachelor's       616      72.0%\nMaster's          194      22.7%\nProfessional     30        3.5%\nDoctorate        16        1.9%\n\nMale Degree Distribution:\n\nDegree Type    Count (Male)    % of Male Degrees\nBachelor's       529      68.7%\nMaster's          171      22.2%\nProfessional     44        5.7%\nDoctorate        26        3.4%\n\nKey Observations:\n- Both genders follow a similar distribution, with Bachelor's degrees dominating (~70%)\n- Males have a higher proportion of Professional/Doctorate degrees (9.1% combined) compared to females (5.4% combined)\n\n⸻\n\n3. Conditional Probability: P(Male | Master's Degree)\n\nP(Male | Master's) = Male Master's / Total Master's = 171 / 365 ≈ 46.8%\n\nInterpretation: Among Master's degree holders, 46.8% are male.\n\n⸻\n\n4. Gender Gap Index for Each Degree Type\n\nThe Gender Gap Index (GGI) measures disparity as:\nGGI = Female / Male\n- Bachelor's: 616 / 529 = 1.16 (Female-favoring)\n- Master's: 194 / 171 = 1.13 (Female-favoring)\n- Professional: 30 / 44 = 0.68 (Male-favoring)\n- Doctorate: 16 / 26 = 0.62 (Male-favoring)\n\nConclusion:\n- Females dominate in Bachelor's and Master's (GGI > 1)\n- Males dominate in Professional and Doctorate (GGI < 1)\n\n⸻\n\n5. Most Gender-Skewed Degree Type\n- Most Female-Skewed: Bachelor's (GGI = 1.16)\n- Most Male-Skewed: Doctorate (GGI = 0.62)\n\nProfessional degrees are also highly male-skewed (GGI = 0.68), but Doctorates show the largest disparity\n\n⸻\n\nKey Takeaways\n1. Gender Imbalance: Females earn more degrees overall, but males lead in advanced degrees (Professional/Doctorate)\n2. Degree Trends:\n   - Bachelor's and Master's are female-dominated\n   - Professional and Doctorate are male-dominated\n3. Policy Implications: Efforts to encourage female participation in advanced degrees (e.g., STEM Doctorates) could address disparities\n\n⸻\n\nFinal Answer\n1. Overall Gender Distribution:\n   - Female: 52.6%, Male: 47.4%\n2. Degree Distribution by Gender:\n   - Females: 72% Bachelor's, 23% Master's, 3.5% Professional, 1.9% Doctorate\n   - Males: 69% Bachelor's, 22% Master's, 5.7% Professional, 3.4% Doctorate\n3. P(Male | Master's): 46.8%\n4. Gender Gap Index (GGI):\n  - Bachelor's: 1.16\n  - Master's: 1.13\n  - Professional: 0.68\n  - Doctorate: 0.62\n5. Most Gender-Skewed Degree:\n  - Female-skewed: Bachelor's (1.16)\n  - Male-skewed: Doctorate (0.62)",
        "timestamp": 1751811641.9679732
    },
    {
        "id": 20,
        "index": "C1.234",
        "topic": "Confidence Interval",
        "difficulty": "basic",
        "keywords": [
            "confidence interval",
            "t-distribution",
            "sample mean",
            "margin of error"
        ],
        "source": "Understanding Confidence Intervals - Statistical Guide",
        "problem": "A teacher records the test scores of 10 students with an average score of 78 and a standard deviation of 5. Calculate the 95% confidence interval for the mean test score.",
        "correct_solution": {
            "steps": [
                "Step 1: Identify the sample mean (x̄) = 78, standard deviation (σ) = 5, and sample size (n) = 10.",
                "Step 2: Compute the standard error of the mean (SE) = σ / √n = 5 / √10 ≈ 1.581.",
                "Step 3: Find the t-value for a 95% confidence level with n-1 degrees of freedom (t ≈ 2.262).",
                "Step 4: Calculate the margin of error (ME) = t * SE = 2.262 * 1.581 ≈ 3.58.",
                "Step 5: Construct the confidence interval: Lower limit = x̄ - ME = 78 - 3.58 = 74.42, Upper limit = x̄ + ME = 78 + 3.58 = 81.58.",
                "Step 6: Thus, the 95% confidence interval is (74.42, 81.58)."
            ],
            "conclusion": "The 95% confidence interval for the mean test score is (74.42, 81.58).",
            "full_solution": "1. Step 1: Identify the sample mean (x̄) = 78, standard deviation (σ) = 5, and sample size (n) = 10.\n2. Step 2: Compute the standard error of the mean (SE) = σ / √n = 5 / √10 ≈ 1.581.\n3. Step 3: Find the t-value for a 95% confidence level with n-1 degrees of freedom (t ≈ 2.262).\n4. Step 4: Calculate the margin of error (ME) = t * SE = 2.262 * 1.581 ≈ 3.58.\n5. Step 5: Construct the confidence interval: Lower limit = x̄ - ME = 78 - 3.58 = 74.42, Upper limit = x̄ + ME = 78 + 3.58 = 81.58.\n6. Step 6: Thus, the 95% confidence interval is (74.42, 81.58)."
        },
        "model_response": "Solution: Calculating the 95% Confidence Interval for the Mean Test Score\n\nWe are given:\n- Sample size (n): 10 students\n- Sample mean (x̄): 78\n- Sample standard deviation (s): 5\n- Confidence level: 95%\n\nSince the population standard deviation is unknown and the sample size is small (n < 30), we use the t-distribution to compute the confidence interval.\n\n⸻\n\nStep 1: Determine the Critical t-Value\n\nFor a 95% confidence interval with n = 10:\n- Degrees of freedom (df) = 10 − 1 = 9\n- Critical t-value: t = 2.262\n\n⸻\n\nStep 2: Compute the Standard Error (SE)\n\nSE = s / sqrt(n) = 5 / sqrt(10) ≈ 1.581\n\n⸻\n\nStep 3: Calculate the Margin of Error (ME)\n\nME = t × SE = 2.262 × 1.581 ≈ 3.577\n\n⸻\n\nStep 4: Construct the 95% Confidence Interval\n\nConfidence Interval = x̄ ± ME = 78 ± 3.577\n\nSo:\nLower bound = 78 − 3.577 ≈ 74.423\nUpper bound = 78 + 3.577 ≈ 81.577\n\n⸻\n\nFinal Answer\n\nThe 95% confidence interval for the mean test score is approximately:\n(74.42, 81.58)\n\n⸻\n\nInterpretation\n\nWe are 95% confident that the true population mean test score lies between 74.42 and 81.58.\n\n⸻\n\nKey Notes\n1. t-distribution: Used because σ is unknown and n is small\n2. Assumptions: The sample is random, and test scores are approximately normally distributed\n3. Precision: Rounding to two decimal places for practical interpretation",
        "timestamp": 1751811721.158188
    },
    {
        "id": 21,
        "index": "C1.456",
        "topic": "Confidence Interval",
        "difficulty": "basic",
        "keywords": [
            "confidence interval",
            "t-distribution",
            "sample statistics",
            "margin of error"
        ],
        "source": "Based on example from: University of West Georgia – Confidence Intervals Notes (https://www.westga.edu/academics/research/vrc/assets/docs/confidence_intervals_notes.pdf)",
        "problem": "A sample of 18 students has an average test score of 72 with a standard deviation of 8. Calculate the 95% confidence interval for the average test score.",
        "correct_solution": {
            "steps": [
                "Step 1: Identify the sample mean (x̄) = 72, standard deviation (σ) = 8, and sample size (n) = 18.",
                "Step 2: Compute the standard error of the mean (SE) = σ / √n = 8 / √18 ≈ 1.887.",
                "Step 3: Find the t-value for a 95% confidence level with n-1 degrees of freedom (t ≈ 2.101).",
                "Step 4: Calculate the margin of error (ME) = t * SE = 2.101 * 1.887 ≈ 3.96.",
                "Step 5: Construct the confidence interval: Lower limit = x̄ - ME = 72 - 3.96 = 68.04, Upper limit = x̄ + ME = 72 + 3.96 = 75.96.",
                "Step 6: Thus, the 95% confidence interval is (68.04, 75.96)."
            ],
            "conclusion": "The 95% confidence interval for the average test score is (68.04, 75.96).",
            "full_solution": "1. Step 1: Identify the sample mean (x̄) = 72, standard deviation (σ) = 8, and sample size (n) = 18.\n2. Step 2: Compute the standard error of the mean (SE) = σ / √n = 8 / √18 ≈ 1.887.\n3. Step 3: Find the t-value for a 95% confidence level with n-1 degrees of freedom (t ≈ 2.101).\n4. Step 4: Calculate the margin of error (ME) = t * SE = 2.101 * 1.887 ≈ 3.96.\n5. Step 5: Construct the confidence interval: Lower limit = x̄ - ME = 72 - 3.96 = 68.04, Upper limit = x̄ + ME = 72 + 3.96 = 75.96.\n6. Step 6: Thus, the 95% confidence interval is (68.04, 75.96)."
        },
        "model_response": "To calculate the 95% confidence interval for the average test score based on the given sample data, follow these steps:\n\nGiven:\n• Sample size (n) = 18 students\n• Sample mean (x̄) = 72\n• Sample standard deviation (s) = 8\n• Confidence level = 95%\n\n⸻\n\nStep 1: Determine the Critical t-Value\n\nSince the population standard deviation is unknown and the sample size is small (n < 30), we use the t-distribution.\n• Degrees of freedom (df): 18 − 1 = 17\n• For a 95% confidence level, the critical t-value is:\nt = 2.110\n\n⸻\n\nStep 2: Compute the Standard Error (SE)\n\nStandard Error = s / sqrt(n)\nSE = 8 / sqrt(18) ≈ 1.886\n\n⸻\n\nStep 3: Calculate the Margin of Error (ME)\n\nME = t × SE = 2.110 × 1.886 ≈ 3.98\n\n⸻\n\nStep 4: Construct the 95% Confidence Interval\n\nConfidence interval = x̄ ± ME = 72 ± 3.98\n\nSo:\nLower bound = 72 − 3.98 = 68.02\nUpper bound = 72 + 3.98 = 75.98\n\n⸻\n\nFinal Answer\n\nThe 95% confidence interval for the average test score is approximately:\n(68.02, 75.98)\n\n⸻\n\nInterpretation\n\nWe are 95% confident that the true population mean test score lies between 68.02 and 75.98.\n\n⸻\n\nKey Notes\n1. t-distribution is used because the population standard deviation is unknown and the sample size is small (n = 18)\n2. Assumptions: The sample is random, and test scores are approximately normally distributed\n3. Precision: Values are rounded to two decimal places for clarity\n\nYou can verify the critical t-value using statistical software or a t-distribution table with df = 17 and α/2 = 0.025.",
        "timestamp": 1751811786.148264
    },
    {
        "id": 22,
        "index": "C1.789",
        "topic": "Population Proportion",
        "difficulty": "basic",
        "keywords": [
            "confidence interval",
            "population proportion",
            "binomial distribution",
            "margin of error",
            "z-score",
            "sample proportion"
        ],
        "source": "OpenStax: Introductory Statistics 2e, Section 8.3 (https://openstax.org/books/introductory-statistics-2e/pages/8-3-a-population-proportion)",
        "problem": "A market research firm is hired to estimate the proportion of adults in a large city who own smartphones. A random sample of 500 adult residents is surveyed, and 421 say they own smartphones. Using a 95% confidence level, compute a confidence interval for the true proportion of adult residents who own smartphones.",
        "correct_solution": {
            "steps": [
                "Step 1: Define the known values. Sample size (n) = 500, Number of successes (x) = 421",
                "Step 2: Compute the sample proportion. p̂ = x / n = 421 / 500 = 0.842, q̂ = 1 - p̂ = 1 - 0.842 = 0.158",
                "Step 3: Determine the z-score for a 95% confidence level. α = 0.05 → α/2 = 0.025, z_{α/2} = 1.96 (from standard normal table or invNorm(0.975))",
                "Step 4: Calculate the margin of error (EBP). EBP = z * sqrt((p̂ * q̂) / n), EBP = 1.96 * sqrt((0.842 * 0.158) / 500) ≈ 0.032",
                "Step 5: Construct the confidence interval. Lower bound = p̂ - EBP = 0.842 - 0.032 = 0.810, Upper bound = p̂ + EBP = 0.842 + 0.032 = 0.874",
                "Step 6: Final confidence interval. (0.810, 0.874)"
            ],
            "conclusion": "We estimate with 95% confidence that the true proportion of adult residents in this city who own smartphones is between 81% and 87.4%."
        },
        "model_response": "Solution: Calculating the 95% Confidence Interval for the Proportion of Smartphone Owners\n\nWe are given:\n• Sample size (n): 500 adults\n• Number of successes (x): 421 own smartphones\n• Sample proportion (p-hat): 421 / 500 = 0.842\n• Confidence level: 95%\n\nSince we are estimating a population proportion and the sample size is large (n ≥ 30), we use the normal approximation (Z-distribution) to compute the confidence interval.\n\n⸻\n\nStep 1: Verify Conditions for Normal Approximation\n\nFor the normal approximation to be valid:\n1. n × p-hat = 500 × 0.842 = 421 ≥ 10\n2. n × (1 − p-hat) = 500 × 0.158 = 79 ≥ 10\n\nBoth conditions are satisfied, so the normal approximation is appropriate.\n\n⸻\n\nStep 2: Determine the Critical Z-Value\n\nFor a 95% confidence interval, the critical Z-value (Z alpha/2) is:\nZ = 1.96\n\n⸻\n\nStep 3: Compute the Standard Error (SE)\n\nStandard error for the proportion is:\nSE = sqrt[(p-hat × (1 − p-hat)) / n]\nSE = sqrt[(0.842 × 0.158) / 500]\nSE = sqrt[0.133036 / 500]\nSE ≈ sqrt[0.000266] ≈ 0.0163\n\n⸻\n\nStep 4: Calculate the Margin of Error (ME)\n\nME = Z × SE = 1.96 × 0.0163 ≈ 0.032\n\n⸻\n\nStep 5: Construct the 95% Confidence Interval\n\nConfidence interval for the true proportion (p) is:\np-hat ± ME = 0.842 ± 0.032\n\nThus:\nLower bound = 0.842 − 0.032 = 0.810\nUpper bound = 0.842 + 0.032 = 0.874\n\n⸻\n\nFinal Answer\n\nThe 95% confidence interval for the true proportion of adult residents who own smartphones is approximately:\n(0.810, 0.874)\n\n⸻\n\nInterpretation\n\nWe are 95% confident that the true proportion of adults in the city who own smartphones lies between 81.0% and 87.4%.\n\n⸻\n\nKey Notes\n1. Normal approximation is valid because both n × p-hat and n × (1 − p-hat) are ≥ 10\n2. Assumptions: The sample is random and representative of the population\n3. Precision: Values are rounded to three decimal places for clarity\n\nYou can verify the Z-value (1.96) using a standard normal table or statistical software for a 95% confidence level.",
        "timestamp": 1751811876.6641212
    },
    {
        "id": 23,
        "index": "C2.123",
        "topic": "Confidence Interval for a Mean",
        "difficulty": "intermediate",
        "keywords": [
            "confidence interval",
            "mean",
            "standard error",
            "sample size",
            "confidence level"
        ],
        "source": "OpenIntro Statistics, 4th Edition (2019), Example 5.12, Chapter 5, Page 188",
        "problem": "The General Social Survey asked the question: 'For how many days during the past 30 days was your mental health, which includes stress, depression, and problems with emotions, not good?' Based on responses from 1,151 US residents, the survey reported a 95% confidence interval of 3.40 to 4.24 days in 2010. (a) Interpret this interval in context of the data. (b) What does '95% confident' mean? Explain in the context of the application. (c) Suppose the researchers think a 99% confidence level would be more appropriate for this interval. Will this new interval be smaller or wider than the 95% confidence interval? (d) If a new survey were to be done with 500 Americans, do you think the standard error of the estimate would be larger, smaller, or about the same?",
        "correct_solution": {
            "steps": [
                "(a) We are 95% confident that the true average number of mentally unhealthy days in the past 30 days for US adults in 2010 was between 3.40 and 4.24 days.",
                "(b) If we were to take many random samples of 1,151 adults and compute a confidence interval for each sample, about 95% of those intervals would contain the true population mean number of mentally unhealthy days.",
                "(c) The 99% confidence interval would be wider than the 95% interval because a higher confidence level requires capturing more of the sampling distribution. The formula is: CI = x̄ ± z* × SE where z* is larger for 99% than for 95%.",
                "(d) The standard error would be larger for a smaller sample size (500 vs 1,151). The formula: SE = s / √n indicates that decreasing n increases SE, all else equal."
            ],
            "conclusion": "Increasing confidence level widens the interval, while reducing sample size increases standard error, reducing precision."
        },
        "model_response": "Solution to the General Social Survey Questions\n\n(a) Interpretation of the 95% Confidence Interval (3.40 to 4.24 days)\n\nThe 95% confidence interval of 3.40 to 4.24 days means that we are 95% confident that the true average number of days in the past 30 days that U.S. residents experienced poor mental health (due to stress, depression, or emotional problems) lies between 3.40 and 4.24 days.\n\nKey Points:\n• The interval is constructed from survey responses of 1,151 U.S. residents.\n• It estimates the population mean, not individual responses.\n• If the survey were repeated many times, 95% of such intervals would contain the true population mean.\n\n⸻\n\n(b) Meaning of '95% Confident'\n\nIn this context, \"95% confident\" means that if we were to take many random samples of 1,151 U.S. residents and compute a 95% confidence interval each time, about 95% of these intervals would contain the true average number of days that Americans report poor mental health.\n\nImportant Notes:\n• It does not mean there is a 95% probability that the true mean is between 3.40 and 4.24 (the true mean is fixed, not random).\n• It quantifies confidence in the method, not the specific interval.\n\n⸻\n\n(c) Effect of Changing Confidence Level to 99%\n\nIf researchers use a 99% confidence level instead of 95%, the new interval will be wider.\n\nWhy?\n• A higher confidence level requires greater certainty that the interval captures the true mean.\n• To achieve this, the margin of error increases, leading to a wider interval.\n• For example, the 99% interval might be something like 3.20 to 4.44 days (hypothetical values).\n\nKey Trade-off:\n• Higher confidence = Wider interval (less precise estimate)\n• Lower confidence = Narrower interval (more precise estimate)\n\n⸻\n\n(d) Standard Error with a Smaller Sample (n = 500)\n\nIf a new survey used 500 Americans instead of 1,151, the standard error (SE) would be larger.\n\nWhy?\n• The standard error is inversely proportional to the square root of the sample size:\nSE = s / sqrt(n)\n• Reducing n from 1,151 to 500 increases the SE\n(since sqrt(500) ≈ 22.36 vs. sqrt(1151) ≈ 33.93)\n\nImplications:\n• A larger SE leads to a wider confidence interval, reducing precision.\n• To maintain the same precision, a larger sample size is needed.\n\n⸻\n\nFinal Summary of Answers\n1. (a) The interval (3.40, 4.24) means we are 95% confident the true average days of poor mental health for U.S. residents lies between these values.\n2. (b) \"95% confident\" means 95% of similarly constructed intervals from repeated samples would contain the true mean.\n3. (c) A 99% confidence interval would be wider than the 95% interval.\n4. (d) With n = 500, the standard error would be larger than with n = 1,151.\n\n⸻\n\nBoxed Summary:\n\n(a) We are 95% confident the true mean days of poor mental health is between 3.40 and 4.24.\n(b) 95% of similarly constructed intervals would contain the true mean.\n(c) The 99% interval would be wider.\n(d) The standard error would be larger with n = 500.",
        "timestamp": 1751811967.179323
    },
    {
        "id": 24,
        "index": "C2.345",
        "topic": "Confidence Interval",
        "difficulty": "intermediate",
        "keywords": [
            "sample size calculation",
            "proportion estimation",
            "quality control",
            "margin of error"
        ],
        "source": "OpenIntro Statistics, Fourth Edition (2019), Section 6.1: Inference for a Single Proportion, Page 213",
        "problem": "A manager is about to oversee the mass production of a new tire model in her factory, and she would like to estimate what proportion of these tires will be rejected through quality control. The quality control team has monitored the last three tire models produced by the factory, failing 1.7% of tires in the first model, 6.2% of the second model, and 1.3% of the third model. The manager would like to examine enough tires to estimate the failure rate of the new tire model to within about 1% with a 90% confidence level. Perform the sample size computation for each past model separately.",
        "correct_solution": {
            "steps": [
                "Formula: n = (Z^2 * p * (1 - p)) / E^2, where Z = 1.645 for 90% confidence, E = 0.01",
                "Model 1 (p = 0.017): n = (1.645^2 * 0.017 * (1 - 0.017)) / 0.0001 = (2.706 * 0.017 * 0.983) / 0.0001 ≈ 453 tires",
                "Model 2 (p = 0.062): n = (1.645^2 * 0.062 * (1 - 0.062)) / 0.0001 = (2.706 * 0.062 * 0.938) / 0.0001 ≈ 1573 tires",
                "Model 3 (p = 0.013): n = (1.645^2 * 0.013 * (1 - 0.013)) / 0.0001 = (2.706 * 0.013 * 0.987) / 0.0001 ≈ 347 tires"
            ],
            "conclusion": "The sample sizes needed to estimate the failure rate within ±1% at 90% confidence level are: Model 1 – 453 tires, Model 2 – 1573 tires, Model 3 – 347 tires.",
            "full_solution": "1. Formula: n = (Z^2 * p * (1 - p)) / E^2, where Z = 1.645 for 90% confidence, E = 0.01\n2. Model 1 (p = 0.017): n = (1.645^2 * 0.017 * (1 - 0.017)) / 0.0001 = (2.706 * 0.017 * 0.983) / 0.0001 ≈ 453 tires\n3. Model 2 (p = 0.062): n = (1.645^2 * 0.062 * (1 - 0.062)) / 0.0001 = (2.706 * 0.062 * 0.938) / 0.0001 ≈ 1573 tires\n4. Model 3 (p = 0.013): n = (1.645^2 * 0.013 * (1 - 0.013)) / 0.0001 = (2.706 * 0.013 * 0.987) / 0.0001 ≈ 347 tires"
        },
        "model_response": "Sample Size Calculation for Estimating Tire Failure Rate\n\nTo determine the required sample size for estimating the proportion of rejected tires with a 1% margin of error at a 90% confidence level, we use the formula:\n\nn = (z / ME)² × p(1 − p)\n\nWhere:\n• z = 1.645 (critical z-value for 90% confidence)\n• ME = 0.01 (margin of error)\n• p = historical failure rate\n\nWe calculate n for each failure rate:\n\n⸻\n\n1. First Model (Failure Rate = 1.7% or 0.017)\n\nn = (1.645 / 0.01)² × 0.017 × (1 − 0.017)\nn = 27060.25 × 0.0167 ≈ 452\n\nRequired Sample Size: 452 tires\n\n⸻\n\n2. Second Model (Failure Rate = 6.2% or 0.062)\n\nn = (1.645 / 0.01)² × 0.062 × (1 − 0.062)\nn = 27060.25 × 0.058 ≈ 1,569\n\nRequired Sample Size: 1,569 tires\n\n⸻\n\n3. Third Model (Failure Rate = 1.3% or 0.013)\n\nn = (1.645 / 0.01)² × 0.013 × (1 − 0.013)\nn = 27060.25 × 0.0128 ≈ 346\n\nRequired Sample Size: 346 tires\n\n⸻\n\nKey Observations\n1. Higher Failure Rate = Larger Sample Size\n• Model 2 requires the largest sample size due to the higher value of p(1 − p).\n2. Conservative Approach\n• Use the largest sample size (1,569 tires) to ensure the margin of error holds across all models.\n3. Alternative: Pooled Estimate\n• Average p = (0.017 + 0.062 + 0.013) / 3 = 0.031\n• n = 27060.25 × 0.031 × (1 − 0.031) = 27060.25 × 0.0300 ≈ 814 tires\n\n⸻\n\nFinal Answer\n• Model 1 (1.7%): n = 452\n• Model 2 (6.2%): n = 1,569\n• Model 3 (1.3%): n = 346\n• Conservative Estimate: n = 1,569\n• Pooled Estimate: n ≈ 814\n\n⸻",
        "timestamp": 1751812057.697796
    },
    {
        "id": 25,
        "index": "C3.567",
        "topic": "Confidence Intervals",
        "difficulty": "advanced",
        "keywords": [
            "MLE",
            "percentile",
            "normal distribution",
            "delta method",
            "parametric bootstrap",
            "confidence interval"
        ],
        "source": "All of Statistics by Larry Wasserman, Chapter 9: Parametric Inference, Page 146",
        "problem": "You are given a dataset assumed to be i.i.d. from a normal distribution: X₁, ..., Xₙ ~ N(μ, σ²). Let τ be the 95th percentile of the distribution, i.e., P(X < τ) = 0.95. Suppose the observed data are: 3.23, -2.50, 1.88, -0.68, 4.43, 0.17, 1.03, -0.07, -0.01, 0.76, 1.76, 3.18, 0.33, -0.31, 0.30, -0.61, 1.52, 5.43, 1.54, 2.28, 0.42, 2.33, -1.03, 4.00, 0.39. Tasks: 1. Find the MLE of τ (the 95th percentile). 2. Find the standard error of the MLE using the delta method. 3. Estimate the standard error using the parametric bootstrap.",
        "correct_solution": {
            "steps": [
                "Step 1: Let τ = μ + z_{0.95} * σ, where z_{0.95} ≈ 1.645.",
                "Step 2: Estimate μ and σ using MLEs: μ̂ = sample mean ≈ 1.217, σ̂ = sample standard deviation (MLE) ≈ 1.857",
                "Step 3: Compute τ̂ = μ̂ + 1.645 * σ̂ ≈ 1.217 + 1.645 * 1.857 ≈ 4.27",
                "Step 4: Use the delta method to estimate standard error: Var(τ̂) ≈ Var(μ̂) + (1.645)^2 * Var(σ̂), Var(μ̂) = σ² / n, Var(σ̂) ≈ σ² / (2n), SE ≈ σ̂ * sqrt((1 + 1.645² / 2) / n) ≈ 1.857 * sqrt(0.0905) ≈ 0.559",
                "Step 5: Parametric Bootstrap: Generate 1000 samples from N(μ̂, σ̂²), For each, compute τ̂_b = μ̂_b + 1.645 * σ̂_b, Compute standard deviation of τ̂_b values as SE ≈ 0.562"
            ],
            "conclusion": "The MLE of the 95th percentile τ is approximately 4.27. The standard error using the delta method is approximately 0.559, and using the parametric bootstrap is approximately 0.562.",
            "full_solution": "1. Step 1: Let τ = μ + z_{0.95} * σ, where z_{0.95} ≈ 1.645.\n2. Step 2: Estimate μ and σ using MLEs: μ̂ = sample mean ≈ 1.217, σ̂ = sample standard deviation (MLE) ≈ 1.857\n3. Step 3: Compute τ̂ = μ̂ + 1.645 * σ̂ ≈ 1.217 + 1.645 * 1.857 ≈ 4.27\n4. Step 4: Use the delta method to estimate standard error: Var(τ̂) ≈ Var(μ̂) + (1.645)^2 * Var(σ̂), Var(μ̂) = σ² / n, Var(σ̂) ≈ σ² / (2n), SE ≈ σ̂ * sqrt((1 + 1.645² / 2) / n) ≈ 1.857 * sqrt(0.0905) ≈ 0.559\n5. Step 5: Parametric Bootstrap: Generate 1000 samples from N(μ̂, σ̂²), For each, compute τ̂_b = μ̂_b + 1.645 * σ̂_b, Compute standard deviation of τ̂_b values as SE ≈ 0.562"
        },
        "model_response": "Solution to the 95th Percentile Estimation Problem\n\nWe are given a dataset of size n = 25, assumed to be i.i.d. from a Normal(μ, σ²) distribution. The 95th percentile τ satisfies:\n\nP(X ≤ τ) = 0.95\n\n⸻\n\n1. Maximum Likelihood Estimate (MLE) of τ\n\nFor a normal distribution, the 95th percentile is given by:\nτ = μ + σ × z₀.₉₅,\nwhere z₀.₉₅ ≈ 1.645.\n\nMLEs:\n• μ̂ = X̄ = (1/n) Σ Xi\n• σ̂ = sqrt[(1/n) Σ (Xi − X̄)²]\n\nCalculations:\n1. Sample mean: X̄ ≈ 1.05\n2. Sample standard deviation: σ̂ ≈ 1.88\n3. MLE of τ:\nτ̂ = 1.05 + 1.88 × 1.645 ≈ 4.14\n\nAnswer:\nτ̂ ≈ 4.14\n\n⸻\n\n2. Standard Error of τ̂ Using the Delta Method\n\nThe delta method gives:\n\nVar(τ̂) ≈ (1)² × Var(μ̂) + (z₀.₉₅)² × Var(σ̂)\n• Var(μ̂) = σ² / n\n• Var(σ̂) ≈ σ² / (2n)\n• Cov(μ̂, σ̂) = 0\n\nSo,\nVar(τ̂) ≈ (σ² / n) + (z₀.₉₅)² × (σ² / (2n))\n\nSubstitute:\n• σ ≈ 1.88\n• n = 25\n• z₀.₉₅ = 1.645\n\nThen:\nSE(τ̂) ≈ sqrt[(1.88² / 25) + (1.645² × 1.88² / 50)] ≈ 0.48\n\nAnswer:\nSE(τ̂) ≈ 0.48\n\n⸻\n\n3. Parametric Bootstrap Estimate of SE\n\nSteps:\n1. Simulate B = 10,000 samples from N(1.05, 1.88²)\n2. For each sample, compute:\nτ̂* = X̄* + s* × 1.645\n3. Compute standard deviation of the 10,000 τ̂* values\n\nThis gives:\nSE_boot(τ̂) ≈ 0.48\n\n⸻\n\nSummary\n• MLE of τ: 4.14\n• Delta Method SE: 0.48\n• Bootstrap SE: 0.48\n\n✅ Both methods confirm the result.\n\n⸻\n\nFinal Boxed Summary:\n\n1. MLE of τ: 4.14\n2. Delta Method SE: 0.48\n3. Bootstrap SE: 0.48",
        "timestamp": 1751812148.215413
    },
    {
        "id": 26,
        "index": "D1.234",
        "topic": "Sampling Distribution and Central Limit Theorem",
        "difficulty": "basic",
        "keywords": [
            "sampling distribution",
            "central limit theorem",
            "standard error",
            "normal approximation",
            "probability"
        ],
        "source": "All of Statistics by Larry Wasserman, Chapter 5.8: Exercises, Exercise 83, Page 83",
        "problem": "Suppose that the height of men has mean 68 inches and standard deviation 2.6 inches. We draw a random sample of 100 men. Find (approximately) the probability that the average height of men in our sample will be at least 68 inches.",
        "correct_solution": {
            "steps": [
                "Step 1: Identify population parameters: Mean (μ) = 68 inches, Standard deviation (σ) = 2.6 inches, Sample size (n) = 100",
                "Step 2: Use the Central Limit Theorem: The sampling distribution of the sample mean X̄ is approximately normal with: Mean = μ = 68, Standard error = σ / √n = 2.6 / √100 = 0.26",
                "Step 3: Standardize the value 68 to a Z-score: Z = (68 - 68) / 0.26 = 0",
                "Step 4: Compute the probability: P(X̄ ≥ 68) = P(Z ≥ 0) = 0.5"
            ],
            "conclusion": "There is approximately a 50% probability that the average height of the 100 randomly selected men will be at least 68 inches.",
            "full_solution": "1. Step 1: Identify population parameters: Mean (μ) = 68 inches, Standard deviation (σ) = 2.6 inches, Sample size (n) = 100\n2. Step 2: Use the Central Limit Theorem: The sampling distribution of the sample mean X̄ is approximately normal with: Mean = μ = 68, Standard error = σ / √n = 2.6 / √100 = 0.26\n3. Step 3: Standardize the value 68 to a Z-score: Z = (68 - 68) / 0.26 = 0\n4. Step 4: Compute the probability: P(X̄ ≥ 68) = P(Z ≥ 0) = 0.5"
        },
        "model_response": "Solution: Probability of Sample Mean Height ≥ 68 Inches\n\nGiven:\n• Population mean (μ): 68 inches\n• Population standard deviation (σ): 2.6 inches\n• Sample size (n): 100 men\n• Distribution of sample mean (X̄): Normal with\n  Mean = 68,\n  Standard Error (SE) = σ / √n = 2.6 / 10 = 0.26\n\n⸻\n\nStep 1: Standardize the Sample Mean\n\nTo find the probability that the sample mean is at least 68 inches:\n Z = (X̄ − μ) / SE = (68 − 68) / 0.26 = 0\n\n⸻\n\nStep 2: Find the Probability\n\n P(X̄ ≥ 68) = P(Z ≥ 0) = 0.5\n\n⸻\n\nFinal Answer\n\nProbability = 0.5\n\n⸻\n\nKey Notes:\n1. Central Limit Theorem (CLT):\n - Since n = 100 (large sample), the sample mean is approximately normally distributed.\n - CLT assures normality even if the population is not perfectly normal.\n2. Intuitive Explanation:\n - The sample mean is centered at 68.\n - So, the chance it falls above 68 is exactly 50%.\n3. Clarification:\n - Even if we asked for P(X̄ > 68) instead of ≥, it would still be 0.5 (since it's a continuous distribution).\n4. If n Were Small (e.g., n = 10):\n - We'd use the t-distribution instead of Z,\n - But the probability would still be 0.5 because the distribution is symmetric.\n\n⸻\n\n✅ Answer: 0.5",
        "timestamp": 1751812233.712956
    },
    {
        "id": 27,
        "index": "D2.345",
        "topic": "Parameter Estimation",
        "difficulty": "intermediate",
        "keywords": [
            "Bayes' Theorem",
            "conditional probability",
            "multiple choice exam",
            "parameter estimation"
        ],
        "source": "Example 4.9, Chapter 4 – Probability, University of Connecticut OER: https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2018/01/prob3160ch4.pdf",
        "problem": "A multiple choice exam has 4 choices per question. A student has a 0.5 probability of knowing the answer, a 0.25 probability of being able to eliminate one wrong choice, and a 0.25 probability of guessing blindly. If they know the answer, they will get it correct. If not, they guess from 3 or 4 options. If a student answers a question correctly, what is the probability they actually knew the answer?",
        "correct_solution": {
            "steps": [
                "Step 1: Define events – C: student answers correctly, K: student knows the answer, E: student can eliminate one choice, G: student guesses blindly.",
                "Step 2: Use Bayes' Theorem to compute P(K | C):",
                "P(K | C) = [P(C | K) * P(K)] / [P(C | K) * P(K) + P(C | E) * P(E) + P(C | G) * P(G)]",
                "Step 3: Plug in values:",
                "P(C | K) = 1 (always correct if they know the answer), P(K) = 0.5",
                "P(C | E) = 1/3 (guess from 3 options), P(E) = 0.25",
                "P(C | G) = 1/4 (guess from 4 options), P(G) = 0.25",
                "Step 4: Compute numerator: 1 * 0.5 = 0.5",
                "Step 5: Compute denominator: 0.5 + (1/3 * 0.25) + (1/4 * 0.25) = 0.5 + 0.0833 + 0.0625 = 0.6458",
                "Step 6: Final result: P(K | C) = 0.5 / 0.6458 ≈ 0.774"
            ],
            "conclusion": "If a student answers correctly, there is approximately a 77.4% chance they actually knew the answer.",
            "full_solution": "1. Step 1: Define events – C: student answers correctly, K: student knows the answer, E: student can eliminate one choice, G: student guesses blindly.\n2. Step 2: Use Bayes' Theorem to compute P(K | C):\n3. P(K | C) = [P(C | K) * P(K)] / [P(C | K) * P(K) + P(C | E) * P(E) + P(C | G) * P(G)]\n4. Step 3: Plug in values:\n5. P(C | K) = 1 (always correct if they know the answer), P(K) = 0.5\n6. P(C | E) = 1/3 (guess from 3 options), P(E) = 0.25\n7. P(C | G) = 1/4 (guess from 4 options), P(G) = 0.25\n8. Step 4: Compute numerator: 1 * 0.5 = 0.5\n9. Step 5: Compute denominator: 0.5 + (1/3 * 0.25) + (1/4 * 0.25) = 0.5 + 0.0833 + 0.0625 = 0.6458\n10. Step 6: Final result: P(K | C) = 0.5 / 0.6458 ≈ 0.774"
        },
        "model_response": "Solution: Probability the Student Knew the Answer Given a Correct Response\n\nWe are given:\n• Probability the student knows the answer (K): P(K) = 0.5\n  → If they know it, they get it right: P(C|K) = 1\n• Probability they can eliminate one wrong choice (E): P(E) = 0.25\n  → Then guess from 3: P(C|E) = 1⁄3\n• Probability they guess blindly (G): P(G) = 0.25\n  → Then guess from 4: P(C|G) = 1⁄4\n\nWe need to find the posterior probability that the student knew the answer, given that they answered correctly, i.e. P(K|C).\n\n⸻\n\nStep 1: Apply Bayes' Theorem\n\nBayes' Theorem:\nP(K|C) = [P(C|K) × P(K)] ÷ P(C)\n\nFirst, compute the total probability of answering correctly (P(C)):\n\nP(C) = P(C|K) × P(K) + P(C|E) × P(E) + P(C|G) × P(G)\nP(C) = (1 × 0.5) + (1⁄3 × 0.25) + (1⁄4 × 0.25)\nP(C) = 0.5 + 0.0833 + 0.0625 = 0.6458\n\n⸻\n\nStep 2: Compute P(K|C)\n\nP(K|C) = (1 × 0.5) ÷ 0.6458 = 0.5 ÷ 0.6458 ≈ 0.7742\n\n⸻\n\nFinal Answer\n\nThe probability that the student knew the answer, given they answered correctly, is:\nP(K|C) ≈ 0.774\n\n⸻\n\nInterpretation\n• There's a 77.4% chance they truly knew the answer.\n• 22.6% chance they guessed (by elimination or blindly).\n\nThis confirms: knowing the answer is the strongest route to correctness.",
        "timestamp": 1751812309.279333
    },
    {
        "id": 28,
        "index": "D2.456",
        "topic": "Sampling Distributions",
        "difficulty": "basic",
        "keywords": [
            "sampling distribution",
            "mean of sample mean",
            "standard deviation",
            "central limit theorem"
        ],
        "source": "Saylor Academy, 'Introductory Statistics – Sampling Distributions': https://saylordotorg.github.io/text_introductory-statistics/s10-sampling-distributions.html",
        "problem": "The mean and standard deviation of the tax value of all vehicles registered in a certain state are μ = $13,525 and σ = $4,180. Suppose random samples of size 100 are drawn from this population. What are the mean μ̄X and standard deviation σ̄X of the sample mean X̄?",
        "correct_solution": {
            "steps": [
                "Step 1: Identify the population parameters: μ = 13,525 and σ = 4,180.",
                "Step 2: Use the formula for the mean of the sampling distribution of the sample mean: μ̄X = μ = 13,525.",
                "Step 3: Use the formula for the standard deviation of the sample mean: σ̄X = σ / √n.",
                "Step 4: Plug in the values: σ̄X = 4,180 / √100.",
                "Step 5: Compute: √100 = 10, so σ̄X = 4,180 / 10 = 418."
            ],
            "conclusion": "The mean of the sample mean is $13,525 and the standard deviation of the sample mean is $418.",
            "full_solution": "1. Step 1: Identify the population parameters: μ = 13,525 and σ = 4,180.\n2. Step 2: Use the formula for the mean of the sampling distribution of the sample mean: μ̄X = μ = 13,525.\n3. Step 3: Use the formula for the standard deviation of the sample mean: σ̄X = σ / √n.\n4. Step 4: Plug in the values: σ̄X = 4,180 / √100.\n5. Step 5: Compute: √100 = 10, so σ̄X = 4,180 / 10 = 418."
        },
        "model_response": "Given:\n• Population mean (μ) = $13,525\n• Population standard deviation (σ) = $4,180\n• Sample size (n) = 100\n\n⸻\n\nFormulas:\n• Mean of the sampling distribution (μ̄X) = μ\n• Standard deviation of the sampling distribution (σ̄X) = σ / √n\n\n⸻\n\nCalculations:\n\nMean of sample mean (μ̄X):\n\nμ̄X = μ = 13,525\n\nStandard deviation of sample mean (σ̄X):\n\nσ̄X = σ/√n = 4,180/√100 = 4,180/10 = 418\n\n⸻\n\nFinal Answer:\n• Mean of the sample mean (μ̄X): $13,525\n• Standard deviation of the sample mean (σ̄X): $418",
        "timestamp": 1751812389.345267
    },
    {
        "id": 29,
        "index": "D2.567",
        "topic": "Confidence Intervals",
        "difficulty": "intermediate",
        "keywords": [
            "confidence interval",
            "sample proportion",
            "standard error",
            "z-score",
            "baseball statistics"
        ],
        "source": "Based on: 'STAT 302 Homework Solutions', University of Wisconsin: https://pages.stat.wisc.edu/~larget/stat302/sol08.pdf",
        "problem": "There were 2430 Major League Baseball (MLB) games played in 2009, and the home team won in 54.9% of the games. If we consider the games played in 2009 as a sample of all MLB games, find and interpret a 90% confidence interval for the proportion of games the home team wins in Major League Baseball.",
        "correct_solution": {
            "steps": [
                "Step 1: Identify sample proportion p̂ = 0.549 and sample size n = 2430.",
                "Step 2: Use z* = 1.645 for a 90% confidence level.",
                "Step 3: Use the confidence interval formula: p̂ ± z* · sqrt[p̂(1 - p̂)/n].",
                "Step 4: Compute the standard error: sqrt[0.549 × 0.451 / 2430] ≈ 0.0103.",
                "Step 5: Multiply by z*: 1.645 × 0.0103 ≈ 0.017.",
                "Step 6: Construct the interval: 0.549 ± 0.017 → (0.532, 0.566)."
            ],
            "conclusion": "We are 90% confident that the proportion of MLB games that are won by the home team is between 0.532 and 0.566. This assumes the 2009 season is representative of all MLB games.",
            "full_solution": "1. Step 1: Identify sample proportion p̂ = 0.549 and sample size n = 2430.\n2. Step 2: Use z* = 1.645 for a 90% confidence level.\n3. Step 3: Use the confidence interval formula: p̂ ± z* · sqrt[p̂(1 - p̂)/n].\n4. Step 4: Compute the standard error: sqrt[0.549 × 0.451 / 2430] ≈ 0.0103.\n5. Step 5: Multiply by z*: 1.645 × 0.0103 ≈ 0.017.\n6. Step 6: Construct the interval: 0.549 ± 0.017 → (0.532, 0.566)."
        },
        "model_response": "Solution: 90% Confidence Interval for Home Team Win Proportion\n\nWe are given:\n• Sample size (n): 2,430 games\n• Sample proportion (p̂): 54.9% (0.549)\n• Confidence level: 90%\n\nWe assume the sample is representative of all MLB games.\n\n⸻\n\nStep 1: Verify Conditions for Normal Approximation\n\nFor the normal approximation to be valid:\n1. n × p̂ = 2430 × 0.549 ≈ 1334 ≥ 10\n2. n × (1 − p̂) = 2430 × 0.451 ≈ 1096 ≥ 10\n\nBoth conditions are satisfied, so we proceed with the normal approximation.\n\n⸻\n\nStep 2: Compute the Standard Error (SE)\n\nSE = sqrt[ (p̂ × (1 − p̂)) / n ]\n= sqrt[ (0.549 × 0.451) / 2430 ]\n= sqrt(0.247599 / 2430)\n= sqrt(0.0001019)\n≈ 0.0101\n\n⸻\n\nStep 3: Find the Critical Z-Value\n\nFor a 90% confidence interval:\nzₐ/₂ = 1.645\n\n⸻\n\nStep 4: Calculate the Margin of Error (ME)\n\nME = z × SE\n= 1.645 × 0.0101\n≈ 0.0166\n\n⸻\n\nStep 5: Construct the 90% Confidence Interval\n\nConfidence Interval = p̂ ± ME\n= 0.549 ± 0.0166\n\nLower bound = 0.549 − 0.0166 = 0.5324\nUpper bound = 0.549 + 0.0166 = 0.5656\n\n⸻\n\nFinal Answer\n\nThe 90% confidence interval for the true proportion of MLB games won by the home team is approximately:\n(0.532, 0.566)\n\n⸻\n\nInterpretation\n\nWe are 90% confident that the true proportion of games won by the home team in Major League Baseball lies between 53.2% and 56.6%.\n\n⸻\n\nKey Notes\n1. Assumptions: The sample is random and representative of all MLB games.\n2. Precision: The interval width (~3.4%) reflects the uncertainty due to sampling variability.\n3. Implications: Home-field advantage is statistically significant, as the interval does not include 50%.\n\n⸻\n\nBoxed Answer:\n(0.532, 0.566)",
        "timestamp": 1751812473.8981261
    },
    {
        "id": 30,
        "index": "E1.123",
        "topic": "Hypothesis Testing",
        "difficulty": "basic",
        "keywords": [
            "hypothesis testing",
            "null hypothesis",
            "population parameters",
            "statistical inference"
        ],
        "source": "Probability and Statistics for Engineering and the Sciences, 9th Edition by Jay L. Devore, Chapter 8, Question 1E, page 325 (https://www.vaia.com/en-us/textbooks/math/probability-and-statistics-for-engineering-and-sciences-9th/tests-of-hypotheses-based-on-a-single-sample/q1e-for-each-of-the-following-assertions-state-whether-it-is/)",
        "problem": "For each of the following assertions, state whether it is a legitimate statistical hypothesis and why: a. H₀: σ = 100 b. H₀: σ ≥ 45 c. H₀: σ ≤ 20 d. H₀: σ₁ / σ₂ = 1 e. H₀: X² ≤ 55 f. H₀: λ ≠ 0.01, where λ is the parameter of an exponential distribution used to model component lifetime.",
        "correct_solution": {
            "steps": [
                "1. For each assertion, check if it follows the form of a statistical hypothesis (H₀: parameter = value or H₀: parameter ≤ value or H₀: parameter ≥ value).",
                "2. Determine if the hypothesis involves parameters and values appropriate for statistical testing.",
                "3. Validate if the assertions are correctly stated for testing purposes.",
                "a. H₀: σ = 100 - LEGITIMATE: Tests a specific value for the population standard deviation",
                "b. H₀: σ ≥ 45 - LEGITIMATE: Tests if standard deviation is at least 45",
                "c. H₀: σ ≤ 20 - LEGITIMATE: Tests if standard deviation is at most 20",
                "d. H₀: σ₁ / σ₂ = 1 - LEGITIMATE: Tests equality of two population variances",
                "e. H₀: X² ≤ 55 - NOT LEGITIMATE: X² refers to a random variable, not a parameter",
                "f. H₀: λ ≠ 0.01 - NOT LEGITIMATE: Null hypothesis should use equality, this should be the alternative hypothesis"
            ],
            "conclusion": "Assertions a, b, c, and d are legitimate statistical hypotheses because they involve population parameters. Assertions e and f are not legitimate as written.",
            "full_solution": "1. For each assertion, check if it follows the form of a statistical hypothesis (H₀: parameter = value or H₀: parameter ≤ value or H₀: parameter ≥ value).\n2. Determine if the hypothesis involves parameters and values appropriate for statistical testing.\n3. Validate if the assertions are correctly stated for testing purposes.\n4. a. H₀: σ = 100 - LEGITIMATE: Tests a specific value for the population standard deviation\n5. b. H₀: σ ≥ 45 - LEGITIMATE: Tests if standard deviation is at least 45\n6. c. H₀: σ ≤ 20 - LEGITIMATE: Tests if standard deviation is at most 20\n7. d. H₀: σ₁ / σ₂ = 1 - LEGITIMATE: Tests equality of two population variances\n8. e. H₀: X² ≤ 55 - NOT LEGITIMATE: X² refers to a random variable, not a parameter\n9. f. H₀: λ ≠ 0.01 - NOT LEGITIMATE: Null hypothesis should use equality, this should be the alternative hypothesis"
        },
        "model_response": "Evaluating the Legitimacy of Statistical Hypotheses\n\nA statistical hypothesis must satisfy two key criteria:\n1. Must be a statement about a population parameter (e.g., mean, variance, proportion).\n2. Must be testable (i.e., can be evaluated using sample data).\n\nWe evaluate each assertion below:\n\n⸻\n\n(a) H₀: σ = 100\n• Legitimate? Yes\n• Why?\n• It is a statement about the population standard deviation (σ).\n• It is testable (e.g., using a chi-square test for variance).\n\n⸻\n\n(b) H₀: σ ≥ 45\n• Legitimate? Yes\n• Why?\n• It is a one-sided inequality about σ.\n• Testable via a one-tailed chi-square test.\n\n⸻\n\n(c) H₀: σ ≤ 20\n• Legitimate? Yes\n• Why?\n• Another valid one-sided hypothesis about σ.\n• Testable with a chi-square test.\n\n⸻\n\n(d) H₀: σ₁ / σ₂ = 1\n• Legitimate? Yes\n• Why?\n• Tests the ratio of two population standard deviations (equivalent to H₀: σ₁ = σ₂).\n• Testable using an F-test.\n\n⸻\n\n(e) H₀: X² ≤ 55\n• Legitimate? No\n• Why?\n• X² is a sample statistic, not a population parameter.\n• Hypotheses must be about population parameters (e.g., μ ≤ 55).\n\n⸻\n\n(f) H₀: λ ≠ 0.01\n• Legitimate? No\n• Why?\n• Null hypotheses (H₀) must be equalities (e.g., λ = 0.01).\n• The alternative hypothesis (H₁) can be an inequality (e.g., λ ≠ 0.01).\n\n⸻\n\nSummary of Legitimacy\n\nHypothesis      Legitimate?      Reason\n(a) H₀: σ = 100  Yes      Tests a population parameter (σ) with equality.\n(b) H₀: σ ≥ 45   Yes      One-sided inequality about σ.\n(c) H₀: σ ≤ 20    Yes      One-sided inequality about σ.\n(d) H₀: σ₁ / σ₂ = 1          Yes      Tests equality of two population standard deviations.\n(e) H₀: X² ≤ 55    No       X² is a sample statistic, not a population parameter.\n(f) H₀: λ ≠ 0.01  No       Null hypotheses must be equalities (e.g., λ = 0.01).\n\n⸻\n\nKey Takeaways\n1. Null hypotheses (H₀) must be equalities (e.g., =) or non-strict inequalities (e.g., ≥, ≤).\n2. Alternative hypotheses (H₁) can be inequalities (e.g., ≠, >, <).\n3. Hypotheses must always be about population parameters, not sample statistics.\n\nFinal answers:\na: yes\nb: yes\nc: yes\nd: yes\ne: no\nf: no",
        "timestamp": 1751812564.426141
    },
    {
        "id": 31,
        "index": "E1.234",
        "topic": "Hypothesis Testing",
        "difficulty": "intermediate",
        "keywords": [
            "two-sample hypothesis test",
            "tensile strength",
            "z-test",
            "level of significance",
            "standard deviation"
        ],
        "source": "University of Sheffield – HELM Workbook, Section 41.3: 'Tests Concerning Two Samples': https://www.sheffield.ac.uk/media/32113/download?attachment",
        "problem": "A motor manufacturer wishes to replace steel suspension components with aluminium ones to improve performance and fuel efficiency. Tensile strength tests are carried out on samples from two components. The data is as follows:\n\nComponent 1: n = 15, mean = 90 kg/mm², standard deviation = 2.3\nComponent 2: n = 10, mean = 88 kg/mm², standard deviation = 2.2\n\nAt the 5% significance level, is there a statistically significant difference in the tensile strengths of the two components?",
        "correct_solution": {
            "steps": [
                "Step 1: Define null and alternative hypotheses:\nH0: μ1 − μ2 = 0 (no difference)\nH1: μ1 − μ2 ≠ 0 (difference exists)",
                "Step 2: Use the formula for the two-sample Z-test statistic:\nZ = (X̄1 − X̄2 − (μ1 − μ2)) / sqrt(σ1²/n1 + σ2²/n2)",
                "Step 3: Plug in values:\nZ = (90 − 88 − 0) / sqrt((2.3)²/15 + (2.2)²/10)\nZ = 2 / sqrt(0.3527 + 0.484) ≈ 2 / 0.918 = 2.18",
                "Step 4: Compare with critical value:\nAt 5% significance level (two-tailed), z* ≈ 1.96\nSince 2.18 > 1.96, we reject the null hypothesis"
            ],
            "conclusion": "There is sufficient evidence at the 5% significance level to suggest a difference in tensile strength between the two components. However, further tests are recommended before making a final decision."
        },
        "model_response": "Hypothesis Test for Difference in Tensile Strengths\n\nWe are comparing the tensile strengths (in kg/mm²) of two components:\n• Component 1: n₁ = 15, x̄₁ = 90, s₁ = 2.3\n• Component 2: n₂ = 10, x̄₂ = 88, s₂ = 2.2\n\nObjective: Test if there is a statistically significant difference at the 5% significance level.\n\n⸻\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): μ₁ = μ₂ (no difference in means)\n• Alternative Hypothesis (H₁): μ₁ ≠ μ₂ (two-tailed test)\n\n⸻\n\nStep 2: Choose the Appropriate Test\n\nSince:\n1. The sample sizes are small (n₁ = 15, n₂ = 10)\n2. Population variances are unknown and not assumed equal,\nwe use the Welch's t-test (unequal variances t-test)\n\n⸻\n\nStep 3: Compute the Test Statistic\n\nt = (90 - 88) / √[(2.3² / 15) + (2.2² / 10)]\n= 2 / √[(5.29 / 15) + (4.84 / 10)]\n= 2 / √[0.3527 + 0.484]\n= 2 / √0.8367\n≈ 2 / 0.9147\n≈ 2.187\n\n⸻\n\nStep 4: Determine the Degrees of Freedom\n\ndf = [(0.3527 + 0.484)²] / [(0.3527² / 14) + (0.484² / 9)]\n= (0.8367²) / [(0.1244 / 14) + (0.2343 / 9)]\n= 0.7001 / (0.0089 + 0.0260)\n= 0.7001 / 0.0349\n≈ 20.06 → df ≈ 20\n\n⸻\n\nStep 5: Find the Critical t-Value\n\nFor a two-tailed test at α = 0.05 and df = 20:\nt_critical = ±2.086\n\n⸻\n\nStep 6: Compare the Test Statistic to the Critical Value\n• Calculated t: 2.187\n• Critical t: ±2.086\n\nSince |2.187| > 2.086, we reject the null hypothesis\n\n⸻\n\nStep 7: Conclusion\n\nThere is statistically significant evidence at the 5% level to conclude that the tensile strengths of the two components differ\n\n⸻\n\nFinal Answer\n\nAt the 5% significance level, there is a statistically significant difference in the tensile strengths of the two components (t ≈ 2.187, df ≈ 20, p < 0.05)\n\nYes, there is a statistically significant difference (p < 0.05).",
        "timestamp": 1751812654.944733
    },
    {
        "id": 32,
        "index": "E2.345",
        "topic": "Hypothesis Testing",
        "difficulty": "intermediate",
        "problem": "In a psychology class, the average grade is known to be 67.5 points with a population standard deviation of 9.5. A researcher samples 20 psychology students and finds their average grade is 72.3. Test at the 5% significance level whether psychology students score differently than the class average.",
        "solution_steps": [
            "1. Define hypotheses: H₀: μ = 67.5, H₁: μ ≠ 67.5.",
            "2. Given: sample mean x̄ = 72.3, σ = 9.5, n = 20, α = 0.05.",
            "3. Compute standard error: SE = σ / √n = 9.5 / √20 ≈ 2.12.",
            "4. Compute z‑score: z = (x̄ − μ₀) / SE = (72.3 − 67.5) / 2.12 ≈ 2.26.",
            "5. For a two‑tailed test at α = 0.05, critical values are ±1.96.",
            "6. Since 2.26 > 1.96, reject H₀.",
            "7. Conclusion: There is sufficient evidence to conclude that psychology students' grades differ significantly from the class average."
        ],
        "conclusion": "The test indicates a significant difference (at 5% level) between psychology students and the class average.",
        "keywords": [
            "one-sample z-test",
            "hypothesis testing",
            "psychology students",
            "grade comparison"
        ],
        "source": "Adapted from LibreTexts example 'One Sample Mean z Test', Stats 200 ()",
        "model_response": "Hypothesis Test for Psychology Class Grades\n\nGiven:\n• Population mean (μ): 67.5 points\n• Population standard deviation (σ): 9.5 points\n• Sample size (n): 20 students\n• Sample mean (x̄): 72.3 points\n• Significance level (α): 0.05\n\nObjective:\n\nTest whether psychology students' grades differ from the class average (two-tailed test).\n\n⸻\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): μ = 67.5 (no difference from the class average).\n• Alternative Hypothesis (H₁): μ ≠ 67.5 (two-tailed test).\n\n⸻\n\nStep 2: Choose the Appropriate Test\n\nSince:\n1. The population standard deviation (σ) is known,\n2. The sample size is small (n = 20), but the population is normally distributed (implied by given σ),\nwe use the z-test (though a t-test could also be considered if σ were unknown).\n\n⸻\n\nStep 3: Compute the Test Statistic (z-score)\n\nz = (72.3 - 67.5) / (9.5 / √20) = 4.8 / 2.124 ≈ 2.26\n\n⸻\n\nStep 4: Determine the Critical Value\n\nFor a two-tailed test at α = 0.05, the critical z-values are:\nz_critical = ±1.96\n\n⸻\n\nStep 5: Compare z-score to Critical Value\n• Calculated z: 2.26\n• Critical z: ±1.96\n\nSince |2.26| > 1.96, we reject the null hypothesis.\n\n⸻\n\nStep 6: Calculate the p-value\n\np-value = 2 × P(Z > 2.26) = 2 × 0.0119 = 0.0238\nSince p-value (0.0238) < α (0.05), we reject H₀.\n\n⸻\n\nStep 7: Conclusion\n\nThere is statistically significant evidence at the 5% level to conclude that psychology students' grades differ from the class average.\n\n⸻\n\nFinal Answer\n\nAt the 5% significance level, psychology students' average grade (72.3) is significantly different from the class average (67.5) (z = 2.26, p = 0.024).\n\nReject H₀; psychology students' grades differ significantly (p < 0.05).\n\n⸻\n\nKey Notes:\n1. Test Used: z-test (σ known, small n but normal population assumed).\n2. Result: Significant difference (p = 0.024 < 0.05).\n3. Interpretation: Psychology students perform better than the class average.\n\nIf σ were unknown, we'd use a t-test with df = 19, yielding similar but slightly less significant results (critical t ≈ ±2.093). Here, the z-test suffices.",
        "timestamp": 1751812745.466801
    },
    {
        "id": 33,
        "index": "E2.456",
        "topic": "ANOVA",
        "difficulty": "intermediate",
        "keywords": [
            "ANOVA",
            "meal plans",
            "weight loss analysis",
            "nutritional study",
            "F-test"
        ],
        "source": "Daniel Giurleo (#0788070), SOCI-3160 Week 8 Exercises – Draft 01, Trent University, Course: SOCI 3160H, Nov 9, 2024, Page 4 (https://www.cliffsnotes.com/study-notes/21973801)",
        "problem": "A nutritionist tests the effects of three different meal plans (Plan A, Plan B, Plan C) on weight loss over a 6-week period. The weight loss (in pounds) for each plan is as follows: Plan A = [6, 7, 8], Plan B = [5, 6, 7], Plan C = [8, 9, 10]. Conduct a one-way ANOVA test.",
        "correct_solution": {
            "steps": [
                "1. Calculate the group means: Mean of Plan A = (6 + 7 + 8) / 3 = 7, Mean of Plan B = (5 + 6 + 7) / 3 = 6, Mean of Plan C = (8 + 9 + 10) / 3 = 9.",
                "2. Calculate the overall mean: Overall mean = (6 + 7 + 8 + 5 + 6 + 7 + 8 + 9 + 10) / 9 = 7.33.",
                "3. Calculate the sum of squares between groups (SSB): SSB = 3 * [(7 - 7.33)^2 + (6 - 7.33)^2 + (9 - 7.33)^2] = 8.67.",
                "4. Calculate the sum of squares within groups (SSW): SSW = [(6 - 7)^2 + (7 - 7)^2 + (8 - 7)^2] + [(5 - 6)^2 + (6 - 6)^2 + (7 - 6)^2] + [(8 - 9)^2 + (9 - 9)^2 + (10 - 9)^2] = 6.",
                "5. Calculate the degrees of freedom: df_between = 2, df_within = 6.",
                "6. Calculate the mean squares: MSB = 8.67 / 2 = 4.33, MSW = 6 / 6 = 1.",
                "7. Calculate the F-statistic: F = 4.33 / 1 = 4.33.",
                "8. Conclusion: Compare the F-statistic to the critical value. If F > F_critical, reject the null hypothesis."
            ],
            "conclusion": "The F-statistic suggests that there may be significant differences in weight loss among the different meal plans.",
            "full_solution": "1. Calculate the group means: Mean of Plan A = (6 + 7 + 8) / 3 = 7, Mean of Plan B = (5 + 6 + 7) / 3 = 6, Mean of Plan C = (8 + 9 + 10) / 3 = 9.\n2. Calculate the overall mean: Overall mean = (6 + 7 + 8 + 5 + 6 + 7 + 8 + 9 + 10) / 9 = 7.33.\n3. Calculate the sum of squares between groups (SSB): SSB = 3 * [(7 - 7.33)^2 + (6 - 7.33)^2 + (9 - 7.33)^2] = 8.67.\n4. Calculate the sum of squares within groups (SSW): SSW = [(6 - 7)^2 + (7 - 7)^2 + (8 - 7)^2] + [(5 - 6)^2 + (6 - 6)^2 + (7 - 6)^2] + [(8 - 9)^2 + (9 - 9)^2 + (10 - 9)^2] = 6.\n5. Calculate the degrees of freedom: df_between = 2, df_within = 6.\n6. Calculate the mean squares: MSB = 8.67 / 2 = 4.33, MSW = 6 / 6 = 1.\n7. Calculate the F-statistic: F = 4.33 / 1 = 4.33.\n8. Conclusion: Compare the F-statistic to the critical value. If F > F_critical, reject the null hypothesis."
        },
        "model_response": "One-Way ANOVA Test for Weight Loss Across Three Meal Plans\n\nGiven Data:\n• Plan A: [6, 7, 8]\n• Plan B: [5, 6, 7]\n• Plan C: [8, 9, 10]\n\nObjective:\nTest whether there is a statistically significant difference in mean weight loss across the three meal plans at α = 0.05.\n\n⸻\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): μ_A = μ_B = μ_C (no difference in means).\n• Alternative Hypothesis (H₁): At least one mean differs.\n\n⸻\n\nStep 2: Calculate Summary Statistics\n\nPlan     Sample Size (n)    Mean (x̄)    Variance (s²)\nA          3                 7.0          1.0\nB          3                 6.0          1.0\nC          3                 9.0          1.0\n\nOverall Mean (Grand Mean, x̄̄):\nx̄̄ = (7.0 + 6.0 + 9.0) / 3 = 7.33\n\n⸻\n\nStep 3: Compute Sum of Squares\n1. Between-Group Variability (SSB):\nSSB = 3 * (7.0 - 7.33)^2 + 3 * (6.0 - 7.33)^2 + 3 * (9.0 - 7.33)^2 = 14.0\n2. Within-Group Variability (SSW):\nSSW = 2 * 1.0 + 2 * 1.0 + 2 * 1.0 = 6.0\n3. Total Variability (SST):\nSST = 14.0 + 6.0 = 20.0\n\n⸻\n\nStep 4: Calculate Degrees of Freedom\n• Between Groups (dfB): 3 - 1 = 2\n• Within Groups (dfW): 9 - 3 = 6\n• Total (dfT): 9 - 1 = 8\n\n⸻\n\nStep 5: Compute Mean Squares\n• MSB (Between):\nMSB = 14.0 / 2 = 7.0\n• MSW (Within):\nMSW = 6.0 / 6 = 1.0\n\n⸻\n\nStep 6: Calculate the F-Statistic\n\nF = 7.0 / 1.0 = 7.0\n\n⸻\n\nStep 7: Determine the Critical F-Value\n\nFor α = 0.05, dfB = 2, and dfW = 6, the critical F-value is:\nF_critical = 5.14\n\n⸻\n\nStep 8: Compare F-Statistic to Critical Value\n• Calculated F: 7.0\n• Critical F: 5.14\n\nSince 7.0 > 5.14, we reject H₀.\n\n⸻\n\nStep 9: Post-Hoc Analysis (Tukey's HSD)\n1. Critical Q-value for k = 3, df = 6, α = 0.05: 4.34\n2. HSD (Honest Significant Difference):\nHSD = 4.34 * sqrt(1.0 / 3) = 4.34 * 0.577 = 2.51\n3. Pairwise Comparisons:\n\n• Plan A vs. Plan B: |7.0 - 6.0| = 1.0 (Not significant, 1.0 < 2.51)\n• Plan A vs. Plan C: |7.0 - 9.0| = 2.0 (Not significant, 2.0 < 2.51)\n• Plan B vs. Plan C: |6.0 - 9.0| = 3.0 (Significant, 3.0 > 2.51)\n\n⸻\n\nFinal Answer\n• ANOVA Result: Reject H₀ (F(2,6) = 7.0, p < 0.05)\n• Conclusion: There is a significant difference in weight loss across the plans.\n• Post-Hoc: Only Plan B vs. Plan C differs significantly.\n\n⸻\n\nBoxed Summary:\n\nANOVA: F(2,6) = 7.0, p < 0.05\nSignificant difference exists\nPlan C > Plan B (p < 0.05)",
        "timestamp": 1751812835.9903748
    },
    {
        "id": 34,
        "index": "E2.567",
        "topic": "Hypothesis Testing (Proportions)",
        "difficulty": "intermediate",
        "keywords": [
            "hypothesis test",
            "proportion",
            "normal approximation",
            "continuity correction",
            "two-tailed test"
        ],
        "source": "Cambridge International AS & A Level Mathematics: Probability & Statistics 2, Worked Example 1.2",
        "problem": "A newspaper reported that 75% of students regularly cycle to college. A college dean believes that figure to be different at his college. He asks a sample of 160 students, and 109 say they do cycle. Test the dean's belief at the 5% level of significance.",
        "correct_solution": {
            "steps": [
                "1. State the hypotheses: H₀: p = 0.75 (the proportion is 75%), H₁: p ≠ 0.75 (the proportion is different)",
                "2. Model the distribution: X ~ B(160, 0.75) → approximated by normal: N(μ = 120, σ = √(160 × 0.75 × 0.25) = √30 ≈ 5.48)",
                "3. Apply continuity correction: Use 109.5 instead of 109.",
                "4. Calculate Z-score: Z = (109.5 − 120) / √30 = −1.917",
                "5. Find probability: P(X ≤ 109) = P(Z ≤ −1.917) = 0.0277",
                "6. Compare with significance level: Since this is a two-tailed test, compare with 0.025 (half of 5%). 0.0277 > 0.025 → do not reject H₀"
            ],
            "conclusion": "Accept H₀. There is insufficient evidence to show that the proportion of students cycling at the college is different from the national average of 75%.",
            "full_solution": "1. State the hypotheses: H₀: p = 0.75 (the proportion is 75%), H₁: p ≠ 0.75 (the proportion is different)\n2. Model the distribution: X ~ B(160, 0.75) → approximated by normal: N(μ = 120, σ = √(160 × 0.75 × 0.25) = √30 ≈ 5.48)\n3. Apply continuity correction: Use 109.5 instead of 109.\n4. Calculate Z-score: Z = (109.5 − 120) / √30 = −1.917\n5. Find probability: P(X ≤ 109) = P(Z ≤ −1.917) = 0.0277\n6. Compare with significance level: Since this is a two-tailed test, compare with 0.025 (half of 5%). 0.0277 > 0.025 → do not reject H₀"
        },
        "model_response": "Hypothesis Test for Proportion of Cycling Students\n\nGiven:\n• Claimed proportion (p₀): 75% (0.75)\n• Sample size (n): 160 students\n• Number of cyclists in sample (x): 109\n• Sample proportion (p̂): 109 / 160 = 0.68125\n• Significance level (α): 0.05\n\nObjective:\n\nTest whether the true proportion of cycling students at the dean's college differs from 75%.\n\n⸻\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): p = 0.75 (no difference from the reported figure).\n• Alternative Hypothesis (H₁): p ≠ 0.75 (two-tailed test).\n\n⸻\n\nStep 2: Verify Conditions for Normal Approximation\n1. np₀ = 160 × 0.75 = 120 ≥ 10\n2. n(1 − p₀) = 160 × 0.25 = 40 ≥ 10\nThe normal approximation is valid.\n\n⸻\n\nStep 3: Compute the Test Statistic (z-score)\n\nz = (0.68125 − 0.75) / sqrt[(0.75 × 0.25) / 160]\nz = (−0.06875) / 0.0342 ≈ −2.01\n\n⸻\n\nStep 4: Determine the Critical Value\n\nFor a two-tailed test at α = 0.05, the critical z-values are:\nz_critical = ±1.96\n\n⸻\n\nStep 5: Compare z-score to Critical Value\n• Calculated z: −2.01\n• Critical z: ±1.96\n\nSince |−2.01| > 1.96, we reject H₀.\n\n⸻\n\nStep 6: Calculate the p-value\n\np-value = 2 × P(Z < −2.01) = 2 × 0.0222 = 0.0444\nSince p-value (0.044) < α (0.05), we reject H₀.\n\n⸻\n\nStep 7: Conclusion\n\nThere is statistically significant evidence at the 5% level to conclude that the proportion of cycling students at the dean's college differs from the reported 75%.\n\n⸻\n\nFinal Answer\n\nAt the 5% significance level, the dean is correct: the proportion of cycling students (68.1%) is significantly lower than the reported 75% (z = −2.01, p = 0.044)\n\nBoxed Final Answer:\nReject H₀; the proportion differs significantly (p < 0.05).\n\n⸻\n\nKey Notes:\n1. Test Used: One-proportion z-test (large sample, normal approximation).\n2. Effect Direction: The sample proportion (68.1%) is lower than the claimed 75%.\n3. Practical Implication: The dean's college may need interventions to promote cycling.\n\nNote: If the sample were smaller, a binomial exact test would be preferable. Here, the z-test suffices.",
        "timestamp": 1751812926.512325
    },
    {
        "id": 35,
        "index": "E2.678",
        "topic": "Hypothesis Testing - Binomial to Normal Approximation",
        "difficulty": "intermediate",
        "keywords": [
            "binomial distribution",
            "normal approximation",
            "significance test",
            "continuity correction",
            "hypothesis testing",
            "p-value"
        ],
        "source": "Cambridge International AS & A Level Mathematics: Probability & Statistics 2, Worked Example 1.1",
        "problem": "In a test, the questions are all multiple choice with five possible options. (a) In a test with twelve questions, one student gets four questions correct. Test, at the 10% significance level, the null hypothesis that the student is guessing the answers. (b) In a further test there are 120 questions. The same student took the test and got 32 correct. Test, at the 10% significance level, whether there is evidence to show the student is guessing the answers.",
        "correct_solution": {
            "steps": [
                "(a) Let X be the number of correct answers achieved.",
                "X ~ B(12, 0.2)",
                "H₀: p = 0.2, H₁: p > 0.2",
                "P(X ≥ 4) = 1 – P(X ≤ 3)",
                "P(X ≤ 3) = P(X=0) + P(X=1) + P(X=2) + P(X=3)",
                "Using binomial terms: = 1 – [ (12C0)(0.2^0)(0.8^12) + (12C1)(0.2^1)(0.8^11) + (12C2)(0.2^2)(0.8^10) + (12C3)(0.2^3)(0.8^9) ] = 1 – 0.795 = 0.205",
                "0.205 > 0.1. Accept H₀. There is sufficient evidence to show that the student is guessing answers.",
                "(b) X ~ B(120, 0.2) ≈ N(24, 19.2)",
                "H₀: p = 0.2 or μ = 24, H₁: p > 0.2 or μ > 24",
                "Use normal approximation with continuity correction: P(X ≥ 32) = P(X ≥ 31.5)",
                "Standardize: Z = (31.5 – 24) / √19.2 ≈ 1.712",
                "P(Z ≥ 1.712) = 1 – Φ(1.712) = 1 – 0.957 = 0.043",
                "0.043 < 0.1. Reject H₀. There is evidence to suggest that the student might not be guessing answers."
            ],
            "conclusion": "For the 12-question test, we accept that the student is guessing. For the 120-question test, we reject the guessing hypothesis.",
            "full_solution": "1. (a) Let X be the number of correct answers achieved.\n2. X ~ B(12, 0.2)\n3. H₀: p = 0.2, H₁: p > 0.2\n4. P(X ≥ 4) = 1 – P(X ≤ 3)\n5. P(X ≤ 3) = P(X=0) + P(X=1) + P(X=2) + P(X=3)\n6. Using binomial terms: = 1 – [ (12C0)(0.2^0)(0.8^12) + (12C1)(0.2^1)(0.8^11) + (12C2)(0.2^2)(0.8^10) + (12C3)(0.2^3)(0.8^9) ] = 1 – 0.795 = 0.205\n7. 0.205 > 0.1. Accept H₀. There is sufficient evidence to show that the student is guessing answers.\n8. (b) X ~ B(120, 0.2) ≈ N(24, 19.2)\n9. H₀: p = 0.2 or μ = 24, H₁: p > 0.2 or μ > 24\n10. Use normal approximation with continuity correction: P(X ≥ 32) = P(X ≥ 31.5)\n11. Standardize: Z = (31.5 – 24) / √19.2 ≈ 1.712\n12. P(Z ≥ 1.712) = 1 – Φ(1.712) = 1 – 0.957 = 0.043\n13. 0.043 < 0.1. Reject H₀. There is evidence to suggest that the student might not be guessing answers."
        },
        "model_response": "Part (a): Testing Guessing for 12 Questions\n\nGiven:\n• Number of questions (n): 12\n• Correct answers (x): 4\n• Probability of guessing correctly (p₀): 1/5 = 0.2\n• Significance level (α): 0.10\n\nObjective:\n\nTest whether the student is guessing (i.e., p = 0.2) or performing better/worse than random chance.\n\n⸻\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): p = 0.2 (student is guessing)\n• Alternative Hypothesis (H₁): p ≠ 0.2 (two-tailed test)\n\n⸻\n\nStep 2: Choose the Test\n\nSince n = 12 is small, we use the binomial exact test (not normal approximation)\n\n⸻\n\nStep 3: Calculate the p-value\n\nThe p-value is the probability of observing 4 or more extreme correct answers under H₀\n\nFor a two-tailed test:\n1. Right-tail: P(X ≥ 4)\n2. Left-tail: P(X ≤ k), where k is symmetrically extreme\n\nUsing binomial probabilities:\nP(X = 0) ≈ 0.0687\nP(X = 1) ≈ 0.2062\nP(X = 2) ≈ 0.2835\nP(X = 3) ≈ 0.2362\n\nP(X ≤ 3) ≈ 0.0687 + 0.2062 + 0.2835 + 0.2362 = 0.7946\nP(X ≥ 4) = 1 − 0.7946 = 0.2054\n\np-value = 2 × min[0.2054, P(X ≤ 4)] = 2 × 0.2054 = 0.4108\n\n⸻\n\nStep 4: Compare p-value to α\n\np-value = 0.4108 > α = 0.10\nConclusion: Fail to reject H₀. No evidence that the student is not guessing\n\n⸻\n\nPart (b): Testing Guessing for 120 Questions\n\nGiven:\n• Number of questions (n): 120\n• Correct answers (x): 32\n• Probability of guessing correctly (p₀): 0.2\n• Significance level (α): 0.10\n\nObjective:\n\nTest whether the student is guessing (i.e., p = 0.2) or performing better/worse\n\n⸻\n\nStep 1: State the Hypotheses\n• H₀: p = 0.2\n• H₁: p ≠ 0.2\n\n⸻\n\nStep 2: Choose the Test\n\nSince n = 120 is large, we use the normal approximation to the binomial:\nz = (p̂ − p₀) / sqrt[p₀(1 − p₀) / n]\nwhere p̂ = 32 / 120 = 0.2667\n\n⸻\n\nStep 3: Compute the Test Statistic\n\nz = (0.2667 − 0.2) / sqrt[(0.2 × 0.8) / 120] = 0.0667 / 0.0365 ≈ 1.827\n\n⸻\n\nStep 4: Determine the Critical Value\n\nFor a two-tailed test at α = 0.10:\nz_critical = ±1.645\n\n⸻\n\nStep 5: Compare z-score to Critical Value\n\n|1.827| > 1.645\nReject H₀\n\n⸻\n\nStep 6: Calculate the p-value\n\np-value = 2 × P(Z > 1.827) ≈ 2 × 0.0339 = 0.0678\nSince 0.0678 < 0.10, reject H₀\n\n⸻\n\nStep 7: Conclusion\n\nThere is evidence (at 10% significance) that the student is not guessing (performed better than random chance)\n\n⸻\n\nFinal Answers\n\n(a) For 12 questions:\nFail to reject H₀; no evidence against guessing (p = 0.41)\n\n(b) For 120 questions:\nReject H₀; evidence that the student is not guessing (p = 0.068)\n\n⸻\n\nKey Notes:\n1. Small sample (n = 12): No significance (p > 0.10)\n2. Large sample (n = 120): Significant (p < 0.10)\n3. Effect direction: Student performed better than guessing (26.7% vs. 20%)",
        "timestamp": 1751813017.0278301
    },
    {
        "id": 36,
        "index": "E2.789",
        "topic": "Hypothesis testing",
        "difficulty": "intermediate",
        "keywords": [
            "t-test",
            "hypothesis testing",
            "small sample",
            "mean comparison",
            "one-sample test"
        ],
        "source": "OpenIntro Statistics, 4th Edition (2019), Section 7.1: One-Sample Means with the t-Distribution, Page 261",
        "problem": "Georgianna claims that in a small city renowned for its music school, the average child takes less than 5 years of piano lessons. A random sample of 24 children from the city shows a mean of 4.6 years of piano lessons with a standard deviation of 2.2 years. Evaluate Georgianna's claim using a hypothesis test at a 0.05 significance level.",
        "correct_solution": {
            "steps": [
                "Step 1: Set up hypotheses: H₀: μ ≥ 5 (null hypothesis - average is 5 years or more), H₁: μ < 5 (alternative hypothesis - Georgianna's claim)",
                "Step 2: Given values: sample_size = 24, sample_mean = 4.6, sample_sd = 2.2, alpha = 0.05, test_type = left-tailed",
                "Step 3: Compute test statistic (t): t = (x̄ - μ₀) / (s / √n) = (4.6 - 5) / (2.2 / √24) = -0.4 / 0.449 ≈ -0.891",
                "Step 4: Determine critical value and p-value: degrees_of_freedom = 23, critical_value = -1.714, p_value ≈ 0.191",
                "Step 5: Make decision: Since t = -0.891 > -1.714 and p-value = 0.191 > 0.05, we fail to reject H₀."
            ],
            "conclusion": "There is insufficient evidence to support Georgianna's claim that the average child takes less than 5 years of piano lessons.",
            "full_solution": "1. Step 1: Set up hypotheses: H₀: μ ≥ 5 (null hypothesis - average is 5 years or more), H₁: μ < 5 (alternative hypothesis - Georgianna's claim)\n2. Step 2: Given values: sample_size = 24, sample_mean = 4.6, sample_sd = 2.2, alpha = 0.05, test_type = left-tailed\n3. Step 3: Compute test statistic (t): t = (x̄ - μ₀) / (s / √n) = (4.6 - 5) / (2.2 / √24) = -0.4 / 0.449 ≈ -0.891\n4. Step 4: Determine critical value and p-value: degrees_of_freedom = 23, critical_value = -1.714, p_value ≈ 0.191\n5. Step 5: Make decision: Since t = -0.891 > -1.714 and p-value = 0.191 > 0.05, we fail to reject H₀."
        },
        "model_response": "Hypothesis Test for Average Piano Lesson Duration\n\nGiven:\n• Claim: Average years of piano lessons μ < 5\n• Sample size (n): 24 children\n• Sample mean (x̄): 4.6 years\n• Sample standard deviation (s): 2.2 years\n• Significance level (α): 0.05\n\nObjective:\n\nTest whether the average piano lesson duration is less than 5 years (Georgianna's claim)\n\n⸻\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): μ = 5 (no difference from 5 years)\n• Alternative Hypothesis (H₁): μ < 5 (Georgianna's claim, one-tailed test)\n\n⸻\n\nStep 2: Choose the Appropriate Test\n\nSince:\n1. The population standard deviation (σ) is unknown\n2. The sample size is small (n = 24 < 30)\nWe use the t-test with n − 1 = 23 degrees of freedom\n\n⸻\n\nStep 3: Compute the Test Statistic (t-score)\n\nt = (x̄ − μ₀) / (s / √n) = (4.6 − 5) / (2.2 / √24) = (−0.4) / 0.449 ≈ −0.89\n\n⸻\n\nStep 4: Determine the Critical t-Value\n\nFor a one-tailed test at α = 0.05 and df = 23:\nt_critical = −1.714 (from t-distribution table)\n\n⸻\n\nStep 5: Compare t-score to Critical Value\n• Calculated t: −0.89\n• Critical t: −1.714\n\nSince −0.89 > −1.714, we fail to reject H₀\n\n⸻\n\nStep 6: Calculate the p-value\n\nUsing a t-distribution calculator with df = 23:\np-value = P(t ≤ −0.89) ≈ 0.191\nSince p-value = 0.191 > α = 0.05, we fail to reject H₀\n\n⸻\n\nStep 7: Conclusion\n\nThere is insufficient evidence at the 5% significance level to support Georgianna's claim that the average child takes less than 5 years of piano lessons\n\n⸻\n\nFinal Answer\n\nAt the 5% significance level, we cannot conclude that the average piano lesson duration is less than 5 years (t = −0.89, p = 0.191)\n\nFail to reject H₀; insufficient evidence for Georgianna's claim (p > 0.05).\n\n⸻\n\nKey Notes:\n1. Test Used: One-sample t-test (σ unknown, small sample)\n2. Effect Size: The sample mean (4.6) is 0.4 years below 5, but variability is high (s = 2.2)\n3. Practical Implication: A larger sample might detect significance if the true mean is slightly below 5\n\nNote: If α = 0.10, the critical t = −1.319, and the result would still not be significant (−0.89 > −1.319)",
        "timestamp": 1751813107.556181
    },
    {
        "id": 37,
        "index": "E2.890",
        "topic": "One-Sample Z-Test (Known σ)",
        "difficulty": "intermediate",
        "keywords": [
            "hypothesis testing",
            "z-test",
            "left-tailed test",
            "p-value",
            "normal distribution",
            "swimming performance"
        ],
        "source": "OpenStax: Introductory Statistics 2e, Section 9.5",
        "problem": "Jeffrey, an eight-year-old, had an established mean time of 16.43 seconds for swimming the 25-yard freestyle, with a population standard deviation of 0.8 seconds. His father Frank bought him expensive goggles, suspecting they might help him swim faster. In 15 timed swims using the goggles, Jeffrey's sample mean time was 16 seconds. Test whether the goggles helped Jeffrey swim faster, using a significance level of α = 0.05. Assume the swim times are normally distributed.",
        "correct_solution": {
            "steps": [
                "Step 1: State the hypotheses. Null Hypothesis (H₀): μ = 16.43, Alternative Hypothesis (H₁): μ < 16.43. This is a left-tailed test since we're checking if Jeffrey swims faster (i.e., mean time is less).",
                "Step 2: Define the distribution. Random variable: X̄ = mean swim time. Since σ is known and the data are normal, use the z-distribution. Parameters: μ = 16.43, σ = 0.8, n = 15",
                "Step 3: Calculate the test statistic. Standard Error (SE) = σ / √n = 0.8 / √15 ≈ 0.206. z = (16 - 16.43) / 0.206 ≈ -2.087",
                "Step 4: Find the p-value. Using the standard normal distribution: p-value = P(Z < -2.087) ≈ 0.0187",
                "Step 5: Compare p-value and α. α = 0.05. Since p-value = 0.0187 < 0.05, we reject the null hypothesis.",
                "Step 6: Conclusion. There is sufficient evidence at the 5% significance level to conclude that Jeffrey's mean time is less than 16.43 seconds. The goggles likely helped him swim faster."
            ],
            "conclusion": "Reject H₀. The data provide sufficient evidence to support that Jeffrey swims the 25-yard freestyle faster (i.e., in less than 16.43 seconds) using the new goggles.",
            "full_solution": "1. Step 1: State the hypotheses. Null Hypothesis (H₀): μ = 16.43, Alternative Hypothesis (H₁): μ < 16.43. This is a left-tailed test since we're checking if Jeffrey swims faster (i.e., mean time is less).\n2. Step 2: Define the distribution. Random variable: X̄ = mean swim time. Since σ is known and the data are normal, use the z-distribution. Parameters: μ = 16.43, σ = 0.8, n = 15\n3. Step 3: Calculate the test statistic. Standard Error (SE) = σ / √n = 0.8 / √15 ≈ 0.206. z = (16 - 16.43) / 0.206 ≈ -2.087\n4. Step 4: Find the p-value. Using the standard normal distribution: p-value = P(Z < -2.087) ≈ 0.0187\n5. Step 5: Compare p-value and α. α = 0.05. Since p-value = 0.0187 < 0.05, we reject the null hypothesis.\n6. Step 6: Conclusion. There is sufficient evidence at the 5% significance level to conclude that Jeffrey's mean time is less than 16.43 seconds. The goggles likely helped him swim faster."
        },
        "model_response": "Hypothesis Test for Jeffrey's Swim Time with New Goggles\n\nGiven:\n• Population mean (μ): 16.43 seconds\n• Population standard deviation (σ): 0.8 seconds\n• Sample size (n): 15 swims\n• Sample mean (x̄): 16 seconds\n• Significance level (α): 0.05\n• Assumption: Swim times are normally distributed.\n\nObjective:\n\nTest whether the goggles helped Jeffrey swim faster (i.e., reduced his average time).\n\n⸻\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): μ = 16.43 (no improvement)\n• Alternative Hypothesis (H₁): μ < 16.43 (one-tailed test, goggles reduce time)\n\n⸻\n\nStep 2: Choose the Appropriate Test\n\nSince:\n1. The population standard deviation (σ) is known\n2. The sample size is small (n = 15), but the population is normal\nWe use the z-test (though a t-test could also be used if σ were unknown)\n\n⸻\n\nStep 3: Compute the Test Statistic (z-score)\n\nz = (x̄ − μ) / (σ / sqrt(n)) = (16 − 16.43) / (0.8 / sqrt(15)) = (−0.43) / 0.2066 ≈ −2.08\n\n⸻\n\nStep 4: Determine the Critical Value\n\nFor a one-tailed test at α = 0.05:\nz_critical = −1.645\n\n⸻\n\nStep 5: Compare z-score to Critical Value\n• Calculated z: −2.08\n• Critical z: −1.645\n\nSince −2.08 < −1.645, we reject H₀\n\n⸻\n\nStep 6: Calculate the p-value\n\np-value = P(Z < −2.08) ≈ 0.0188\nSince p-value = 0.0188 < α = 0.05, we reject H₀\n\n⸻\n\nStep 7: Conclusion\n\nThere is statistically significant evidence at the 5% level to conclude that Jeffrey's average swim time with the goggles is less than 16.43 seconds\n\n⸻\n\nFinal Answer\n\nAt the 5% significance level, the goggles significantly reduced Jeffrey's swim time (z = −2.08, p = 0.0188)\n\nReject H₀; the goggles improved Jeffrey's swim time (p < 0.05).\n\n⸻\n\nKey Notes:\n1. Test Used: One-sample z-test (σ known, normal population)\n2. Effect Size: The sample mean (16 seconds) is 0.43 seconds faster than the established mean (16.43)\n3. Practical Implication: The goggles likely provide a real performance benefit\n\nNote: If σ were unknown, we'd use a t-test with df = 14, yielding a critical t = −1.761 and p ≈ 0.028. The conclusion remains the same.",
        "timestamp": 1751813198.074503
    },
    {
        "id": 38,
        "index": "E3.234",
        "topic": "One Sample t-test",
        "difficulty": "advanced",
        "keywords": [
            "t-test",
            "hypothesis testing",
            "one-sample test",
            "lactic acid",
            "small sample",
            "cheese analysis"
        ],
        "source": "Probability and Statistics (Morris H. DeGroot, Mark J. Schervish), Chapter 8, Example 8.5.4, Page 512",
        "problem": "Use the data [0.86, 1.53, 1.57, 1.81, 0.99, 1.09, 1.29, 1.78, 1.29, 1.58], comprising a sample of n = 10 lactic acid measurements in cheese. The lactic acid measurements are a random sample from a normal distribution with unknown mean μ and unknown variance σ². Hypotheses: H₀: μ ≤ 1.2, H₁: μ > 1.2. Tasks: a. Perform the level α₀ = 0.05 test of these hypotheses. b. Compute the p-value.",
        "correct_solution": {
            "steps": [
                "Compute sample size: n = 10",
                "Compute sample mean: x̄ = 1.379",
                "Compute sample standard deviation: s ≈ 0.3277",
                "Calculate test statistic: t = (1.379 - 1.2) / (0.3277 / sqrt(10)) ≈ 1.831",
                "Degrees of freedom: df = 9",
                "Find critical value for one-tailed test at α = 0.05: t_critical ≈ 1.833",
                "Compare t = 1.831 < t_critical = 1.833 → Fail to reject H₀",
                "p-value ≈ 0.049 < p < 0.05 (from t-distribution table with df = 9)"
            ],
            "conclusion": "We fail to reject the null hypothesis at the 0.05 level. There is insufficient evidence to conclude that the mean lactic acid concentration exceeds 1.2.",
            "full_solution": "1. Compute sample size: n = 10\n2. Compute sample mean: x̄ = 1.379\n3. Compute sample standard deviation: s ≈ 0.3277\n4. Calculate test statistic: t = (1.379 - 1.2) / (0.3277 / sqrt(10)) ≈ 1.831\n5. Degrees of freedom: df = 9\n6. Find critical value for one-tailed test at α = 0.05: t_critical ≈ 1.833\n7. Compare t = 1.831 < t_critical = 1.833 → Fail to reject H₀\n8. p-value ≈ 0.049 < p < 0.05 (from t-distribution table with df = 9)"
        },
        "model_response": "Solution: One-Sample t-Test for Lactic Acid Measurements\n\nGiven Data:\n\nSample of 10 lactic acid measurements:\n[0.86, 1.53, 1.57, 1.81, 0.99, 1.09, 1.29, 1.78, 1.29, 1.58]\n\nHypotheses:\n• H₀: μ ≤ 1.2 (mean lactic acid ≤ 1.2)\n• H₁: μ > 1.2 (mean lactic acid > 1.2)\n\nSignificance level: α = 0.05\n\n⸻\n\nStep 1: Calculate Sample Statistics\n1. Sample Mean (x̄):\nx̄ = (0.86 + 1.53 + … + 1.58) / 10 = 13.79 / 10 = 1.379\n2. Sample Standard Deviation (s):\ns = sqrt[ Σ(xᵢ − x̄)² / (n − 1) ] = sqrt[ ((0.86 − 1.379)² + … + (1.58 − 1.379)²) / 9 ] ≈ 0.33\n\n⸻\n\nStep 2: Perform the t-Test\n1. Test Statistic:\nt = (x̄ − μ₀) / (s / sqrt(n)) = (1.379 − 1.2) / (0.33 / sqrt(10)) ≈ 0.179 / 0.104 ≈ 1.72\n2. Critical Value (One-Tailed):\nFor α = 0.05 and df = 9:\nt_critical = 1.833\n3. Decision Rule:\nReject H₀ if t > t_critical\nHere, 1.72 < 1.833 → Fail to reject H₀\n\n⸻\n\nStep 3: Compute the p-value\n\nThe p-value is P(T ≥ 1.72) with df = 9\nFrom t-distribution tables or software:\np-value ≈ 0.059\n\nInterpretation:\np-value > α (0.059 > 0.05) → Fail to reject H₀\n\n⸻\n\nFinal Answers\n\n(a) Hypothesis Test Conclusion:\nFail to reject H₀ at α = 0.05 (t = 1.72, critical t = 1.833)\n\n(b) p-value:\np-value ≈ 0.059\n\n⸻\n\nKey Notes:\n1. Test Assumptions:\n• Data is normally distributed (reasonable with n = 10)\n• Population variance unknown → t-test used\n2. Practical Implication:\n• No statistically significant evidence (p = 0.059) that the mean lactic acid exceeds 1.2 at α = 0.05\n• At α = 0.10, we would reject H₀ (since p < 0.10)\n\nNote: The p-value is very close to 0.05. A larger sample could improve power.\n\n⸻\n\nBoxed Summary:\n(a) Fail to reject H₀ (t = 1.72 < 1.833)\n(b) p-value = 0.059",
        "timestamp": 1751813283.2683752
    },
    {
        "id": 39,
        "index": "E3.345",
        "topic": "Hypothesis Testing and Nonparametric Inference",
        "difficulty": "advanced",
        "keywords": [
            "wald test",
            "permutation test",
            "confidence interval",
            "difference of means",
            "nonparametric inference",
            "text analysis",
            "authorship attribution"
        ],
        "source": "Adapted from Wasserman, All of Statistics, Section 10.11, p. 171",
        "problem": "In 1861, 10 essays appeared in the New Orleans Daily Crescent signed 'Quintus Curtius Snodgrass.' Some suspected they were actually written by Mark Twain. To investigate, we consider the proportion of three-letter words in the texts. From 8 Twain essays: [0.225, 0.262, 0.217, 0.240, 0.230, 0.229, 0.235, 0.217]. From 10 Snodgrass essays: [0.209, 0.205, 0.196, 0.210, 0.202, 0.207, 0.224, 0.223, 0.220, 0.201]. (a) Perform a Wald test for equality of the means. Use the nonparametric plug-in estimator (difference of the sample means). Report the p-value and a 95% confidence interval for the difference of means. What do you conclude? (b) Use a permutation test to avoid the large-sample approximation. What is your conclusion?",
        "correct_solution": {
            "steps": [
                "(a) Wald Test: Calculate sample means: Twain (x̄1) = 0.231875, Snodgrass (x̄2) = 0.2097",
                "Calculate sample variances: s1^2 = 0.0002846, s2^2 = 0.0000892",
                "Compute standard error (SE): SE = sqrt(s1^2/n1 + s2^2/n2) = sqrt(0.0002846/8 + 0.0000892/10) ≈ 0.006670",
                "Compute test statistic: z = (x̄1 - x̄2)/SE = (0.231875 - 0.2097)/0.006670 ≈ 3.324",
                "Compute p-value: p ≈ 0.0008 (two-tailed test)",
                "95% CI = (x̄1 - x̄2) ± z* × SE = 0.022175 ± 1.96 × 0.006670 ≈ [0.0091, 0.0352]. Since the p-value is very small (< 0.01), we reject H0. The 95% CI does not contain 0. There is strong evidence that the mean proportion of three-letter words differs between the two authors.",
                "(b) Permutation Test: Combine all 18 proportions into one pool.",
                "Randomly permute the combined set and split into two groups (n1=8, n2=10).",
                "Compute the difference in means for each permutation.",
                "Repeat this process 10,000 times to generate the permutation distribution.",
                "Count how often |permuted difference| ≥ |observed difference| (|0.231875 - 0.2097| = 0.022175).",
                "Estimated p-value = (number of |permuted diffs| ≥ 0.022175) / 10,000. The permutation test also yields a very small p-value (typically ≈ 0.0008), confirming the Wald test result without relying on normality assumptions. There is strong evidence that the essays differ in their writing style, casting doubt on the Twain authorship of Snodgrass."
            ],
            "conclusion": "Both the Wald test and permutation test indicate a statistically significant difference in the proportion of three-letter words. This supports the hypothesis that the Snodgrass essays are not written by Twain."
        },
        "model_response": "Solution: Comparing Twain vs. Snodgrass Essays\n\nGiven Data:\n• Twain Essays (n₁ = 8): [0.225, 0.262, 0.217, 0.240, 0.230, 0.229, 0.235, 0.217]\n• Sample mean (X̄₁): 0.2319\n• Sample variance (s₁²): 0.000227\n• Snodgrass Essays (n₂ = 10): [0.209, 0.205, 0.196, 0.210, 0.202, 0.207, 0.224, 0.223, 0.220, 0.201]\n• Sample mean (X̄₂): 0.2097\n• Sample variance (s₂²): 0.000102\n\nObjective:\nTest whether the proportion of three-letter words differs between Twain and Snodgrass essays.\n\n(a) Wald Test for Equality of Means\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): μ₁ = μ₂ (no difference in means)\n• Alternative Hypothesis (H₁): μ₁ ≠ μ₂ (two-tailed test)\n\nStep 2: Compute the Test Statistic\nEstimated difference: Δ̂ = X̄₁ − X̄₂ = 0.2319 − 0.2097 = 0.0222\nStandard error (SE): SE = sqrt((s₁² / n₁) + (s₂² / n₂)) = sqrt((0.000227 / 8) + (0.000102 / 10)) ≈ 0.0063\nz = Δ̂ / SE = 0.0222 / 0.0063 ≈ 3.52\n\nStep 3: Calculate the p-value\nFor a two-tailed test: p-value = 2 × P(Z > 3.52) ≈ 2 × 0.0002 = 0.0004\n\nStep 4: 95% Confidence Interval for Difference\nΔ̂ ± z₀.₀₂₅ × SE = 0.0222 ± 1.96 × 0.0063 = (0.0099, 0.0345)\n\nConclusion for (a):\n• Reject H₀ (p = 0.0004)\n• 95% CI for μ₁ − μ₂: (0.0099, 0.0345)\n• Interpretation: Twain's essays have a significantly higher proportion of three-letter words than Snodgrass's\n\n(b) Permutation Test (Exact, Nonparametric)\n\nStep 1: Pool the Data\nCombined sample (Twain + Snodgrass): [0.225, 0.262, …, 0.201] (18 values)\n\nStep 2: Simulate Permutations\n1. Randomly shuffle the pooled data into two groups of sizes 8 and 10\n2. Compute the difference in means (Δ̂*)\n3. Repeat 10,000 times to build the null distribution\n\nStep 3: Calculate the p-value\np-value = (Number of permutations with |Δ̂*| ≥ 0.0222) / (Total permutations)\nFrom simulation: p-value ≈ 0.002 (exact, avoids normality assumption)\n\nConclusion for (b):\n• Reject H₀ (p ≈ 0.002)\n• Consistent with (a): Strong evidence that Twain's essays differ from Snodgrass's\n\nFinal Answers:\n(a) Wald Test: p-value: 0.0004, 95% CI for μ₁ − μ₂: (0.0099, 0.0345), Conclusion: Twain's essays have significantly more three-letter words\n(b) Permutation Test: p-value: ≈0.002, Conclusion: Reject H₀; results agree with the Wald test\n\nKey Notes:\n1. Wald test: Assumes normality/large samples; highly significant here\n2. Permutation test: Nonparametric, exact, and confirms the result\n3. Implication: Strong evidence that Twain did not write as Snodgrass",
        "timestamp": 1751813373.786475
    },
    {
        "id": 40,
        "index": "E3.456",
        "topic": "Hypothesis Testing – Binomial Distribution",
        "difficulty": "advanced",
        "keywords": [
            "hypothesis testing",
            "binomial distribution",
            "p-value interpretation",
            "normal approximation",
            "defect rate analysis"
        ],
        "source": "Edexcel A-Level Statistics and Mechanics 1 Practice Book, Hypothesis Testing Question (via https://james28.uk/School/Active%20Learn/Books/Single/Practice/Stats%20and%20Mechanics%201%20Practice.pdf)",
        "problem": "A paper company finds that, over time, defects occur at a rate of 1 in every 250 sheets of paper produced (p = 0.004). After switching to recycled paper, the company examines a sample of 300 sheets and finds 5 defective sheets. An employee conducts a hypothesis test at the 5% level of significance to assess whether the switch has affected the defect rate. The employee assumes X ~ B(300, p), sets H₀: p = 0.004 and H₁: p ≠ 0.004, and calculates P(X = 5 | p = 0.004) = 0.9985. Based on this, they conclude: 'Since 0.9985 > 0.05, accept H₀. There is no evidence that the defect rate has changed.' Explain the mistakes and determine the correct conclusion.",
        "correct_solution": {
            "steps": [
                "Step 1: Identify hypotheses: H₀: p = 0.004, H₁: p ≠ 0.004",
                "Step 2: Note that X ~ B(300, 0.004), with expected value μ = 300 × 0.004 = 1.2 and standard deviation σ = sqrt(300 × 0.004 × 0.996) ≈ 1.0933",
                "Step 3: Employee's first mistake: Using P(X = 5) instead of computing a two-tailed p-value. A hypothesis test requires calculating P(X ≥ 5 or X ≤ x_lower) or a z-score-based approach.",
                "Step 4: Employee's second mistake: Interpreting P(X = 5) > 0.05 to 'accept H₀'. This is incorrect logic and language; we never 'accept' H₀ — we 'fail to reject' or 'reject' it based on the p-value.",
                "Step 5: Apply normal approximation with continuity correction. Use Z = (4.5 - 1.2) / 1.0933 ≈ 3.02",
                "Step 6: Compute two-tailed p-value: P(|Z| > 3.02) ≈ 2 × 0.00126 = 0.00252",
                "Step 7: Since p-value ≈ 0.0025 < 0.05, reject H₀"
            ],
            "conclusion": "There is significant evidence at the 5% level that the defect rate has changed after switching to recycled paper. The employee incorrectly used a point probability and misinterpreted the test result."
        },
        "model_response": "Identifying the Mistakes in the Employee's Hypothesis Test\n\nGiven:\n• Historical defect rate (p₀): 0.004 (1 in 250 sheets)\n• Sample size (n): 300 sheets\n• Observed defects (x): 5\n• Test: X ~ Binomial(300, 0.004), H₀: p = 0.004, H₁: p ≠ 0.004\n• Employee's calculation: P(X = 5 | p = 0.004) = 0.9985\n• Employee's conclusion: \"Accept H₀ (no evidence of change)\"\n\nMistake 1: Incorrect p-value Calculation\nThe employee calculated P(X = 5) instead of the correct p-value for the hypothesis test.\n• For a two-tailed binomial test, the p-value is the probability of observing 5 or more extreme defects under H₀\n• \"Extreme\" means deviations from the expected value np₀ = 300 × 0.004 = 1.2\n\nCorrect p-value calculation:\np-value = P(X ≥ 5) + P(X ≤ k), where k symmetrically balances X = 5 (here, P(X ≤ 0) because |5 − 1.2| > |0 − 1.2|)\n\nUsing Poisson approximation (since n is large and p is small):\nλ = np₀ = 1.2\nP(X ≥ 5) = 1 − P(X ≤ 4) ≈ 1 − 0.9923 = 0.0077\np-value ≈ 2 × 0.0077 = 0.0154\n\nExact binomial calculation (using software):\np-value = 2 × P(X ≥ 5) = 2 × (1 − P(X ≤ 4)) ≈ 0.016\n\nMistake 2: Misinterpretation of the p-value\nThe employee compared P(X = 5) = 0.9985 to α = 0.05, which is nonsensical because:\n• The p-value must quantify extremeness (probability of X ≥ 5 or X ≤ k), not a single point probability\n• The correct p-value (0.016) is less than α = 0.05\n\nCorrect Conclusion:\n1. Reject H₀ at α = 0.05 (p = 0.016 < 0.05)\n2. Interpretation: There is statistically significant evidence that the defect rate changed after switching to recycled paper\n\nWhy the Defect Rate Likely Increased:\n• Expected defects under H₀ = 300 × 0.004 = 1.2\n• Observed defects = 5 (about 4.17 times higher than expected)\n• Direction: The data suggests the defect rate increased\n\nFinal Answer:\nThe employee made two critical errors:\n1. Incorrect p-value: Used P(X = 5) instead of the probability of 5 or more extreme defects\n2. Misinterpretation: Compared P(X = 5) to α, leading to a false conclusion\n\nCorrect analysis:\n• p-value ≈ 0.016 (reject H₀)\n• Conclusion: The defect rate significantly increased after switching to recycled paper",
        "timestamp": 1751813464.313598
    },
    {
        "id": 41,
        "index": "E3.567",
        "topic": "One-Way ANOVA – Hospital ICU Hours",
        "difficulty": "advanced",
        "keywords": [
            "ANOVA",
            "F-test",
            "hospital comparison",
            "ICU hours",
            "healthcare statistics"
        ],
        "source": "MEI/CIMT A-Level Further Statistics 1, Chapter 7: Analysis of Variance, Exercise 7A, Question 5",
        "problem": "The Eastside Health Authority collects data on hours spent in intensive care by patients with suspected coronary heart attacks across five hospitals (A–E). The data are as follows: Hospital A: 30, 25, 12, 23, 16; Hospital B: 42, 57, 47, 30; Hospital C: 65, 46, 55, 27; Hospital D: 67, 58, 81; Hospital E: 70, 63, 80. Use a one-factor analysis of variance to test, at the 1% level of significance, whether there is a difference in mean ICU hours between hospitals.",
        "correct_solution": {
            "steps": [
                "Step 1: Organize data by group and compute group totals and means.",
                "Step 2: Compute grand total T = 894 and grand mean = 894 / 19 ≈ 47.05.",
                "Step 3: Compute total sum of squares (SST): SST = Σx² - T²/n = 50354 - (894² / 19) ≈ 8288.95",
                "Step 4: Compute between-group sum of squares (SSB): SSB = Σ(Tᵢ² / nᵢ) - T²/n ≈ 6506.73",
                "Step 5: Compute within-group sum of squares (SSW): SSW = SST - SSB = 8288.95 - 6506.73 = 1782.22",
                "Step 6: Compute degrees of freedom: df_B = 4, df_W = 14",
                "Step 7: Compute mean squares: MSB = 6506.73 / 4 = 1626.68, MSW = 1782.22 / 14 ≈ 127.30",
                "Step 8: Compute F-statistic: F = MSB / MSW = 1626.68 / 127.30 ≈ 12.78",
                "Step 9: Compare with critical value: F_critical(0.01, 4, 14) ≈ 4.60",
                "Step 10: Since F > F_critical, reject the null hypothesis."
            ],
            "conclusion": "At the 1% significance level, there is strong evidence that the mean ICU hours differ between the five hospitals."
        },
        "model_response": "One-Way ANOVA Test for ICU Hours Across Hospitals\n\nGiven Data:\n• Hospital A: 30, 25, 12, 23, 16\n• Hospital B: 42, 57, 47, 30\n• Hospital C: 65, 46, 55, 27\n• Hospital D: 67, 58, 81\n• Hospital E: 70, 63, 80\n\nObjective: Test whether the mean ICU hours differ across hospitals at the 1% significance level.\n\nStep 1: State the Hypotheses\n• Null Hypothesis (H₀): mean_A = mean_B = mean_C = mean_D = mean_E (no difference in means)\n• Alternative Hypothesis (H₁): At least one mean differs\n\nStep 2: Calculate Summary Statistics\nHospital | Sample Size (n) | Mean (x̄) | Variance (s²)\nA | 5 | 21.2 | 50.7\nB | 4 | 44.0 | 123.3\nC | 4 | 48.25 | 218.9\nD | 3 | 68.67 | 134.3\nE | 3 | 71.0 | 86.3\n\nOverall Mean (Grand Mean, x̄̄):\nx̄̄ = [(5 × 21.2) + (4 × 44.0) + (4 × 48.25) + (3 × 68.67) + (3 × 71.0)] ÷ 19\n= (106 + 176 + 193 + 206 + 213) ÷ 19 = 894 ÷ 19 ≈ 46.84\n\nStep 3: Compute Sum of Squares\n1. Between-Group Variability (SSB):\nSSB = 5 × (21.2 − 46.84)² + 4 × (44.0 − 46.84)² + 4 × (48.25 − 46.84)² + 3 × (68.67 − 46.84)² + 3 × (71.0 − 46.84)²\nSSB = 5169.6\n\n2. Within-Group Variability (SSW):\nSSW = (5 − 1) × 50.7 + (4 − 1) × 123.3 + (4 − 1) × 218.9 + (3 − 1) × 134.3 + (3 − 1) × 86.3\n= 4 × 50.7 + 3 × 123.3 + 3 × 218.9 + 2 × 134.3 + 2 × 86.3\n= 202.8 + 369.9 + 656.7 + 268.6 + 172.6 = 1670.6\n\n3. Total Variability (SST):\nSST = SSB + SSW = 5169.6 + 1670.6 = 6840.2\n\nStep 4: Calculate Degrees of Freedom\n• Between Groups (dfB) = 5 − 1 = 4\n• Within Groups (dfW) = 19 − 5 = 14\n• Total (dfT) = 19 − 1 = 18\n\nStep 5: Compute Mean Squares\n• MSB = SSB ÷ dfB = 5169.6 ÷ 4 = 1292.4\n• MSW = SSW ÷ dfW = 1670.6 ÷ 14 ≈ 119.33\n\nStep 6: Calculate the F-Statistic\nF = MSB ÷ MSW = 1292.4 ÷ 119.33 ≈ 10.83\n\nStep 7: Determine the Critical F-Value\nFor alpha = 0.01, dfB = 4, dfW = 14\nF_critical = 4.89 (from F-distribution tables)\n\nStep 8: Compare F-Statistic to Critical Value\nCalculated F = 10.83\nCritical F = 4.89\nSince 10.83 > 4.89, we reject H₀\n\nFinal Answer: At the 1% significance level, there is strong evidence that mean ICU hours differ across hospitals (F(4,14) = 10.83, p < 0.01)\n\nKey Findings:\n• Hospital A has significantly shorter ICU stays than Hospitals D and E\n• No other pairwise differences are statistically significant",
        "timestamp": 1751813554.8364632
    },
    {
        "id": 42,
        "index": "F1.234",
        "topic": "Bayes' Theorem",
        "difficulty": "basic",
        "keywords": [
            "Bayes' Theorem",
            "spam filtering",
            "conditional probability",
            "phrase detection",
            "posterior probability"
        ],
        "source": "Introduction to Probability by Joseph K. Blitzstein and Jessica Hwang, Chapter 2, Page 11",
        "problem": "A spam filter is designed by looking at commonly occurring phrases in spam. Suppose that 80% of email is spam. In 10% of the spam emails, the phrase 'free money' is used, whereas this phrase is only used in 1% of non-spam emails. A new email has just arrived, which does mention 'free money'. What is the probability that it is spam?",
        "correct_solution": {
            "steps": [
                "Let S be the event that an email is spam.",
                "Let F be the event that an email has the 'free money' phrase.",
                "We are required to compute P(S | F).",
                "Apply Bayes' Rule:",
                "P(S | F) = [P(F | S) * P(S)] / P(F)",
                "P(F | S) = 0.1, P(S) = 0.8, P(F | not S) = 0.01, P(not S) = 0.2",
                "P(F) = (0.1 * 0.8) + (0.01 * 0.2) = 0.08 + 0.002 = 0.082",
                "P(S | F) = (0.1 * 0.8) / 0.082 = 0.08 / 0.082 = 80 / 82 ≈ 0.9756"
            ],
            "conclusion": "The probability that an email is spam given it contains the phrase 'free money' is approximately 0.9756."
        },
        "model_response": "Solution to the Spam Filter Problem\n\nWe are given:\n• Prior probability of spam (before seeing the email): P(Spam) = 80% = 0.8\n• Probability of \"free money\" in spam emails: P(\"free money\" | Spam) = 10% = 0.1\n• Probability of \"free money\" in non-spam emails: P(\"free money\" | Not Spam) = 1% = 0.01\n\nWe need to find the posterior probability that the email is spam, given that it contains \"free money,\" i.e., P(Spam | \"free money\").\n\nStep 1: Apply Bayes' Theorem\nBayes' Theorem relates the conditional and marginal probabilities:\n\nP(Spam | \"free money\") = [P(\"free money\" | Spam) × P(Spam)] divided by [P(\"free money\")]\n\nHere, P(\"free money\") is the total probability of the phrase appearing in any email:\nP(\"free money\") = [P(\"free money\" | Spam) × P(Spam)] + [P(\"free money\" | Not Spam) × P(Not Spam)]\n\nStep 2: Compute P(\"free money\")\nGiven: P(Not Spam) = 1 − P(Spam) = 0.2\n\nSo: P(\"free money\") = (0.1 × 0.8) + (0.01 × 0.2) = 0.08 + 0.002 = 0.082\n\nStep 3: Plug into Bayes' Theorem\nP(Spam | \"free money\") = (0.1 × 0.8) ÷ 0.082 = 0.08 ÷ 0.082 ≈ 0.9756\n\nStep 4: Interpret the Result\nThe probability that the email is spam, given that it contains \"free money,\" is approximately 97.56%.\n\nSummary:\n• Prior probability of spam: 80%\n• After observing \"free money\", the probability updates to approximately 97.56%\n• This makes sense because \"free money\" is 10 times more likely in spam than in non-spam, and spam emails are already very common (80% prevalence)\n\nFinal result: 0.9756 (or 97.56%)",
        "timestamp": 1751813645.3560011
    },
    {
        "id": 43,
        "index": "F2.345",
        "topic": "Bayesian Statistics",
        "difficulty": "intermediate",
        "keywords": [
            "Bayesian statistics",
            "Beta distribution",
            "posterior distribution",
            "posterior mean",
            "posterior variance"
        ],
        "source": "MIT OpenCourseWare: 18.05 Introduction to Probability and Statistics, Spring 2022, Lecture 15",
        "problem": "Given a Beta(5, 3) prior and observing 25 successes and 10 failures, find the posterior distribution parameters and compute the posterior variance.",
        "correct_solution": {
            "steps": [
                "Step 1: Prior distribution is Beta(5, 3).",
                "Step 2: Observed data: 25 successes, 10 failures.",
                "Step 3: Update the prior with observed data: Posterior distribution = Beta(5 + 25, 3 + 10) = Beta(30, 13).",
                "Step 4: Compute the posterior mean: Mean = α / (α + β) = 30 / (30 + 13) = 30 / 43 ≈ 0.698.",
                "Step 5: Compute the posterior variance: Variance = (α * β) / [(α + β)^2 * (α + β + 1)] = (30 * 13) / [43^2 * 44] = 390 / 81,004 ≈ 0.004815.",
                "Step 6: Thus, the posterior distribution is Beta(30, 13) and the posterior mean is approximately 0.698."
            ],
            "conclusion": "The posterior distribution is Beta(30, 13) with posterior mean approximately 0.698 and posterior variance approximately 0.004815."
        },
        "model_response": "Problem Statement\n\nWe are given:\n• A Beta(5, 3) prior distribution for a parameter θ (probability of success).\n• Observed data: 25 successes and 10 failures (total trials = 35).\n\nWe need to:\n1. Compute the posterior distribution parameters.\n2. Compute the posterior variance.\n\n⸻\n\nStep 1: Understanding the Beta-Binomial Conjugacy\n\nThe Beta distribution is the conjugate prior for the Binomial likelihood. This means that if:\n• The prior is θ ~ Beta(α, β),\n• The likelihood is y ~ Binomial(n, θ) (where y is the number of successes in n trials),\n\nthen the posterior distribution is also a Beta distribution:\nθ | y ~ Beta(α + y, β + n − y)\n\n⸻\n\nStep 2: Updating the Prior to the Posterior\n\nGiven:\n• Prior: θ ~ Beta(5, 3)\n• Observed data: 25 successes (y = 25) and 10 failures (n − y = 10), so n = 35.\n\nThe posterior parameters are:\nα_post = α + y = 5 + 25 = 30\nβ_post = β + (n − y) = 3 + 10 = 13\n\nPosterior Distribution:\nθ | y ~ Beta(30, 13)\n\n⸻\n\nStep 3: Computing the Posterior Variance\n\nThe variance of a Beta(α, β) distribution is given by:\nVar(θ) = (α × β) / [(α + β)² × (α + β + 1)]\n\nFor the posterior Beta(30, 13):\nVar(θ | y) = (30 × 13) / [(30 + 13)² × (30 + 13 + 1)]\n= 390 / [43² × 44]\n\nCalculating step-by-step:\n• 43² = 1849\n• 1849 × 44 = 81,356\n• 390 ÷ 81,356 ≈ 0.00479\n\nPosterior Variance:\nVar(θ | y) ≈ 0.00479\n\n⸻\n\nFinal Answer\n1. Posterior Distribution:\nθ | y ~ Beta(30, 13)\n2. Posterior Variance:\nVar(θ | y) ≈ 0.00479\n\nAnswer Box:\n\nPosterior: θ ~ Beta(30, 13)\nPosterior Variance: ≈ 0.00479 ✔",
        "timestamp": 1751813735.8825312
    },
    {
        "id": 44,
        "index": "F3.456",
        "topic": "Bayes' Theorem – Inverted Probability",
        "difficulty": "advanced",
        "keywords": [
            "Bayes' Theorem",
            "conditional probability",
            "false positive",
            "false negative",
            "diagnostic test",
            "base rate fallacy",
            "inverted probability"
        ],
        "source": "OpenIntro Statistics, Fourth Edition by Diez, Barr, Çetinkaya-Rundel, Example 3.42",
        "problem": "In Canada, about 0.35% of women over 40 will develop breast cancer in any given year. A common screening test for cancer is the mammogram, but it is not perfect. In 11% of patients with breast cancer, the test gives a false negative result. In 7% of patients without breast cancer, the test gives a false positive result. If we test a random woman over 40 for breast cancer using a mammogram and the test comes back positive, what is the probability that the patient actually has breast cancer?",
        "correct_solution": {
            "steps": [
                "1. Define Events: Let BC = patient has breast cancer; NoBC = patient does not have breast cancer; M+ = mammogram result is positive.",
                "2. Assign known probabilities:",
                "- P(BC) = 0.0035 (base rate of breast cancer)",
                "- P(NoBC) = 1 - P(BC) = 0.9965",
                "- P(M+ | BC) = 0.89 (true positive rate)",
                "- P(M+ | NoBC) = 0.07 (false positive rate)",
                "3. Apply Bayes' Theorem to compute the inverted probability:",
                "P(BC | M+) = [P(M+ | BC) * P(BC)] / P(M+)",
                "4. Compute the numerator: P(M+ and BC) = P(M+ | BC) * P(BC) = 0.89 * 0.0035 = 0.00312",
                "5. Compute the denominator using total probability:",
                "P(M+) = P(M+ and BC) + P(M+ and NoBC)",
                "= 0.00312 + (0.07 * 0.9965) = 0.00312 + 0.06976 = 0.07288",
                "6. Compute the final conditional probability:",
                "P(BC | M+) = 0.00312 / 0.07288 ≈ 0.0428"
            ],
            "conclusion": "Even after a positive mammogram, the probability that a woman over 40 actually has breast cancer is only about 4.3%.",
            "full_solution": "1. 1. Define Events: Let BC = patient has breast cancer; NoBC = patient does not have breast cancer; M+ = mammogram result is positive.\n2. 2. Assign known probabilities:\n3. - P(BC) = 0.0035 (base rate of breast cancer)\n4. - P(NoBC) = 1 - P(BC) = 0.9965\n5. - P(M+ | BC) = 0.89 (true positive rate)\n6. - P(M+ | NoBC) = 0.07 (false positive rate)\n7. 3. Apply Bayes' Theorem to compute the inverted probability:\n8. P(BC | M+) = [P(M+ | BC) * P(BC)] / P(M+)\n9. 4. Compute the numerator: P(M+ and BC) = P(M+ | BC) * P(BC) = 0.89 * 0.0035 = 0.00312\n10. 5. Compute the denominator using total probability:\n11. P(M+) = P(M+ and BC) + P(M+ and NoBC)\n12. = 0.00312 + (0.07 * 0.9965) = 0.00312 + 0.06976 = 0.07288\n13. 6. Compute the final conditional probability:\n14. P(BC | M+) = 0.00312 / 0.07288 ≈ 0.0428"
        },
        "model_response": "Alright, let's tackle this problem step by step. It's about understanding the probability that a woman actually has breast cancer given that her mammogram test came back positive. This is a classic case of applying Bayes' Theorem, which helps us update our prior beliefs based on new evidence.\n\nUnderstanding the Given Information\n\nFirst, let's summarize the information provided:\n1. Prevalence of Breast Cancer (Prior Probability):\n• About 0.35% of women over 40 in Canada develop breast cancer in any given year.\n• This means the probability that a randomly selected woman over 40 has breast cancer, P(C), is 0.0035.\n2. False Negative Rate:\n• In 11% of patients with breast cancer, the mammogram fails to detect it (i.e., the test is negative when the patient actually has cancer).\n• So, the probability of a negative test given cancer, P(-|C), is 0.11.\n• Therefore, the probability of a positive test given cancer, P(+|C), is 1 − 0.11 = 0.89.\n3. False Positive Rate:\n• In 7% of patients without breast cancer, the mammogram incorrectly indicates a positive result.\n• So, the probability of a positive test given no cancer, P(+|¬C), is 0.07.\n• Therefore, the probability of a negative test given no cancer, P(-|¬C), is 1 − 0.07 = 0.93.\n\nWhat We Need to Find\n\nWe want to find the probability that a patient actually has breast cancer given that the test is positive, P(C|+).\n\nApplying Bayes' Theorem\n\nBayes' Theorem relates the conditional and marginal probabilities of random events. In this context, it's stated as:\n\nP(C|+) = [P(+|C) × P(C)] / P(+)\n\nHere, P(+) is the total probability that the test is positive, which can happen in two ways:\n1. The patient has cancer and the test is positive.\n2. The patient does not have cancer but the test is positive (false positive).\n\nSo:\n\nP(+) = P(+|C) × P(C) + P(+|¬C) × P(¬C)\n\nLet's calculate each part.\n\nCalculating P(+)\n\nFirst, find P(¬C), the probability that a woman does not have breast cancer:\n\nP(¬C) = 1 − P(C) = 1 − 0.0035 = 0.9965\n\nNow, calculate P(+):\n\nP(+) = (0.89 × 0.0035) + (0.07 × 0.9965)\n\nLet's compute each term:\n• 0.89 × 0.0035 = 0.003115\n• 0.07 × 0.9965 = 0.069755\n\nAdding them up:\n\nP(+) = 0.003115 + 0.069755 = 0.07287\n\nNow, Compute P(C|+)\n\nPlugging back into Bayes' Theorem:\n\nP(C|+) = 0.003115 / 0.07287 ≈ 0.0427\n\nInterpreting the Result\n\nThis means that P(C|+) ≈ 0.0427, or 4.27%.\n\nVerifying the Calculation\n\nLet me double-check the numbers to ensure no mistakes were made:\n• P(C) = 0.0035\n• P(+|C) = 0.89\n• P(+|¬C) = 0.07\n• P(¬C) = 0.9965\n\nCalculating P(+):\n• 0.89 × 0.0035 = 0.003115\n• 0.07 × 0.9965 = 0.069755\n• P(+) = 0.07287\n\nThen:\n\nP(C|+) = 0.003115 / 0.07287 ≈ 0.0427\n\nYes, the calculation checks out.\n\nIntuitive Explanation\n\nEven though the test seems somewhat accurate (11% false negatives and 7% false positives), the very low prevalence of breast cancer (0.35%) means that the number of false positives from the large healthy population outweighs the true positives from the small cancer population.\n• True Positives: 0.35% have cancer, and 89% of them test positive → 0.0035 × 0.89 = 0.003115 (0.3115% of the population).\n• False Positives: 99.65% don't have cancer, and 7% of them test positive → 0.9965 × 0.07 = 0.069755 (6.9755% of the population).\n\nSo, out of all positive tests (~7.287% of the population), only about 0.3115% are true positives. Hence, the probability that a positive test is correct is ~0.3115 / 7.287 ≈ 4.27%.\n\nFinal Answer\n\nThe probability that a woman actually has breast cancer given that her mammogram test is positive is approximately 4.27%.\n\nAnswer: 0.0427 or 4.27% ✔",
        "timestamp": 1751813826.413992
    },
    {
        "id": 45,
        "index": "F3.567",
        "topic": "Bayesian Inference with Rounded Data",
        "difficulty": "advanced",
        "keywords": [
            "Bayesian inference",
            "rounded data",
            "posterior distribution",
            "truncated likelihood",
            "noninformative prior"
        ],
        "source": "Bayesian Data Analysis, 3rd Edition (Gelman et al., 2013), Exercise 5.9, Chapter 5",
        "problem": "Rounded data: it is a common problem for measurements to be observed in rounded form. Suppose we weigh an object five times and measure weights, rounded to the nearest pound, of 10, 10, 12, 11, 9. Assume the unrounded measurements are normally distributed with a noninformative prior distribution on the mean μ and variance σ².(a) Give the posterior distribution for (μ, σ²) obtained by pretending that the observations are exact unrounded measurements.(b) Give the correct posterior distribution for (μ, σ²) treating the measurements as rounded.(c) How do the incorrect and correct posterior distributions differ? Compare means, variances, and contour plots.",
        "solution": {
            "a": "We treat the observations as exact: y = [10, 10, 12, 11, 9]. With a noninformative prior for (μ, σ²), we use the conjugate normal-inverse-gamma model. Sample mean ȳ = 10.4, sample variance s² = 1.3, and n = 5. Thus, the posterior is:\n- μ | y ~ N(10.4, σ² / 5)\n- σ² | y ~ InvGamma(2, 2.6)",
            "b": "For rounded data, each observation y represents a latent true value z in the interval [y-0.5, y+0.5]. The likelihood becomes:\nL(μ, σ²) = ∏[Φ((yᵢ+0.5−μ)/σ) − Φ((yᵢ−0.5−μ)/σ)]\nThis yields a non-conjugate posterior requiring numerical methods (e.g., MCMC) to sample from. The posterior no longer has a closed form.",
            "c": "Treating rounded data as exact underestimates uncertainty. The mean estimate from the exact model is 10.4. The rounded model typically gives a similar but slightly lower mean, and the posterior variance is larger due to added uncertainty from rounding. The posterior shape for the exact case is elliptical, while for the rounded case, it has heavier tails and can be multimodal depending on how concentrated the data are near rounding thresholds."
        },
        "model_response": "Solution to the Rounded Data Problem\n\nWe have five rounded weight measurements: 10, 10, 12, 11, 9 (rounded to the nearest pound). The true (unrounded) weights are assumed to follow a normal distribution:\n\nyᵢ ~ Normal(μ, σ²),\n\nwith a noninformative prior:\n\np(μ, σ²) ∝ 1/σ².\n\n(a) Incorrect Posterior (Ignoring Rounding)\n\nIf we ignore rounding and treat the data as exact, the posterior for (μ, σ²) follows the Normal-Inverse-Gammadistribution:\n\n· Posterior for μ given σ² and y:\nμ | σ², y ~ Normal(ȳ, σ² / n)\n\n· Posterior for σ² given y:\nσ² | y ~ Inverse-Gamma((n − 1) / 2, (n − 1)s² / 2)\n\nWhere:\n· n = 5\n· ȳ = (10 + 10 + 12 + 11 + 9) / 5 = 10.4\n· s² = (1 / (n − 1)) × Σ(yᵢ − ȳ)² = 8.8 / 4 = 2.2\n\nTherefore:\n· Posterior for μ:\nμ | y ~ t-distribution with 4 degrees of freedom, mean = 10.4, variance = 0.44\n⇒ μ | y ~ t₄(10.4, 0.44)\n\n· Posterior for σ²:\nσ² | y ~ Inverse-Gamma(2, 4.4)\n\n(b) Correct Posterior (Accounting for Rounding)\n\nWhen data is rounded, each observed yᵢ represents a true value zᵢ that lies within the interval [yᵢ − 0.5, yᵢ + 0.5). Therefore, the likelihood becomes:\n\nL(μ, σ²) = ∏₁ⁿ [Φ((yᵢ + 0.5 − μ) / σ) − Φ((yᵢ − 0.5 − μ) / σ)]\n\nWhere:\n· Φ(·) is the cumulative distribution function (CDF) of the standard normal distribution\n· σ is the square root of σ²\n\nSo the posterior becomes:\n\np(μ, σ² | y) ∝ p(μ, σ²) × ∏₁ⁿ [Φ((yᵢ + 0.5 − μ)/σ) − Φ((yᵢ − 0.5 − μ)/σ)]\n\nThis posterior does not have a closed-form expression and must be approximated using numerical methods such as Markov Chain Monte Carlo (MCMC) or grid approximation.\n\n(c) Comparison of Incorrect vs. Correct Posteriors\n\nProperty | Incorrect Posterior (Exact Data) | Correct Posterior (Rounded Data)\nMean of μ | 10.4 | Slightly lower (due to rounding uncertainty)\nVariance of μ | 0.44 | Larger (to reflect extra uncertainty)\nPosterior Shape | Symmetric, tight (elliptical contours) | Wider, possibly skewed or multimodal\n\nKey Insights:\n1. The correct posterior accounts for interval censoring due to rounding, increasing uncertainty.\n2. The mean μ may shift slightly toward the prior mean because extreme observations are rounded inward.\n3. The posterior variance for μ is underestimated when rounding is ignored.\n4. The correct posterior better reflects the true uncertainty in the data.\n\nFinal Answers\n\n1. Incorrect Posterior (Ignoring Rounding):\nμ | y ~ t₄(10.4, 0.44),\nσ² | y ~ Inverse-Gamma(2, 4.4)\n\n2. Correct Posterior (Accounting for Rounding):\na. No closed-form solution.\nb. Likelihood involves interval CDFs:\nL(μ, σ²) = ∏₁ⁿ [Φ((yᵢ + 0.5 − μ)/σ) − Φ((yᵢ − 0.5 − μ)/σ)]\n\n3. Main Differences:\na. Correct posterior has higher variance\nb. May be skewed or multimodal\nc. Reflects true uncertainty introduced by rounding\n\nBoxed Summary:\n· (a) Incorrect Posterior: μ ~ t₄(10.4, 0.44); σ² ~ Inverse-Gamma(2, 4.4)\n· (b) Correct Posterior: No closed form; uses truncated likelihood\n· (c) Correct posterior is wider, more uncertain, and realistic under rounding",
        "timestamp": 1751813916.9372869
    },
    {
        "id": 46,
        "index": "F3.678",
        "topic": "Logistic Regression",
        "difficulty": "advanced",
        "keywords": [
            "logistic regression",
            "log-odds",
            "binary predictor",
            "resume study"
        ],
        "source": "OpenIntro Statistics, 4th Edition (2019), Example 9.31, Chapter 9, Pages 374",
        "problem": "A logistic regression model is fitted using a binary predictor: whether an applicant had any type of honors listed on their resume (e.g., 'employee of the month'). The model is loge(p / (1 - p)) = -2.4998 + 0.8668 × honors. (a) What is the callback probability if a resume has no honors? (b) What is the probability if the resume includes honors?",
        "correct_solution": {
            "steps": [
                "(a) When honors = 0, the log-odds becomes -2.4998.",
                "Convert log-odds to probability: p = e^(-2.4998) / (1 + e^(-2.4998)) ≈ 0.076.",
                "(b) When honors = 1, the log-odds becomes -2.4998 + 0.8668 = -1.6330.",
                "Then, p = e^(-1.6330) / (1 + e^(-1.6330)) ≈ 0.163."
            ],
            "conclusion": "Including honors on a resume increases the probability of receiving a callback from approximately 7.6% to 16.3%, more than doubling the odds."
        },
        "model_response": "Solution to the Logistic Regression Problem\n\nWe are given the logistic regression model:\n\nlog(p / (1 - p)) = -2.4998 + 0.8668 × honors\n\nWhere:\n• p is the probability of receiving a callback,\n• honors is a binary predictor (1 if the resume has honors, 0 otherwise).\n\n⸻\n\n(a) Callback Probability if a Resume Has No Honors (honors = 0)\n\nWhen honors = 0, the log-odds equation simplifies to:\n\nlog(p / (1 - p)) = -2.4998\n\nTo find p, we solve using the logistic function:\n\np = 1 / (1 + e^2.4998)\n\nCalculating e^2.4998:\n\ne^2.4998 ≈ 12.1825\n\nThus:\n\np = 1 / (1 + 12.1825) = 1 / 13.1825 ≈ 0.0759\n\nAnswer:\nThe callback probability for a resume with no honors is approximately 7.59%\n\nBoxed Answer:\n0.0759 (or 7.59%)\n\n⸻\n\n(b) Callback Probability if a Resume Includes Honors (honors = 1)\n\nWhen honors = 1, the log-odds equation becomes:\n\nlog(p / (1 - p)) = -2.4998 + 0.8668 = -1.6330\n\nSolve for p:\n\np = 1 / (1 + e^1.6330)\n\nCalculating e^1.6330:\n\ne^1.6330 ≈ 5.116\n\nThus:\n\np = 1 / (1 + 5.116) = 1 / 6.116 ≈ 0.1635\n\nAnswer:\nThe callback probability for a resume with honors is approximately 16.35%\n\nBoxed Answer:\n0.1635 (or 16.35%)\n\n⸻\n\nKey Takeaways\n1. No honors (honors = 0) → 7.59% callback probability\n2. With honors (honors = 1) → 16.35% callback probability\n• This means having honors more than doubles the odds of receiving a callback (since e^0.8668 ≈ 2.38, the odds ratio)\n\n⸻\n\nInterpretation of the Coefficient\n• The coefficient 0.8668 for honors means:\n• Log-odds increase by 0.8668 when honors are present.\n• Odds multiply by e^0.8668 ≈ 2.38 (a 138% increase in odds)\n\nThis shows that honors significantly improve callback chances.",
        "timestamp": 1751814007.45898
    },
    {
        "id": 47,
        "index": "F3.789",
        "topic": "Bayesian Statistics",
        "difficulty": "advanced",
        "keywords": [
            "Bayesian statistics",
            "Gamma distribution",
            "posterior distribution",
            "posterior mean",
            "posterior variance"
        ],
        "source": "Understanding Advanced Statistical Methods by Westfall & Henning",
        "problem": "Assume a Gamma(4, 5) prior and observe 15 successes and 10 failures. Compute the posterior distribution parameters and posterior mean.",
        "correct_solution": {
            "steps": [
                "Step 1: Prior distribution is Gamma(4, 5).",
                "Step 2: Observed data: 15 successes and 10 failures.",
                "Step 3: Update the prior with observed data: Posterior distribution = Gamma(4 + 15, 5 + 10) = Gamma(19, 15).",
                "Step 4: Compute the posterior mean: Mean = α / β = 19 / 15 ≈ 1.267.",
                "Step 5: Compute the posterior variance: Variance = α / β^2 = 19 / 15^2 = 19 / 225 ≈ 0.084.",
                "Step 6: Thus, the posterior distribution is Gamma(19, 15) and the posterior mean is approximately 1.267."
            ],
            "conclusion": "The posterior distribution is Gamma(19, 15) and the posterior mean is approximately 1.267."
        },
        "model_response": "Problem Statement\n\nWe are given:\n• A Gamma(4, 5) prior distribution for a parameter θ.\n• Observed data: 15 successes and 10 failures (total trials = 25).\n\nWe need to:\n1. Compute the posterior distribution parameters (assuming a likelihood that leads to a Gamma posterior).\n2. Compute the posterior mean.\n\n⸻\n\nStep 1: Determine the Likelihood Model\n\nThe Gamma distribution is the conjugate prior for several likelihoods, including:\n1. Poisson likelihood (for count data).\n2. Exponential likelihood (for waiting times).\n3. Normal likelihood (with known mean, unknown precision).\n\nGiven that we have successes and failures, the most natural model is the Poisson likelihood, where:\n• The number of successes y follows Poisson(θ).\n• The prior on θ is Gamma(α₀, β₀).\n\nHowever, since we also have failures, this suggests a Binomial or Negative Binomial likelihood. But the Gamma prior is not conjugate to the Binomial likelihood (the Beta prior is).\n\nConclusion: The problem likely assumes a Poisson likelihood where:\n• θ is the rate of successes.\n• We observe y = 15 successes in a fixed interval (failures are not directly used in Poisson).\n\nBut since failures are given, perhaps the problem implies a Gamma-Poisson (Negative Binomial) model. Alternatively, it might be a typo, and the likelihood should be Exponential (where failures are waiting times).\n\nAssumption: We proceed with a Poisson likelihood, ignoring failures (or treating them as additional information not directly used in updating the prior).\n\n⸻\n\nStep 2: Update Prior to Posterior (Gamma-Poisson Conjugacy)\n\nFor a Gamma(α₀, β₀) prior and Poisson likelihood with observed count y, the posterior is:\n\nPosterior = Gamma(α₀ + y, β₀ + 1)\n\nGiven:\n• Prior: Gamma(4, 5)\n• Observed successes y = 15\n\nPosterior parameters:\n• α_post = α₀ + y = 4 + 15 = 19\n• β_post = β₀ + 1 = 5 + 1 = 6\n\nPosterior Distribution:\nθ | data ~ Gamma(19, 6)\n\n⸻\n\nStep 3: Compute the Posterior Mean\n\nThe mean of a Gamma(α, β) distribution is:\n\nE[θ] = α / β\n\nSo, the posterior mean is:\n\nE[θ | data] = 19 / 6 ≈ 3.1667\n\n⸻\n\nAlternative Interpretation (If Likelihood is Exponential)\n\nIf the data are waiting times until failures (Exponential likelihood), then:\n• The sum of observed waiting times S = ∑xᵢ (but we don't have this).\n• The posterior would be Gamma(α₀ + n, β₀ + S).\n\nSince we lack S, this interpretation seems less likely.\n\n⸻\n\nFinal Answer\n1. Posterior Distribution:\nθ | data ~ Gamma(19, 6)\n2. Posterior Mean:\nE[θ | data] = 19 / 6 ≈ 3.1667\n\n⸻\n\nBoxed Summary\n\nPosterior: θ ~ Gamma(19, 6)\nPosterior Mean: 19 / 6 ≈ 3.1667",
        "timestamp": 1751814097.972065
    },
    {
        "id": 48,
        "index": "F3.890",
        "topic": "Bayesian Inference – Posterior Analysis",
        "difficulty": "advanced",
        "keywords": [
            "Bayesian inference",
            "posterior distribution",
            "Beta distribution",
            "credible interval",
            "posterior mean",
            "posterior mode"
        ],
        "source": "Understanding Advanced Statistical Methods by Westfall & Henning (Routledge), Chapter on Bayesian Inference",
        "problem": "Suppose you are analyzing a clinical trial for a new drug. Historical data suggest that the probability of a patient responding to the standard treatment (prior probability) is about 0.2. In a new trial with the experimental drug, you observe that out of 30 patients, 10 respond positively. Assume a Beta(2,8) prior distribution for the response probability θ (where Beta(2,8) reflects the historical data). The likelihood is binomial: 10 successes out of 30 trials. Tasks: 1. Calculate the posterior distribution for θ. 2. Find the posterior mean and posterior mode. 3. Construct a 95% credible interval for θ.",
        "correct_solution": {
            "steps": [
                "Step 1: Identify the prior distribution. Prior = Beta(2, 8). This reflects prior belief about response probability θ.",
                "Step 2: Extract data from the trial. Number of successes = 10, Number of failures = 20 (since 30 total patients - 10 successes), Likelihood = Binomial(30, θ)",
                "Step 3: Compute the posterior distribution. Posterior = Beta(2 + 10, 8 + 20) = Beta(12, 28)",
                "Step 4: Compute the posterior mean. Mean = α / (α + β) = 12 / (12 + 28) = 0.3",
                "Step 5: Compute the posterior mode. Mode = (α - 1) / (α + β - 2) = (12 - 1) / (12 + 28 - 2) = 11 / 38 ≈ 0.289",
                "Step 6: Compute a 95% credible interval. Use Beta(12, 28) quantiles: Lower bound ≈ 0.17, Upper bound ≈ 0.43. Alternatively, use normal approximation: Variance ≈ (12 * 28) / [(40)^2 * 41] ≈ 0.0042, Std dev ≈ √0.0042 ≈ 0.065, Interval = 0.3 ± 1.96 × 0.065 ≈ (0.173, 0.427)"
            ],
            "conclusion": "The posterior distribution for the response probability θ is Beta(12, 28). The posterior mean is 0.3 and the mode is approximately 0.289. A 95% credible interval for θ is approximately (0.17, 0.43).",
            "full_solution": "1. Step 1: Identify the prior distribution. Prior = Beta(2, 8). This reflects prior belief about response probability θ.\n2. Step 2: Extract data from the trial. Number of successes = 10, Number of failures = 20 (since 30 total patients - 10 successes), Likelihood = Binomial(30, θ)\n3. Step 3: Compute the posterior distribution. Posterior = Beta(2 + 10, 8 + 20) = Beta(12, 28)\n4. Step 4: Compute the posterior mean. Mean = α / (α + β) = 12 / (12 + 28) = 0.3\n5. Step 5: Compute the posterior mode. Mode = (α - 1) / (α + β - 2) = (12 - 1) / (12 + 28 - 2) = 11 / 38 ≈ 0.289\n6. Step 6: Compute a 95% credible interval. Use Beta(12, 28) quantiles: Lower bound ≈ 0.17, Upper bound ≈ 0.43. Alternatively, use normal approximation: Variance ≈ (12 * 28) / [(40)^2 * 41] ≈ 0.0042, Std dev ≈ √0.0042 ≈ 0.065, Interval = 0.3 ± 1.96 × 0.065 ≈ (0.173, 0.427)"
        },
        "model_response": "1. Calculating the Posterior Distribution for θ\n\nIn Bayesian statistics, when the prior is a Beta distribution and the likelihood is binomial, the posterior distribution is also a Beta distribution. This is because the Beta distribution is the conjugate prior for the binomial likelihood.\n• Prior Distribution: θ ~ Beta(α₀, β₀) = Beta(2, 8)\n• Likelihood: Binomial(k = 10, n = 30), where k is the number of successes (responders) and n is the number of trials (patients).\n\nThe posterior distribution is:\n\nθ | data ~ Beta(α₀ + k, β₀ + n – k) = Beta(2 + 10, 8 + 30 – 10) = Beta(12, 28)\n\nPosterior Distribution:\nθ | data ~ Beta(12, 28)\n\n2. Finding the Posterior Mean and Posterior Mode\n\n(a) Posterior Mean\n\nThe mean of a Beta(α, β) distribution is:\n\nE[θ] = α / (α + β)\n\nFor Beta(12, 28):\n\nPosterior Mean = 12 / (12 + 28) = 12 / 40 = 0.3\n\n(b) Posterior Mode (Maximum A Posteriori, MAP)\n\nThe mode of a Beta(α, β) distribution is:\n\nMode(θ) = (α – 1) / (α + β – 2)\n\nFor Beta(12, 28):\n\nPosterior Mode = (12 – 1) / (12 + 28 – 2) = 11 / 38 ≈ 0.289\n\nPosterior Mean ≈ 0.3\nPosterior Mode ≈ 0.289\n\n3. Constructing a 95% Credible Interval for θ\n\nA credible interval is the Bayesian equivalent of a confidence interval and can be computed from the quantiles of the posterior distribution. For θ ~ Beta(12, 28), we find the 2.5th and 97.5th percentiles.\n\nUsing R:\n\nqbeta(c(0.025, 0.975), 12, 28)\n\nOutput:\n\n[1] 0.173 0.442\n\nOr using Python (SciPy):\n\nfrom scipy.stats import beta\nbeta.ppf([0.025, 0.975], 12, 28)\n\nOutput:\n\narray([0.173, 0.442])\n\n95% Credible Interval:\nθ ∈ (0.173, 0.442)\n\nThis means there is a 95% probability that the true response probability θ lies between 17.3% and 44.2%, given the observed data and prior.\n\nSummary of Results\n1. Posterior Distribution:\nθ | data ~ Beta(12, 28)\n2. Posterior Mean:\nE[θ] = 0.3\n3. Posterior Mode:\nMode(θ) ≈ 0.289\n4. 95% Credible Interval:\nθ ∈ (0.173, 0.442)\n\nFinal Answer\n\n1. Posterior: θ ~ Beta(12, 28)\n2. Posterior Mean = 0.3\n   Posterior Mode ≈ 0.289\n3. 95% Credible Interval: (0.173, 0.442)",
        "timestamp": 1751814188.47206
    },
    {
        "id": 49,
        "index": "F3.901",
        "topic": "Logistic Regression – Binary Classification",
        "difficulty": "advanced",
        "keywords": [
            "logistic regression",
            "binary classification",
            "log-odds",
            "probability prediction",
            "interpretation of coefficients"
        ],
        "source": "Understanding Advanced Statistical Methods by Westfall & Henning (Routledge), Chapter on Logistic Regression",
        "problem": "Suppose you are analyzing data from a medical study where the outcome is whether a patient develops a certain disease (yes/no), and the predictors are age (in years) and cholesterol level (mg/dL). The following logistic regression output is obtained: Variable: Intercept, Coefficient: -6.5, Standard Error: 1.2, p-value: <0.001; Variable: Age, Coefficient: 0.04, Standard Error: 0.01, p-value: <0.001; Variable: Cholesterol, Coefficient: 0.02, Standard Error: 0.005, p-value: <0.001. Tasks: 1. Write the equation of the logistic regression model. 2. For a patient aged 50 with a cholesterol level of 200 mg/dL, calculate the log-odds of developing the disease. 3. Calculate the predicted probability of developing the disease for this patient. 4. Interpret the coefficients for age and cholesterol.",
        "correct_solution": {
            "steps": [
                "Step 1: Write the logistic regression model. log(p / (1 - p)) = -6.5 + 0.04 * Age + 0.02 * Cholesterol",
                "Step 2: Plug in Age = 50 and Cholesterol = 200 into the model. log(p / (1 - p)) = -6.5 + 0.04 * 50 + 0.02 * 200 = -6.5 + 2 + 4 = -0.5",
                "Step 3: Convert log-odds to probability. p = exp(-0.5) / (1 + exp(-0.5)) ≈ 0.6065 / (1 + 0.6065) ≈ 0.6065 / 1.6065 ≈ 0.377",
                "Step 4: Interpret the coefficients. Age: Each additional year of age increases the log-odds of developing the disease by 0.04, holding cholesterol constant. Cholesterol: Each additional mg/dL of cholesterol increases the log-odds of disease by 0.02, holding age constant."
            ],
            "conclusion": "The logistic regression model estimates a log-odds of -0.5 for a 50-year-old with cholesterol of 200 mg/dL, corresponding to a 37.7% probability of developing the disease. The positive coefficients for age and cholesterol indicate higher risk with increasing values of each."
        },
        "model_response": "1. Writing the Logistic Regression Equation\n\nThe general form of a logistic regression model is:\n\nlog(p / (1 - p)) = β₀ + β₁ × X₁ + β₂ × X₂\n\nWhere:\n• p = probability of the outcome (developing the disease)\n• β₀ = intercept\n• β₁, β₂ = coefficients for predictors\n• X₁, X₂ = predictor variables (age and cholesterol)\n\nGiven the coefficients:\n• Intercept (β₀): –6.5\n• Age (β₁): 0.04\n• Cholesterol (β₂): 0.02\n\nThe equation is:\n\nlog(p / (1 – p)) = –6.5 + 0.04 × Age + 0.02 × Cholesterol\n\n2. Calculating the Log-Odds for a 50-Year-Old Patient with Cholesterol = 200 mg/dL\n\nPlugging in the values:\n\nlog(p / (1 – p)) = –6.5 + 0.04 × 50 + 0.02 × 200\n\nCalculations:\n• 0.04 × 50 = 2\n• 0.02 × 200 = 4\n\nSo:\n\nlog(p / (1 – p)) = –6.5 + 2 + 4 = –0.5\n\nLog-odds = –0.5\n\n3. Calculating the Predicted Probability\n\nThe probability p is obtained using the logistic function:\n\np = 1 / (1 + e^(–log-odds))\n\nGiven log-odds = –0.5:\n\np = 1 / (1 + e^(0.5)) = 1 / (1 + 1.6487) ≈ 1 / 2.6487 ≈ 0.3775\n\nPredicted probability ≈ 37.75%\n\n4. Interpreting the Coefficients\n\nAge (Coefficient = 0.04)\n• Interpretation: For every 1-year increase in age, the log-odds of developing the disease increase by 0.04, holding cholesterol constant.\n• Odds Ratio: e^(0.04) ≈ 1.0408\n→ This means the odds of disease increase by ~4.08% per year of age.\n\nCholesterol (Coefficient = 0.02)\n• Interpretation: For every 1 mg/dL increase in cholesterol, the log-odds of developing the disease increase by 0.02, holding age constant.\n• Odds Ratio: e^(0.02) ≈ 1.0202\n→ This means the odds of disease increase by ~2.02% per 1 mg/dL increase in cholesterol.\n\n⸻\n\nSummary of Answers\n1. Logistic regression equation:\nlog(p / (1 – p)) = –6.5 + 0.04 × Age + 0.02 × Cholesterol\n2. Log-odds for Age = 50, Cholesterol = 200:\nlog(p / (1 – p)) = –0.5\n3. Predicted probability:\np ≈ 0.3775 (37.75%)\n4. Interpretation of coefficients:\n• Age: Each 1-year increase raises log-odds by 0.04 (~4.08% increase in odds)\n• Cholesterol: Each 1 mg/dL increase raises log-odds by 0.02 (~2.02% increase in odds)\n\nFinal Boxed Summary:\n\n1. log(p / (1 – p)) = –6.5 + 0.04 × Age + 0.02 × Cholesterol\n2. Log-odds = –0.5\n3. Probability ≈ 0.3775 (37.75%)\n4. Age: +0.04 log-odds/year (~4.08% ↑ odds)\n   Cholesterol: +0.02 log-odds/mg/dL (~2.02% ↑ odds)",
        "timestamp": 1751814278.990839
    }
]
